<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>置顶◇代办◇与更新记录</title>
    <url>/Archive/The-First-Blog/</url>
    <content><![CDATA[<p>欢迎光临willkyu的Blog，这是第一次使用博客的方式记录东西，希望能坚持下去！
此博客基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvLw==">Hexo<i class="fa fa-external-link-alt"></i></span> 打造，主题使用的是 <a
href="https://theme-next.js.org/">NexT</a>.</p>
<p>当你在阅读的时候有任何的问题,欢迎与我联系.</p>
<p>封面 [ID:85357809].</p>
<span id="more"></span>
<h1 id="about-willkyu-and-this-blog">About willkyu and This Blog</h1>
<p>一只不务正业的谜拟Q 与其创建的不务正业的Blog.</p>
<p>更多 <em>关于</em> 请参见 <a href="/about/">About 页面</a>.</p>
<p><br></p>
<hr />
<p><br></p>
<h1 id="archives">Archives</h1>
<ul>
<li><a href="/Archive/1-Pokemon/">宝可梦◇熵增定律◇与死亡誓言</a></li>
<li><a href="/Archive/1-Learning/">学习◇生存博弈◇与纯利他主义</a></li>
<li><a href="/Archive/1-Game/">游戏◇动机判定◇与去悲剧化</a></li>
<li><a href="/Archive/1-Life/">生活◇奥康剃刀◇与自由意识</a></li>
<li><a href="/Archive/1-Collection/">收藏◇知觉丧失◇与不完备定理</a></li>
<li><a href="/Archive/1-TRPG/">跑团◇量子骰子◇与观察者效应</a></li>
</ul>
<p><br></p>
<hr />
<p><br></p>
<h1 id="to-do-list">To-do list</h1>
<p>下面是一些之后的计划,用小标题表示,具体的进度会随时更新在下面.</p>
<h2 id="记录与分享生活">记录与分享生活</h2>
<ul>
<li>2021-12-04 创建<a
href="/Pokemon/See-My-Loving-Pokemons/">亲爱的宝可梦♡</a>页面.</li>
<li>2021-12-05 创建<a
href="/Game/Share-Splatoon2-Happiness/">快乐的喷喷生活</a>页面.</li>
<li>2021-12-06 创建<a href="/Pokemon/VS-Recorder/">VS.
Recorder</a>页面.</li>
<li>2022-01-07 创建<a
href="/Game/Undercover-Brella-Diary">间谍伞日记</a>页面.</li>
<li>2022-07-03 创建<a href="/Life/Zheng-with-his-five-dads">Zheng. w/
his five DADs</a>页面.</li>
</ul>
<p>AnyTime.</p>
<h2
id="整理一些宝可梦系列相关的知识等包含游戏内知识与游戏外知识">整理一些宝可梦系列相关的知识等，包含游戏内知识与游戏外知识</h2>
<ul>
<li>2021-12-03 创建<a href="/Archive/1-Pokemon/">宝可梦攻略整理</a>页面.
<ul>
<li>2021-12-13 已合并至宝可梦归档页面：<a
href="/Archive/1-Pokemon/">宝可梦◇熵增定律◇与死亡誓言</a>.</li>
</ul></li>
<li>2021-12-04 完成文章<a
href="/Pokemon/Strategies/In-Game/How-To-Back-Up-Your-Savefiles">如何备份你的存档</a>页面.</li>
<li>2021-12-07 完成文章<a
href="/Pokemon/Strategies/Out-Game/Pokemon-Cartridges-Authenticate/">宝可梦卡带鉴别</a>.</li>
<li>2021-12-16 完成文章<a
href="/Pokemon/Strategies/In-Game/WCD-Distribution-Patch/">如何自制宝可梦Gen4与Gen5的配信器</a>.</li>
<li>2022-01-03 完成文章<a
href="/Pokemon/Strategies/In-Game/Battle-Pyramid-Shiny/">战斗金字塔刷闪教程</a>.</li>
<li>2022-05-24 完成文章<a
href="/Pokemon/Shiny-Lock/">锁闪宝可梦汇总</a></li>
</ul>
<p>No Hurry. 准备从自己b站专栏搬一点先.</p>
<h2
id="整理一下宝可梦各时代的乱数方法">整理一下宝可梦各时代的乱数方法</h2>
<ul>
<li>第三世代(RSE)
<ul>
<li>2021-12-03 完成文章<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part1/">宝可梦绿宝石及没有电的红蓝宝石实机乱数（不包含
ID 或 Egg）</a>.</li>
<li>2021-12-14 完成文章<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part2/">宝可梦有电的红蓝宝石实机乱数（不包含
ID 或 Egg）</a>.</li>
<li>2021-12-24 完成文章<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part3/">宝可梦火红叶绿实机乱数（不包含
ID 或 Egg）</a>.</li>
</ul></li>
<li>第四世代(DPPt HgSs)
<ul>
<li>2022-01-14 完成文章<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen4">宝可梦四代实机乱数</a>.</li>
</ul></li>
<li>第五世代(BW BW2)</li>
<li>第六世代(XY OrAs)
<ul>
<li>2022-01-15 完成文章<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen6">宝可梦六代实机乱数（破解机插件辅助
&amp; 不包含蛋）</a>.</li>
</ul></li>
<li>第七世代(SM UsUm)</li>
</ul>
<h2 id="整理一下搭建博客的方法">整理一下搭建博客的方法</h2>
<ul>
<li>2021-12-02 完成了文章<a
href="/Learning/Blog/Build-Your-Own-Blog-Like-This-One/">基于Hexo与GitHub制作私人博客</a>.</li>
<li>2021-12-19 完成文章<a
href="/Learning/Blog/Blog-Personalization/">博客个性化笔记----基于Ocean</a></li>
</ul>
<h2 id="给博客加上评论等功能">给博客加上评论等功能</h2>
<ul>
<li>2021-12-06 想鸽了.</li>
<li>2021-12-13 思考必要性.</li>
<li>2021-12-17 实现Gitalk评论功能，使用GitHub账号登陆，支持MarkDown语法.
此外新增指定post开启评论功能.
<strong><em>请不要发布无意义的评论</em></strong>
当你在某篇文章下评论后，如果有其他人跟帖，你也会收到GitHub邮件提醒.
如果想要取消，请前去<a
href="https://github.com/willkyu/Hexo-Gitalk/issues">Issues</a>中找到对应<strong>Issue</strong>，进入后选择右侧栏的取消订阅
<em>Unsubscribe</em> 即可.</li>
</ul>
<h2 id="完善博客相册已废弃">完善博客相册（已废弃）</h2>
<ul>
<li>2021-12-02 添加了3张生活照.</li>
<li>宝可梦相关的照片请见：<a
href="/Pokemon/See-My-Loving-Pokemons/">亲爱的宝可梦♡</a>页面.</li>
<li>喷喷相关的照片请见：<a
href="/Game/Share-Splatoon2-Happiness/">快乐的喷喷生活</a>页面.</li>
<li>2021-12-19 拍的好看照片太少了555，也许应该多出去走走.</li>
</ul>
<p>No Hurry.</p>
<h2 id="学习记录">学习记录</h2>
<ul>
<li>请参考<a
href="/Archive/1-Learning/">学习◇生存博弈◇与纯利他主义</a>页面.</li>
<li>2021-12-17 思考是否要将笔记转移至GitHub仓库.</li>
</ul>
<h2 id="个性化博客">个性化博客</h2>
<ul>
<li>2021-12-01 更新了首页视频为 <strong>《GOTCHA》</strong> 片段.</li>
<li>2021-12-02 开启Gallery功能.</li>
<li>2021-12-02 新增Favorites页面.</li>
<li>2021-12-02 更新了谜拟Q的icon.</li>
<li>2021-12-04 背景添加动态线条效果.</li>
<li>2021-12-04 添加了点击特效.</li>
<li>2021-12-05 更新了点击特效的颜色，使其更贴合博客风格.
试试长按再松开~</li>
<li>2021-12-06 新增博客隐藏功能.</li>
<li>2021-12-13 加入大分类页(<a
href="/Archive/1-Pokemon/">宝可梦◇熵增定律◇与死亡誓言</a>、<a
href="/Archive/1-Learning/">学习◇生存博弈◇与纯利他主义</a>、<a
href="/Archive/1-Game/">游戏◇动机判定◇与去悲剧化</a>、<a
href="/Archive/1-Life/">生活◇奥康剃刀◇与自由意识</a>、<a
href="/Archive/1-Collection/">收藏◇知觉丧失◇与不完备定理</a>)以归档所有博客并置顶.
使博客更加美观简洁，提高易读性.</li>
<li>2021-12-15 修改了博客结构，使得博客分类更加直观.</li>
<li>2021-12-15 实现背景动态线条的随机颜色效果.</li>
<li>2021-12-16
更新了博客的一些细节，修复了Category页面无法正确显示标题的错误.</li>
<li>2021-12-17 实现博客评论功能，详见<a
href="#给博客加上评论等功能">本页面对应部分</a>.</li>
<li>2021-12-18 实现图片懒加载.</li>
<li>2021-12-19 加入了<a
href="https://github.com/HFIProgramming/mikutap">Mikutap</a>，点击<a
href="/mikutap/">这里</a>进行游玩.</li>
<li>2021-12-20 新增博客加密功能.</li>
<li>2022-01-01 优化博客细节.</li>
<li><strong><em>2022-01-19 更改博客主题为NexT.</em></strong></li>
<li>2022-01-19 引入Gitter聊天室，快来聊天室聊天8！</li>
<li>2022-01-30 重新修改404页面，化繁为简:D.</li>
<li>2022-02-08 优化博客内容，修复了一些因换主题带来的显示bug.</li>
<li>2022-05-16 优化博客排版.</li>
<li>2024-02-17 加入大分类页<a
href="/Archive/1-TRPG/">跑团◇量子骰子◇与观察者效应</a>.</li>
</ul>
<p>No Hurry.</p>
<p><br></p>
<hr />
<p><br></p>
<h1 id="test">Test</h1>
<ul>
<li>点击<a
href="/ZONE/WeiChenDemo/index.html">这里</a>来访问卧看小工具测试页.
成品：<a
href="https://wokann.github.io/Tool/GEN3_Mirage_island/index.html">3代幻之岛计算器</a>.</li>
<li>点击<a href="/404/">这里</a>来访问404页面.</li>
</ul>
<p><br></p>
<hr />
<p><br></p>
<h1 id="something-else">Something else</h1>
<p>本博客中未说明来源的封面可能是忘记了来源,还请见谅.
如有侵权请与我联系!</p>
]]></content>
      <categories>
        <category>Archive</category>
      </categories>
      <tags>
        <tag>Archive</tag>
        <tag>Blog</tag>
      </tags>
  </entry>
  <entry>
    <title>跑团◇量子骰子◇与观察者效应</title>
    <url>/Archive/1-TRPG/</url>
    <content><![CDATA[<blockquote>
<p>毕宿星的歌无人听晓，国王的褴衣随风飘摇，歌声默默地消逝在那，昏暗的卡尔克萨。</p>
<p>我的灵魂已无法歌唱，我的歌像泪不再流淌，只有干涸和沉默在那，失落的卡尔克萨。</p>
<p>降临吧！我们衣衫褴褛的王。</p>
</blockquote>
<p>封面 [ID:98137168].</p>
<span id="more"></span>
<h1 id="preface">Preface</h1>
<blockquote>
<p>那是你少年时所见与所爱的一切的总和，</p>
<p>它是那些奇迹凝聚而成的永恒宝石，</p>
<p>它的光芒将会照亮你夜晚的道路。</p>
</blockquote>
<p><br></p>
<hr />
<p><br></p>
<h1 id="mods">Mods</h1>
<ul>
<li><a
href="/TRPG/Mods/Third-Spiral-Grey-Sea/">《第三螺旋：灰海》</a></li>
</ul>
<p><br></p>
<hr />
<p><br></p>
<h1 id="tools">Tools</h1>
<ul>
<li><a href="/TRPG/Tools/UTLov/">UTLov for OlivOS |
像看replay一样跑团</a></li>
</ul>
]]></content>
      <categories>
        <category>TRPG</category>
      </categories>
      <tags>
        <tag>Archive</tag>
        <tag>TRPG</tag>
      </tags>
  </entry>
  <entry>
    <title>学习◇生存博弈◇与纯利他主义</title>
    <url>/Archive/1-Learning/</url>
    <content><![CDATA[<blockquote>
<p>就算没达到预期的水平也不能放弃，继续锻炼.</p>
<p>不管什么时候，</p>
<p>改变世界的都是认真追求梦想的人. --------
<strong><em>阿戴克</em></strong></p>
</blockquote>
<p>封面 [ID:90778756].</p>
<span id="more"></span>
<h1 id="learning">Learning</h1>
<p>记录与整理学习上的一些要点或者问题.</p>
<h2 id="notes">Notes</h2>
<h3 id="pytorch">PyTorch</h3>
<ul>
<li><a
href="/Learning/Notes/PyTorch/PyTorch01/">PyTorch笔记01----基本数据类型</a></li>
<li><a
href="/Learning/Notes/PyTorch/PyTorch02/">PyTorch笔记02----创建Tensor</a></li>
<li><a
href="/Learning/Notes/PyTorch/PyTorch03/">PyTorch笔记03----索引与切片</a></li>
<li><a
href="/Learning/Notes/PyTorch/PyTorch04/">PyTorch笔记04----Tensor维度变换</a></li>
<li><a
href="/Learning/Notes/PyTorch/PyTorch05/">PyTorch笔记05----Broadcast自动扩展</a></li>
<li><a
href="/Learning/Notes/PyTorch/PyTorch06/">PyTorch笔记06----拼接与拆分</a></li>
<li><a
href="/Learning/Notes/PyTorch/PyTorch07/">PyTorch笔记07----基本运算</a></li>
<li><a
href="/Learning/Notes/PyTorch/PyTorch08/">PyTorch笔记08----统计属性</a></li>
<li><a
href="/Learning/Notes/PyTorch/PyTorch09/">PyTorch笔记09----高阶OP</a></li>
<li><a
href="/Learning/Notes/PyTorch/PyTorch10/">PyTorch笔记10----激活函数与常见Loss</a></li>
</ul>
<h3 id="papers">Papers</h3>
<ul>
<li><a
href="/Learning/Notes/Papers/GraIL/">GraIL相关论文阅读笔记</a></li>
<li><a
href="/Learning/Notes/Papers/MMKG-Survey/">多模态知识图谱综述笔记</a></li>
<li><a
href="/Learning/Notes/Papers/KG-in-RS-Survey/">基于知识图谱的推荐系统综述笔记</a></li>
<li><a
href="/Learning/Notes/Papers/TKG-Note/">时序知识图谱笔记与知识图谱推理的机遇挑战</a></li>
</ul>
<h3 id="summer-the-basics">2022 Summer: the Basics</h3>
<ul>
<li><a href="/Learning/Notes/2022Summer/the-Basics01/">基础知识</a>
<ul>
<li>张量</li>
<li>参数初始化策略</li>
<li>参数范数与正则化</li>
<li>梯度下降法</li>
<li>梯度爆炸与梯度消失</li>
<li>自适应学习率算法</li>
<li>评估指标</li>
<li>归一化</li>
<li>Dropout</li>
<li>激活函数</li>
<li>损失函数</li>
<li>反向传播算法（公式推导）</li>
<li>过拟合与欠拟合</li>
</ul></li>
</ul>
<h3 id="flutter">Flutter</h3>
<ul>
<li><a href="/Learning/Notes/CommonFlutterWidgets/">Top 70 Common
Flutter Widgets</a></li>
</ul>
<h3 id="latex">Latex</h3>
<ul>
<li><a href="/Learning/Notes/LATEX/">LATEX笔记</a></li>
</ul>
<h3 id="miscellaneousness">Miscellaneousness</h3>
<ul>
<li><a
href="/Learning/Notes/Sparse-Matrix/">稀疏矩阵及其存储格式（COO、CSR、CSC）</a></li>
</ul>
<h2 id="solutions">Solutions</h2>
<ul>
<li><a
href="/Learning/Solutions/Accessing-GitHub-Slowly-Solution/">解决访问GithHub速度慢的问题</a></li>
</ul>
<p><br></p>
<hr />
<p><br></p>
<h1 id="blog">Blog</h1>
<ul>
<li><a
href="/Learning/Blog/Build-Your-Own-Blog-Like-This-One/">基于Hexo与GitHub制作私人博客</a>.</li>
<li><a
href="/Learning/Blog/Blog-Personalization/">博客个性化笔记----基于Ocean</a></li>
<li><a
href="https://markdown.com.cn/basic-syntax/">MarkDown语法</a></li>
<li><a href="/ZONE/Emoji/Emoji.html">MarkDown支持Emoji列表</a> 原地址:
<span class="exturl" data-url="aHR0cHM6Ly9naXN0LmdpdGh1Yi5jb20vcnhhdmllcnMvNzM2MDkwOA==">Complete list of
github markdown emoji markup<i class="fa fa-external-link-alt"></i></span></li>
</ul>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Archive</tag>
        <tag>Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>生活◇奥康剃刀◇与自由意识</title>
    <url>/Archive/1-Life/</url>
    <content><![CDATA[<blockquote>
<p>重要的人和事物，</p>
<p>无论经历多久都不会改变，</p>
<p>人们如此祈祷着.</p>
</blockquote>
<p>封面 [ID:76002561].</p>
<span id="more"></span>
<h1 id="life-recorder">Life-Recorder</h1>
<blockquote>
<p>趁阳光正好，趁微风不燥，趁现在的双手还能拥抱彼此，趁我们还能呼吸，去见你想见的人，做你想做的事.</p>
</blockquote>
<blockquote>
<p>只要留存在什么人的记忆里......</p>
<p>那就是曾经存在过的证明.</p>
</blockquote>
<!-- ## Delicacies
> 疏八珍之谱，以为知味，不如庖丁之一啜。

### Beverages
- [百分茶 BeFineTea](/Life/foods/BeFineTea/)
- [乐乐茶 LeLeTea](/Life/foods/LeLeTea/)

### Dessert & Bread
- [广莲申](/Life/foods/GuangLianShen/)
- [泽田](/Life/foods/ZeTian/)

### Hamburger
- [Shake Shake](/Life/foods/shakeshake/)

### Staple Food
- [小川洋风料理](/Life/foods/XiaoChuan/)

### Snacks -->
<p><br></p>
<hr />
<p><br></p>
<h1 id="imprisoned-post">Imprisoned Post</h1>
<ul>
<li><a href="/Life/Draw-100Days/">Draw 100Days</a></li>
<li><a href="/Life/Zheng-with-his-five-dads/">纪念我们的529</a></li>
</ul>
]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>Archive</tag>
        <tag>Life</tag>
      </tags>
  </entry>
  <entry>
    <title>宝可梦◇熵增定律◇与死亡誓言</title>
    <url>/Archive/1-Pokemon/</url>
    <content><![CDATA[<blockquote>
<p>强大的宝可梦，</p>
<p>弱小的宝可梦，</p>
<p>那只是人的一己之见.</p>
<p>真正强大的训练家应该为了用自己喜欢的宝可梦获胜而努力才对哦.</p>
<p>你知道什么才是最重要的呢.</p>
<p>像以往那样前进吧，</p>
<p>冠军在等你哦. -------- <strong><em>梨花</em></strong></p>
</blockquote>
<p>封面 [ID:79498766].</p>
<span id="more"></span>
<h1 id="preface">Preface</h1>
<blockquote>
<p>我知道你，你就是那个把宝可梦往死里使唤的训练师！</p>
<p>你算什么！没有宝可梦，你算什么！</p>
<p>你……到底伤害了多少精灵才走到今天这一步的？</p>
</blockquote>
<hr />
<blockquote>
<p>我有话要对你说.</p>
<p>那是我在唐草镇第一次遇见你的时候.</p>
<p>从你的宝可梦那里听到的声音让我很震惊………</p>
<p>因为它说</p>
<p>喜欢你，</p>
<p>想和你在一起.</p>
<p>当时我不理解.</p>
<p>世界上居然有喜欢人类的宝可梦.</p>
<p>在那之前我还不知道有这样的宝可梦………</p>
<p>从那之后，随著我继续旅行，我的内心逐渐动摇………</p>
<p>因为我遇到的都是心灵相通、互相帮助的宝可梦和人类.</p>
<p>所以，我才想和你战斗，看看自己相信的东西究竟是什么………</p>
<p>我曾希望能同样作为英雄，与你面对面………</p>
<p>只考虑宝可梦………</p>
<p>不，连宝可梦也无法理解的我………</p>
<p>根本不可能战胜与众多宝可梦邂逅，身边还围绕著同伴的你………</p>
<p>冠军原谅我了………</p>
<p>但是今后我该怎么做，还是要我自己决定………</p>
<p>你说过，你有梦想.</p>
<p>那就去实现那个梦想吧！</p>
<p>实现美好的梦想，将它作为你所追求的真实！</p>
<p>那么………</p>
<p>再见了！ -------- <strong><em>N</em></strong></p>
</blockquote>
<p><br></p>
<hr />
<p><br></p>
<h1 id="vs.-recorder"><a href="/Pokemon/VS-Recorder/">VS.
Recorder</a></h1>
<p>An amazing device that can record a battle either between friends or
at a special battle facility.</p>
<p><br></p>
<hr />
<p><br></p>
<h1 id="strategies">Strategies</h1>
<p>这里我会用来专门整理宝可梦相关攻略，我之后写的攻略也会将直达链接放在这里，方便大家直接查找.</p>
<h2 id="in-game-strategies">In-Game Strategies</h2>
<ul>
<li><p>关于游戏的锁区</p>
<details>
<summary>
<p><img no-lazy data-src="/images/mimikyu.png" alt="请点击丘丘" align=left></p>
</summary>
<p><img data-src="/images/body/1-Pokemon/ZoneLock.jpg" alt="游戏锁区表"></p>
<p>-- gba不锁区 <br> -- 3ds玩3ds卡必锁区 <br> --
主机（不包括ns）全部锁区（n64不清楚 有待考证）</p>
</details>
<p><br><br></p></li>
<li><p>3-5代努力值推荐表，右击另存为图片保存高清大图</p>
<details>
<summary>
<p><img no-lazy data-src="/images/mimikyu.png" alt="请点击丘丘" align=left></p>
</summary>
<p><img data-src="/images/body/1-Pokemon/EVTips.png" alt="努力值推荐表"></p>
</details>
<p><br><br></p></li>
<li><p>3DS关服前软件整理</p>
<details>
<summary>
<p><img no-lazy data-src="/images/mimikyu.png" alt="请点击丘丘" align=left></p>
</summary>
<p><img data-src="/images/body/1-Pokemon/3DSSoftware.png" alt="3DS下载版软件表"></p>
</details>
<p><br><br></p></li>
<li><p><a
href="https://tieba.baidu.com/p/6580100866?red_tag=2783794550">【攻略】【直播演示】GEN3
全图鉴 全精灵 理论规划及演示 -- 卧看微尘 百度贴吧</a></p></li>
<li><p><a
href="/Pokemon/Strategies/In-Game/How-To-Back-Up-Your-Savefiles/">如何备份你的存档</a></p></li>
<li><p><a
href="/Pokemon/Strategies/In-Game/WCD-Distribution-Patch/">如何自制宝可梦Gen4与Gen5的配信器</a></p></li>
<li><p><a
href="https://tieba.baidu.com/p/7680216276?pid=142702978152&amp;cid=#142702978152">【攻略贴】全球第1份100%开启Gen3幻之岛教程！
新年钜献 -- 卧看微尘 百度贴吧</a></p></li>
<li><p><a
href="https://tieba.baidu.com/p/7349572038?pid=139295609895&amp;cid=#139295609895">【攻略贴】神奥“甜甜蜜树”详解
dppt（珍珠钻石白金） -- 卧看微尘 百度贴吧</a></p></li>
<li><p><a
href="/Pokemon/Strategies/In-Game/Battle-Pyramid-Shiny/">战斗金字塔刷闪教程</a>.</p></li>
<li><p><a href="/Pokemon/Shiny-Lock/">锁闪宝可梦汇总</a></p></li>
</ul>
<h3 id="rng-abuse">RNG Abuse</h3>
<ul>
<li>第三世代(RSE)
<ul>
<li><a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part1/">宝可梦绿宝石及没有电的红蓝宝石实机乱数（不包含
ID 或 Egg）</a></li>
<li><a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part2/">宝可梦有电的红蓝宝石实机乱数（不包含
ID 或 Egg）</a></li>
<li><a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part3/">宝可梦火红叶绿实机乱数（不包含
ID 或 Egg）</a></li>
</ul></li>
<li>第四世代(DPPt HgSs)
<ul>
<li><a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen4">宝可梦四代实机乱数</a></li>
</ul></li>
<li>第五世代(BW BW2)
<ul>
<li>贴吧有详细教程，需要注意，bw的seed0会极小程度波动（实操时可以看作不波动）而bw2的seed0可能会有好几个可能的取值，乱数时需要多加尝试，建议花时间通过统计来得到概率最大的seed0。
&gt; 可能会有更加方便或者准确的方法，请读者自行去外网查阅资料。</li>
</ul></li>
<li>第六世代(XY OrAs)
<ul>
<li><a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen6">宝可梦六代实机乱数（破解机插件辅助
&amp; 不包含蛋）</a></li>
</ul></li>
<li>第七世代(SM UsUm)
<ul>
<li>贴吧有详细教程，丘丘尚未深入研究。</li>
</ul></li>
</ul>
<h2 id="out-game-strategies">Out-Game Strategies</h2>
<ul>
<li><a
href="/Pokemon/Strategies/Out-Game/Pokemon-Cartridges-Authenticate/">宝可梦卡带鉴别</a></li>
</ul>
<p><br></p>
<hr />
<p><br></p>
<h1 id="competition-promotion">Competition Promotion</h1>
<ul>
<li><a
href="/Pokemon/Promotion/Magi-cup-1st/">苏州大学第一届鲤鱼王杯</a></li>
</ul>
<p><br></p>
<hr />
<p><br></p>
<h1 id="commemoration">Commemoration</h1>
<ul>
<li><a
href="/Pokemon/See-My-Loving-Pokemons/">纪念我爱的宝可梦们.</a></li>
<li><a href="/Pokemon/PokeSchedule/">willkyu的宝可梦计划</a></li>
</ul>
]]></content>
      <categories>
        <category>Pokemon</category>
      </categories>
      <tags>
        <tag>Archive</tag>
        <tag>Pokemon</tag>
      </tags>
  </entry>
  <entry>
    <title>游戏◇动机判定◇与去悲剧化</title>
    <url>/Archive/1-Game/</url>
    <content><![CDATA[<blockquote>
<p>真想见识更多的景色啊.</p>
<p>正因为知道了世界的广阔和自己的渺小，</p>
<p>才会对明天充满希望！</p>
</blockquote>
<blockquote>
<p>有的人说，</p>
<p>因为世界如此之大，</p>
<p>才有了各种各样的想法.</p>
<p>也有的人说，</p>
<p>正是因为各种各样的想法，</p>
<p>世界才如此广阔.</p>
<p>这两种说法，</p>
<p>都是正确的.</p>
</blockquote>
<p>封面 [ID:90778756].</p>
<span id="more"></span>
<h1 id="preface">Preface</h1>
<blockquote>
<p>如果你面对抉择的时候，让别人替你做决定.</p>
<p>你会对事情的结果后悔的.</p>
</blockquote>
<p><br></p>
<hr />
<p><br></p>
<h1 id="flash-card">Flash Card</h1>
<ul>
<li><a href="/Game/DSTWO/">DSTWO相关资源整理</a></li>
<li><a href="/Game/EZODE/">EZ-Flash Omega Definitive
Edition相关资源整理</a></li>
</ul>
<p><br></p>
<hr />
<p><br></p>
<h1 id="splatoon2">Splatoon2</h1>
<ul>
<li><a href="/Game/Share-Splatoon2-Happiness/">快乐的喷喷生活</a></li>
<li><a href="/Game/Undercover-Brella-Diary">间谍伞日记</a></li>
</ul>
]]></content>
      <categories>
        <category>Game</category>
      </categories>
      <tags>
        <tag>Archive</tag>
        <tag>Game</tag>
      </tags>
  </entry>
  <entry>
    <title>收藏◇知觉丧失◇与不完备定理</title>
    <url>/Archive/1-Collection/</url>
    <content><![CDATA[<blockquote>
<p>纵然身朽去，心美亦永恒</p>
</blockquote>
<p>封面 [ID:71672001].</p>
<span id="more"></span>
<h1 id="overview.">Overview.</h1>
<figure>
<img data-src="/images/body/Collection/Overview.jpg" title="Overview"
alt="总览" />
<figcaption aria-hidden="true">总览</figcaption>
</figure>
]]></content>
      <categories>
        <category>Collection</category>
      </categories>
      <tags>
        <tag>Collection</tag>
        <tag>Archive</tag>
      </tags>
  </entry>
  <entry>
    <title>UTLov for OlivOS | 像看replay一样跑团</title>
    <url>/TRPG/Tools/UTLov/</url>
    <content><![CDATA[<p>封面 [ID:99703082].</p>
<span id="more"></span>
<h1 id="功能介绍">功能介绍</h1>
<p>本插件基于OlivOS实现跑团时实时窗口,
PL、KP和OB的发言均可以显示在实时窗口中,
并且会将PC、KP和NPC的话实时转语音播放,
掷骰时也会有一点点replay的感觉(有但不多), 使得PL们跑团时更有沉浸感,
希望能鼓励PL们的RP.
此外你也可以使用它来进行跑团直播或是录制当作简单的replay.</p>
<p><a
href="https://www.bilibili.com/video/BV144421c7pP/?vd_source=e1ff0185e3ca082e7577b5654e16f3da">实际演示请看视频.</a></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3dpbGxreXUvVVRMb3Y=">已在Github开源.<i class="fa fa-external-link-alt"></i></span></p>
<h1 id="截图示例">截图示例</h1>
<p><img data-src="/images/body/UTLov/UTLov.png" /></p>
<h1 id="使用环境">使用环境</h1>
<ul>
<li>源码运行的OlivOS, 因为我们需要在运行环境里引入其他第三方库,
我这里使用的是3.11版本的python</li>
<li>在运行环境中, 需要使用pip安装以下的库:
<ul>
<li>flet == 0.19.0 注意, 这个库只能运行在windows10以上.</li>
<li>playsound == 1.2.2 注意, 这个库最好和我的版本一致,
最新版本有bug.</li>
<li>baidu-api == 4.16.13</li>
</ul></li>
<li>此外,
本插件在运行的时候的界面是出现在OlivOS所运行的服务器(电脑)上的,
所以最好该电脑是私人电脑而不是云端服务器.</li>
</ul>
<p>在满足以上条件后,
我们需要先将<code>.opk</code>格式的插件后缀改为<code>.zip</code>,
然后解压并打开<code>UTLovConfig.py</code>文件. 找到第七行的"Path"配置,
将后面的文件路径改为你的资源文件夹的位置.</p>
<blockquote>
<p>如果你不知道资源文件夹是什么,
你只需要随便在一个位置创建一个新的文件夹, 然后输入其地址即可.</p>
</blockquote>
<p>保存后重新打包为<code>.zip</code>的压缩包,
然后更改后缀为<code>.opk</code>,
最后将其放入OlivOS的插件文件夹然后重载插件即可.</p>
<h1 id="资源准备">资源准备</h1>
<p><em>以下操作都在你的资源文件夹中进行.</em></p>
<p>首先是资源文件夹的文件结构如下图所示:</p>
<p><img data-src="/images/body/UTLov/files.png" /></p>
<blockquote>
<p>这里我的资源文件夹就是data. 其中, 打码的部分为用户的QQ号.</p>
</blockquote>
<p>文件结构为:</p>
<ul>
<li>若干个以QQ号命名的文件夹, 他们是KP或者PL们的资源文件夹.</li>
<li>一个名为<code>bg</code>的文件夹, 里面放的是若干你需要使用的背景图片.
(在本插件中, 图片仅支持<code>.jpg</code>或<code>.png</code>格式)</li>
<li>一个名为<code>npc</code>的文件夹,
里面放的是各个npc的资源文件夹.</li>
<li>一个名为<code>ob</code>的文件夹, 不用管它, 一个空的文件夹即可.</li>
<li>一张名为<code>avatar</code>的图片, 它是未找到图像时的默认头像,
一般用于不重要的npc.</li>
<li>一张名为<code>dice_bot_avatar</code>的图片, 它是骰娘的头像.</li>
<li>一个名为<code>dice</code>的音频文件, 只支持<code>.mp3</code>格式,
它是掷骰音效.</li>
<li>一张名为<code>fig</code>的图片, 它是未找到图像时的默认立绘,
一般用于懒得找立绘的pc.</li>
<li>一个名为<code>UTLov</code>的配置文件, 后缀是<code>.ini</code>,
这是主要的配置文件之一, 可以通过新建文本文档然后改后缀来创建.</li>
</ul>
<p>下面我们将按顺序来准备这些文件.</p>
<h2 id="pl的资源文件夹">PL的资源文件夹</h2>
<p>PL的资源文件夹主要有三个文件: - 一个名为<code>avatar</code>的图片,
它是该PL的PC的头像. 如果没有会自动获取该PL的QQ头像. -
一个名为<code>fig</code>的图片, 它是该PL的PC的立绘.
如果没有会自动使用上述根资源文件夹的名为<code>fig</code>的图片. -
一个名为<code>userinfo</code>的配置文件.</p>
<h3 id="userinfo.ini">userinfo.ini</h3>
<p>下图是该文件的一个示例.</p>
<p><img data-src="/images/body/UTLov/userinfo.png" /></p>
<p>其中Main模块中的name和job分别为PC的名字和职业.</p>
<p>audio模块中的spd、pit、vol和per分别为语速(取值0-15，默认为5中语速)、音调(取值0-15，默认为5中语调)、音量(基础音库取值0-9，精品音库取值0-15，默认为5中音量.
取值为0时为音量最小值，并非为无声)和音源(度小宇=1，度小美=0，度逍遥（基础）=3，度丫丫=4，(后面的是精品音库)
度逍遥（精品）=5003，度小鹿=5118，度博文=106，度小童=110，度小萌=111，度米朵=103，度小娇=5)</p>
<p>status中的应该看了都知道什么意思.</p>
<p>下面贴上可以直接复制的示例: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Main]</span><br><span class="line">name = 焦糖色</span><br><span class="line">job = 陪酒妹妹</span><br><span class="line"></span><br><span class="line">[audio]</span><br><span class="line">spd = 5</span><br><span class="line">pit = 7</span><br><span class="line">vol = 5</span><br><span class="line">per = 5118</span><br><span class="line"></span><br><span class="line">[status]</span><br><span class="line">hp = 11</span><br><span class="line">hpmax = 12</span><br><span class="line">san = 56</span><br><span class="line">sanmax = 60</span><br><span class="line">mp = 12</span><br><span class="line">mpmax = 12</span><br><span class="line">status = 正常</span><br></pre></td></tr></table></figure></p>
<h2 id="kp的资源文件夹">KP的资源文件夹</h2>
<p>KP的资源文件夹与PL的类似, 只是没有配置文件<code>userinfo</code>.</p>
<h2 id="背景图片文件夹">背景图片文件夹</h2>
<p>请至少放入一张名为<code>bg</code>的图片文件, 其他的背景随意命名.</p>
<h2 id="npc文件夹">npc文件夹</h2>
<p>npc文件夹里面包含:</p>
<ul>
<li>若干以NPC名字命名的文件夹, 用于存放各个重要NPC的资源文件,
其与PL文件夹内容类似.
<ul>
<li>一个名为<code>avatar</code>的图片, 它是该NPC的头像.</li>
<li>一个名为<code>fig</code>的图片, 它是该NPC的立绘.</li>
<li>一个名为<code>audio</code>的配置文件.</li>
</ul></li>
<li>一张名为<code>default_avatar</code>的图片, 它是不重要NPC的头像.</li>
<li>一张名为<code>default_female</code>的图片,
它是不重要女NPC的立绘.</li>
<li>一个名为<code>default_female</code>的配置文件,
它的内容与npc文件夹里的配置文件<code>audio</code>一致,
它是不重要女NPC的声音配置文件.</li>
<li>一张名为<code>default_male</code>的图片, 它是不重要男NPC的立绘.</li>
<li>一个名为<code>default_male</code>的配置文件,
它的内容与npc文件夹里的配置文件<code>audio</code>一致,
它是不重要男NPC的声音配置文件.</li>
</ul>
<blockquote>
<p>所有没有单独文件夹(以名字命名)的NPC都是不重要NPC</p>
</blockquote>
<h3 id="audio.ini">audio.ini</h3>
<p>下图是该文件的一个示例.</p>
<p><img data-src="/images/body/UTLov/audio.png" /></p>
<p>同PL的配置文件<code>userinfo</code>里的audio模块. 注意,
上述配置文件<code>default_male</code>与<code>default_female</code>的文件内容与这个一致(具体声音配置可以更改).</p>
<h2 id="ob文件夹">OB文件夹</h2>
<p>空文件夹, 运行后如果有人不在配置的PL或是KP中则会被自动归入OB列表,
届时该文件夹会存储他们的QQ头像</p>
<h2 id="utlov.ini">UTLov.ini</h2>
<p>主配置文件, 下图是该文件的一个示例.</p>
<p><img data-src="/images/body/UTLov/UTLov.png" /></p>
<p>其中Main模块的Master_id是用于触发启动命令的QQ号,
一般为运行OlivOS的电脑的所有者. KP_id是KP的QQ号,
Group_id是运行该插件的群号. Opening是插件启动时自动用KP配置说出的话,
已被废弃, 可以不要. Bot_name为显示在窗口中的的骰娘名字.</p>
<p>BaiduAPI模块的三个配置请使用自己的Baidu API信息替换,
这是用于百度语音合成的, 具体请百度 <strong>百度语音合成</strong>,
注册会赠送3w次免费试用(好像).</p>
<p>KP_audio模块是KP声音的配置.</p>
<p>下面贴上可以直接复制的示例:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Main]</span><br><span class="line">Master_id = 49xxxxxx8</span><br><span class="line">KP_id = 49xxxxxx8</span><br><span class="line">Group_id = 95xxxxxx5</span><br><span class="line">Opening = 大家好，我是本次测试KP 丘丘。</span><br><span class="line">Bot_name = 黑巧的容器</span><br><span class="line"></span><br><span class="line">[BaiduAPI]</span><br><span class="line">APP_ID = 48xxxx84</span><br><span class="line">API_KEY = Ts**************EOe</span><br><span class="line">SECRET_KEY = aG****************************Ld</span><br><span class="line"></span><br><span class="line">[KP_audio]</span><br><span class="line">spd = 5</span><br><span class="line">pit = 7</span><br><span class="line">vol = 5</span><br><span class="line">per = 5118</span><br></pre></td></tr></table></figure>
<blockquote>
<p>所有其他的多余文件不会影响插件运行,
所以可以放入一些备用文件以便替换.</p>
</blockquote>
<blockquote>
<p>整个资源文件夹的示例已上传至github.</p>
</blockquote>
<h1 id="使用方法">使用方法</h1>
<p>在配置的群聊中使用<code>.utlov</code>命令即可开始.
使用<code>.utlov end</code>命令即可结束. <strong>注意,
结束后如果要再次使用请重载一次插件</strong>(这是bug懒得修了).</p>
<p>支持的命令:</p>
<ul>
<li>rd</li>
<li>rb</li>
<li>rp</li>
<li>ra</li>
<li>rh</li>
<li>st hp或san或mp + 运算表达式 (如果掉了1血就<code>.st hp-1</code>,
不要直接<code>.st hp 数值</code> 这会无法识别从而不能同步进窗口)</li>
</ul>
<p>特别的命令: -
以<code>(</code>(中英文皆可)开头的PL或KP的发言会进入窗口的meta区(超游区),
并且不会进行语音合成. - <code>.sset PC名字 状态</code>
可以设置窗口中PC的状态, 如果该状态不是"正常", 则其头像会变红.
例如:<code>.sset 小夜子 疯狂</code> - 对于KP,
可以使用<code>.NPC名字.NPC说的话</code>来进行NPC发言,
如果是非重要女NPC则需要在第一个点后面加一个英文问号. 例如: -
命令<code>.Mia.大家好,我是Mia</code>,
如果上述资源准备中有配置npc/Mia的相关资源,
那么会以配置的头像立绘与声音来发言:"大家好,我是Mia". -
命令<code>.路人A.大家好,我是路人A</code>,
如果上述资源准备中没有配置npc/路人A的相关资源,
那么会以default_male的立绘声音来发言:"大家好,我是路人A" -
命令<code>.?路人B.大家好,我是路人B</code>,
如果上述资源准备中没有配置npc/路人B的相关资源,
那么会以default_female的立绘声音来发言:"大家好,我是路人B" - 此外,
不论是KP还是PL,
所有其他以<code>.</code>或<code>。</code>开头的话不会进行处理(OB除外).</p>
<h1 id="写在最后">写在最后</h1>
<p>UTLov这个名字取自我的跑团小群Untitled Tavern的缩写UT加上love,
感谢所有PL们以及和我一起入坑跑团的火龙果.</p>
<p>祝大家次次大成功!</p>
]]></content>
      <categories>
        <category>TRPG</category>
      </categories>
      <tags>
        <tag>TRPG</tag>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>第三螺旋：灰海</title>
    <url>/TRPG/Mods/Third-Spiral-Grey-Sea/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Invalid Password. Check And Try Again! (♯｀∧´)" data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="42c74615a40885e20a152392ca6062584f3c58b589bcd37f86cbffb8f4ef152a">a9154d246928e9e831e6545b33e2d3386fd120119228a405fcd316f4a77f0d9ed16869148bdaef9d382d9486957d6653d73b7041547ff3898089e451c1b7133ed2f1df2ef8019261e2e64fe509af0e5cabcc6933b4cb59abb968fc89b1f3c390a14b971b4e62cde95594f7b68f0212a5a826baec7dff3b1a596c8f32f55c6c5e2fa21d664958df669cdb45add72ac69e473bb55753b7b34c53d4376f39e40b848444aa9233dc4c5607c96f1846a86c47ba256841028f411f59e975488275cb8d06f2fc173388b0aff8da7ccf555cd37a0fcfab93d78583a9096bbc0c2f21908adb02d9891dea6f90f7f6f52f5e172047ebb3cf5aae68f026fc9231f1d10d90c5fab5db9d3072c3816f759dee39175ff6aeeee19999d5ffeaeb7325e6803abd709836ab18876a54ab09c4c69932731af58f8fecf77f14a59a4da0c82642ae04dbc6cf5b632475edce99d6bd39dafd1b213b7c1134d8493838cab997322dcaa3906d6859c3d0d203d74083d6adbeea30aab29d357a09db50ce57603a13d16a6ec71f8d4c31576c08d8ba336c394bb8b4c6d6331cdec4a0d07c6a78b4ebd93c1e0a014dc15810da9045f8639f6ea09abee5cc42f3145ed0f2fd4449e27c82ae46a2725debc74879ea1ee142e0e542943efcfb9d90042b15d59a29de958208ba571022c6651b7589adda9f4279e65ec1733f3ed11368036a5c72bce00c588404fa24cba6d179ead0a6907eb20c38e1ffdb889c67185e51753bd6854cb55298e07f5740cf8be40d0e6dfeebad0010fbde6e780855ba17d4a29d8b58fb15a46413310011f3530958947ef235d96db52b848fd5f9f08e5ae22be99b0d47e5d7560e2550f4a2a7155dea54fefc330a1834058d256b048a3fd00f39ab2de9dde978f4b5d6350b43bc0a5372ba817f503ec1b49c2a7c5d82c235e23e3a623cdd2eefb36b287f1f0f0bca38323d04f730fca5cfebbc6e799b260cbb2930640b0f7a0b1034bb1493c0453bb92838a8740332a0218a85751d57e6d57095116d24a637223194ca79ed2684a1eaaf9ac8f852d7ff8510a2054528208da09d92648e080b8605f9fef0075bed5ef06603762f99d89f3aa6fb66e513a33de971dde9b73674ca91c82290f1bc839d352319bda59fdfee49dab7704e4337d6db9178792324783283c8e227c0ddaae4142c4f5990dc486efbd35837c8e6126f3a7d07f14aa87e89287dc67df9e05d58cfaa1a7b9897d714c203a223696b81c11c48660cc517bdfb6949fc1f70bb5f8f2ca748bfa4e56edb2d8c0f7ea01c1931e481ee415ca33413c92ff38c2e905b532baaa8274ee56392fbda93cef0b84d82e9284bba4a2d1841a1132bd814414443b1630dbbeccd57302a68d83e73760cd907fee2d0df4ec0dccae72d7d9d4fde521c215e89c7a86b03c9852284eacaebefef2a60b518b2cd78f0305fea68889a0d1208c2bda956a41133cc253a7719e72546e77b093f03948e7ff7446d5b0b2784dcf69d0281ba8940f2e6ff40151ac2184d0ef256ae4047a1d009fe927be73b345f2f0f137c3306e6091db8301a0ddf42fda952e107b36561a1f861071f4055130894062b29d8e141804fb55e4cc3db4f6160e56330aaedd5bfd057a0d75e9aa23b99b0284e8a440161a4f4bf2e67f10c39e266f8ff3bc0992a6864ef72710844cab41758574a2dfb19706300eb3777e247d0468e0f9dcb25866be48f79f039eba4df2a5befeb0ee03070ecc1cc63e491f3c904123b79bfeb136700f2a69b20263e4e6a5c990d9a764e18fa4e7da5302de446d9063e7f62630ec32c83f7309879e8dadcb43ec419db1e9b8d369fc147ccecceb6aa4763a878b7c91bf5e4664b79cd6a9888f15c086c005843a2253e4811eb0b3a546887d1c091f30cdbdd789e2f89f0c505c55878fd95df25567cbea467f4cc6820ff4ffddbf401e4e1f3cbb6de62bb09c18f694c53bfc2e9e46a127a1cca8ef607941ff68ec22dae5a72c155fe60db7b006a9e5dbac0b1551f9cb58be0fcc249fd8b7fe034e67a3ec2e20e618256dbd018ac493d5c6812beb74a0639c365b34bfc88529b2c765ad34526901c649254d83345aaf25e316b491dbf4020676f66d8a27d44ef64fe47938481af5573f053168738d208c439c0188c0997ccb297ad2d695e77fc26b951d92e6bee424d771f0e4214694ae44880e00c8142907d7357afa98e96363ab6385380857c524ffd9d6fc2b6842bf96c9a4016f02af19a834fd1cfddd262d3091fce18e2f5445b81f3e606f237f3c5609b65430866306bbcbbda3e136567960b99ac6b0890dca5f2ef6ea03eb99e2338e808bbf63b434c07fef99140a437c8d38f1be5ffb4e6e94800c2d797fd510262fb290f59453b6f2df56e6c69005305fe3df9d558b20865088f97f8ffeb4180d26e1ebc69a5f8f27c45037e3fee6afe8be358c41704fa1e68621f4ee8e9d933d4f434dae6913cbbe8bbe96ed500516586a75503b9ca328d28f451c1ceed30c5d5547598119139666e72320225334e1400fb9e911c89da619f5293492fa506dd499cc8eab66e85191f530fc687c14f015063bddbcaa58705b6853711e5aa430be09a8c23644ba576ef784467fc11de91db1b09d3cb3a53a75fdc1a672a68c32856417618202fb6a6d1825d1765e5607c6ea880f2356a920d9a6456dec3c2c66acb0bb7ce46976ddedbb3aa59e05fec683e38b76fbf17e3a6dcd7d88cf7595f8839c9ef20ee4a3c6d3c996b82505d40ca96f1186c57f79aee161cc58ced13a1f281d89754e973599ff654fcc4348bd11fd284fa1fb73f496374eecda5da9d5b3fb7cb2595801bb27f7d891389d93cd80d4c7af4048042718f3458ba813867f7a8aeded2569570ad19ca7f992486f3533d35e3a6eb8d41ff06c1d8f8db0d1ba4cf0650291f3722c51f15e6e6af45ee5ac07f5135aa4987deabc624b8454ccfd16ed690b7b9ae93bdb31371d48866c1e725b7a0da70c012d8f03ca5d7df8550aef3a0a1e2246b00dfd2802317efca9457d2f4e640703f28c06c545a061557a81292a1c4c2da27369b875e80b3e6a97f72ac123a849fc058da78281ba13cb06c7f7f21b0c567256aa873a93752f7d01e4e640f1989b37fc40d9815c8864e4e57abf1db361748ddbfd740195384610b3d17cb137d7a4018a0613e59f55c1a345df27de5ca5b6b923078c0c07d6f87f131d08624e2cde131f885c941f9869c08a756b78064dc98c2c898b91717d628d28bf323b876cb8a32299d7a060acef169de53cdf6a644528c8d55c611d33ac8171c24291114ba8b9c4a794071665c2b2d5e7bba90af78aefc33033b29cb2e7c96d33c551f73319a7567ac703abc521fcf45db5786de1050338c665998549b348db81a24cf613b66224e1cba6996c415ed01f4c3a73db36273744c2fad96754a91c4aef8bd34839226e15f330995dee65fe39d65c0931bd3102f17b852f3891db40354b632aa391ed325f925b8bfb2e0562d1e3164de7c453a75dfe12da67e3999dde1e7d79b595ef37356e447adb1925aec05a2ebb2832cb70456fc45bd3a58455985c061cb1933418ef554347e7a8f14f69caadf17be62ba06da595d22fdce6b09272b7eedab8d5d352c9e79d51e09008879296a1c8cff163859a146aae4b6fcb7e4b7faded57313cd3870189d5e34d3d0501c0d5b838bb5918b3d30c072cf65e93b76197c4e6c5cb8ce21284e3fce02a1b4076db5f69a58951cc576be6c39d4a766c05ea94bca01935048909cb3d9a3ba371c23453da098d5cfc58157c25fed4e9bab85a150dd4194c20f1de9744e83d0a179db0d7f666f1566929fc915b2ab58b970477b7a10db3bc9a6a0037da09d5250e4949c779d6b7b321ddff96c585dbacdac71999460e531e7d64ebb1120d4addf8b4d734853613612d125cc01f2c98be4487248dfe59c56019cab84323834bb6921b8dcfb625681c866a274bde180f3979a32d46bab59ddb7aaaf2dc22cb9ac437215d818b8697f8e0002c69c897f8e160f3a05f9dfbc6fd17dfe5babcef7c7fd68822de2fec71f711394af77cd62dc54a3dbbdc8a8b5d759875642432f5415a55bfaf2df29a7111b72128db221ba41715d92bfae573de2f6804b9a2df0982821de3eadce249fc29d5769db22db9317c96c85c606fa44a85c6b9e2a69c7350f019a6a2753d49bd30873b8033830384cedc3c05ae852d5b6b32fb4f5be8f27af17c4852dd50ea47d76678f9fe255f1f9c5d27cf2feaa2b6f5f50acceb29a9e0eb42ddfe3e20224618da77f32d9bf4892949689df0d1c5423da976459121056d211efaf6d56e9c635ce4b54c7f11c5ba0187e540fb697eed2f3559beb93b84b510d87ad6cfeb3a286f6ce15ea38462954fcc70f4d236d2d185d6ba3cfeca5cd325bdb805109a33c4f3c05181fbce484107ac4db4179f500deb8d34cc851d7e3fec9768a47556d58b07bf7f8e76fba9d13de611e9e6cb01a24f1d8fa7a43ec60651a7434a309b19638dbfb3f7fa60cbcad713af096cf6693684205782484f3674673e515b35f5527503347bd7f632ffac63350b839b373852da738df0183237c61667bf55e0106c38c01dee03c52f921a35667a47a58a39b3a94dc620eccfb3aea2961e60e993f0047f3fe1d6f0a74ebae356780cb6074a50c9ec737a9e7a2a65042590925a3d0fceadfe21ff2aaa854270aac72b8401b366d9cd3655b9f213856a11db992cf195ba8c547598e81d6a1fa13a51ee02dda95ca8aa19ff0229d07f888ce6125a00d30e1483511c3b720966f6625f2da34d369ab2136565834a5be4c51adc225417854e6d3145165690a865f4526fcbcbbffb3ce69572bd1f3644f126bf635ec4947ff70147ecf549b3fa276de5be2bf97573294f1911b8f23448ecd5c1080e5b7484a9c79c754cf6378dcc4d5f96c119b2b9bbdfa0da830338ab03f9e5a9f99b31a3f8f47d395b8b22923760f3e2d1c5dd702d94575f0745d0480102583d32785997d978318947bbcf6fb4743b121d4b29505377d90460ad5a9cd5481bbca4e267626f26ec948dc1968f7fbed032274b10474b2475d4ede54c12badcca32e30c3703ae4c0597ece427819ce2a6506c80e95618ba09b2875998c545e5a9ad4f37c613a77d77525f5618d9f42089dc1ca5329b76100b3cf1bf901e2be102c192e3b18d5a732a8576a1dffbe0583869fd148cb9852e18a86c24d13f9eb32801e9efbf7ecb35fb9c55c8c72646f56dfcae9b1e36905b4d43e116adbef58b3ee839058a76b5e38d599147c1a9414489ab24955207c841f3f2cb61596bea6a69f038fb69f263ae851d7d1b8da8596ef7daf74af5afd3b6d63bf7636624b11f4be036b6073d887399b0db9c68c095e8d3fca503cebedce9ad1072240f0fb67ba14622ba61c832a2ef21530cf37f95e8e7e13e868e626ef9b8c6d58cd673cdd4e48ce4cc29746f02700cdc2cb8fc1278b1abedf2924d139cae5d0566e3f786800b326e435e155ac82be9ecf95f566650a5f29fdfce732d3bb51e49b52dadfb4893e1a562602535818c87941b999512c1713a3ff8ea40546ae5d4e8b7213f5159cf522b691f6d593ac50f1831b47628ae43be007276d8c2af4269254292918fba8f92462f9afd1acd83c34e57fa8eed21b70c111b96ac0e1c8ae38fed12ff02cc92d36afd68e0925b1a15c0bc30a66ff0cad2b9b28cd608db407f902420c01152577ab4fef2ef0172ec6fd84b254f3c0e11b51ab1574f33e4667b3b82f9b842a80525bb0a77d227b8f4009f4e97a108258b616af3a30385b5bc776d8b8f1b9a45d63223d66d6419a2cc82ed8e37ce49a233a88e46f842441fd122b3b6cbad1b050d5c491815bc329721610f1307e0e3c5ed1e47e5e3bc759f9119633d9db0f465512b7e6e02942a42d025cfb6b0aa11e4c443c3969df67e06922b1efe52cacb336274e16def206464d660dba2d69ca8bccedc66c85ac7c1864d9344f76854ccee481c970a194c584e1ce2f0d3c95c3775f6e49bd9446433b0d3d946db4b85eba277a9787969c7b79512af886fe7491f94fa775dc06efbb9767983e966c0826cf96177f73a2bd2f59ea4a664105c79e97d2ac3895ef858ea58a47fcf9a1ff3a042f4f608ad399ebb186a749c1bbb3423a13b1ad4ebfaa8e9b8e8a5e18cd04eb44475c7c6288d530bffcb46b233d7a859f70b33877982949739ecc44612ee12ee4d16edaa1defe694d95362085e3ba346480d93b525ae2654d9bc20b718d6a59284fedfcf4eb95624295f6bc3279f161cab993f06514ff7cb27f80ea145135a1f0cf7f5a06e0754ddf29827919e31df3ce79ec63ea9db4b23875327c1165545c65208a2ce05f33a0895c1e0604f56a09d1f2ebc696355ee7f6ca99242c304be4603862426600df8d400d7f6142728e00eb916eb2313ba9ba3cd0fc4ac008dfad9a74ece9a4e2414b6a470b862b81ee1547af1391cd574da50c7099ddd7b65d325993bc7b7d028b23299134185f24933f9f846de6e7a7b28a2767ab912baaf862f4a6ca6ed638a2fdd42adbc780209f3bfb2d07d688cffb009a03e8164b26ad8895099bf6690ce08e3048beca3e568b39f9ab593ba6d25bbeae62c22efe13d2be5c468d7c1f3896697a625bde6684a2cd65492f76da4178db234d1ed3b2de298623b12baf14d1a0da0de62796b509c492e92cc50ca4bf29d8b0465475cd77b659bf3310912e9786d45d598ab97917559d6d9af839a6d92c0ac0c5159257d1083b676d901435b19e5c86c9c424565aafda2e0361ac3c55a4092d24eae6cd16026257ce3fe44fbc4d483f6b0c0c3aa1372f6570de16c0c53afaa74dd188e85ea7205c1690078c0db151e4adf0cf3624a1e6a8300a25e248a335262d64efe254862ca54daa33948de3f0bc7e1e8896b56f49ebe8718dd416bfcb51594312ec8ec39ddf092192ba3e7d31896c1d3408b85d07d317dbc913297fd7d8ce8db660657dc8d0f06a289bd2a76c785cda3cf73f3069ac9fe7bd980d64b13c4a813846acf957e4820f27b2f8b227dbc45c73bbce395f4b9f208bdaa9041af2012d1867514643e9d095429a2a547883084a26f0920559c13881b88e6f378304ce476b8ae91e9e1c2f771557dcf2407ad0d70966143e87e4b62bcaa3cc4181578b1e479dbe43739725ac81e300266cce5ed06253959618989b949d0d2fc392ce57117d0e9c1bce3eb5881a541e2a40a11a9e910e0d7b28522c8d57713632044cfea404dc9890051d818343083e2e002517295a1badcd3954b57be8b3c41ca27934983219703fda626692833a62f8dae7aaac3d2d36a368b038e847c829aa79f862461a23f62d58922d2ae641615016b1627b2492219d3343b0326ab464b2385ef76804e08b4ea85348413afb23a80b66ae0a373271ac02184831bc7963ec2403c32670a805db2d674f689cd77d34465575eae4d2bec1c6b3a63ad0cbbef3c4b00160bef9c107c444918977d5d08a1c9a0316000a6f821db5c5c43f9620ec0befd835022ff073bda66a671e00a4f22f2746a581d42becc0c4d19d422214448e1362f1e1db7c8e9ec263a9e8a4804b772e859fd245ae520c0ad0c80b0d8f86b4b8a5b9ca042eff2f3a7e5516efd6c82e13f70a2a9dde7165e3a8fbaa59bdd052efd8b403f56f4bd22684089fcddfcac24cb663cc042f36c083383830efd386839a60a0f24605afe788c998477520ca2e4513996b0bf54c322ba2f2e535b0c6600b1b9104e01da5f2d182085f7b54418832c974b9bb2b87f4511b8c43b627aaf84c6983815a012eb943faf16dafd01fda7fd3bfebaec59764a205843c2a02ab1441ad90687f9e12d2cc18a1887375818b911cd902dff98bebf7f6e43910d85f8c409da61f7c6fd6f562783ccfdc8edacbb4c7021ed485243cf4d1077b6223a9c2adaffd6622ec8b21afbc9cb4927fe653ad01b35f90d31d5a9bcde2c91dceea631ee4235b6adadeacb484512b5306132c4195f13c0ad48fd5b151796b5ac5a3bff548c3070046cd76f34e3b8fcf04a6550d07685ac3baa4206d5310f31ebefd079e87ecdb64d25233b89ce5c16e03ad83261e6e66ff09033a94d23c872d58298255d2990e93e2e4427eb4d0fb1597746b4ebfdd87bdf6383cde76008578f99cf4bfaedc92c590f71a8ede45512cb72a460c24a092617073978ca66914f2c277cca553c435dde127799a36eba94de86a457b0bc99cc6ff2cde5f8352f7005a84cc37ae21581985d96c759c4e58198fc9c17eb97dd443e6975d955a18cd384a8430444cb4f866d6cdff9957cf80220be583003b0523844aacf950c472004c1415d8e8d462a772981de003f4ec1340265bfd11fa6457a82f1f79ffa59206dd8743f20a2f9f44e3837aa07f25e956b599245d895f320ad0fdba36a9e26a9d83ffffa7d8b5bca8fa55dc095096b8c8368f3a1ee273f9d21970036fd2404d604f9e27013cc2faef5b44dc0e29a4e526499589f2ac6a13fb8853fdae4adb39f5189c5d8dc3f5a7251dcc56032f5cc40b44ee7d662be615f4c5dc4fa7ebb726159246ecab43840ece9453bbef5d1455c8cc0b5ea3e77c10d8d251221e741e0e73e3ea65fd6c55b280628f124c32eba35588b90e32c2205dced77c2e4940c62f0a44c725fbe05d462035d9d39cb00b9fd18e77f932ec815482744ae90042639823f32da3106fa887a439f427b05c0fe6e322a3347c61fb61a4c91f06fd86ce6ef8627e6b94496e1e3331e275f2684e320a62fac0faa41aaf1e0e077bccb3196b122c3ed59389c5e2f2f0405222f433c060604f6f549768bd743deb9ea20f3d914c23d7942f9dc93012cb5eb005031127ff439c0ee55f0b0d5416a8a99acde245b61f1e1bd782179a1d704b5fd2e22d99d299ee4f481779bc59aa54eb29b0354244d9f5edc7f69bfac8e3e6387265873b4ec508d5381f53cfd2e8d7e49fab0351df0c77f32c376170a8130cf79bfdeb90d2ba843a6fcec012137f59aed58cca545705f0a2ae86eb439743ad6ec50c5274414ace3005d4e6b3ef73152e28bd93138e512382dabe8fe4434d785b32dac0aacc07c934d17a8b394de3694c2e50dc506f43aca401d33cbd03f38769df73a67840e8066f5f49e2c7ea6d67c43094751f5df1f6ad83b75703c24839cf1a1a797eeee324aed2c2b31bf0ed92e3ea9d3727583fb90e834e1a49bdbe1710e9c422681f57dc5ee98a614dba5e82394f6eb960454aca132251b17b23d2bc14457c96913ee2d18db21be3757e14cf9cbc0e47931ac656eb4f3b2d4c50996513c0fd43b1b47ced18c92075be466c11175b323267bdb5acc4c782bd515237b85f11981c5c5a2e8af865e35897becf416ac38efe9515415c94208e7a7046315486ac73a3716bc100453a6acee999a37c23457c41417fe1903a27ebed64c59e769f5ee591327650271132f4cc25ab84a6544a3f1e90e1526a3b9a24e82473ca5f095d1e11d7bce550e4b1e003d18e8b32ebe4ee0bd3b536ccada54871c642caa1710a4cd3b736363fba98c9bf5ba8099a6195d307ce764f85f737ac162976dfd667aeeb82476bc8d399c075700c9dcaa63ddb8ca0682db0caff82dcdd2d1777e7c93aa2fdd535c8203407efd688ce5bd652cd62220b4656b24d3bf3b6b85a0ca5b9cbc62c61e97db0fe01f9f2d5cf7af5b06420ab8ace135c332c182770865a85f7c61e561608367ff5e56dd00da58463137a3bb43c9b748592ee9ac63685d50589c3ed4e75171dc9f025986a6f4492ec397a34274383785f726c408b9a8e5aaf7db9c908ac846ca39d7e9295d6c6b90a1dc8582d9b2125baf4916d17e51d4148c0243405b95fa29a8ff74a183d930b0e93e5ca75e1824fe7632c3de8dd40c2e56ea441811227f062da185b26a81167398df6486195343d26ea6e98d5fc1ffa786449885e07046eaf7683eb2de0f44da5644ab6dc8df8eb411cf762a7a08d7da17aa9ebdba6a3abf7425f8aae1480bd9d198680ec40d1ff4d79c18fce6662044eca07d30bdf00878c52bf01d502da5fa3fe256ec48aa819a979bf4b736c7bfbcb8a315b86a736aa53ab5e7d4b666e8da46f0662036fe0320e6d274c6adbd15d8af64b1c596203fc815129d7120c23dd3c24129c8956a34144ce8470d7fa4059b1f376e38b8f6f6b4e10d85f7fd3506f5b42d8053c8638793f0e84e62c69619d67a3e4b7b865bf882d5ce5ad121ffc8d514c1c221dbf2ddd7995fb79313a02b7d56019b3b9f5ba6da8c33e7c4c954d5e068a647134e89a9f3f59f57941be7888082970bb2b5253d33db9a96d164a42e36873454f82f539a76b96ec20bc2852b64c86db43af3e9c75f7666434ee8a5864f1a0e69c214e1a49e24e1927c46a2cdc3be88fcb01367d091bd407006f30b2c1bdadddf5df6e955314420fd47b7bd5e6a61b9f204e80f1f41f6c1d769a78681222a44271492f7c11cccdea4bed9c9e567a49750c8a2cb1144ff9aca686f8b51b7d39d2b4829b9e19b18f24520a517adcd10db2266545289ebb70273027d5cac236d6b072caa047780ab61df21ed2d9e33c72523658bb3b5ed52e712a953c3b8711c46547b85ba9eca76acd4df37f4ee8d68e181ef1326b411d5678a5cd1dcb6f5030a036ecc38c16d20f9fcff5fbad033c0c0445d13eeb5106850fa25ade499802894a4a6ac36926edbef27f5603ecf8cb588972ead729da0208e1854de431a1988639a6b47e13e230fd33e99946b07393ec5d858136ffbd8c27fa018ee01cf524610a0d7bb00031dd97079998f14e315849ffd03778f06f3b595887671ccc3434910f86319c18e5bfd16884844d2584e2a76e607b59c2cb52da94c7332012a76bce9155cd4a6199cde550a986d5ab2ff5cc489e46f70836cfa96d7b6fd00a9f211f5eb910d618bd2e71927f417cde94f6476d31d46949f1ee8f52899f24cdb00cbd739925b863d1571fb93741d7410860bc7b8d88baa057a9f9fc9b4ad2116561f8c719855a02cfc6b806c8e72cc78f47c21c7fe654e23f8643d4fe3e028afa346262aaa827a9639c965053b74395d99a72a39b955def951db8ae0c405ad4f11d868dddc9eac70cf6ba7f5e856124fbb95acbdaba938173d56f3f185a500e3f5e4c85646c3fc5a0a512391fcd6f4c72eb0e66f93ef6f73a049f5b21b6ed2da94ecc287927948dc98f7513b5513bafdbc3409beb104ffd1918a0f3c258ab649785d17cd33cfa6e0fc7f14ef56387746479f4040700a96ce04358d45156132adef2d5833529c758bf638c2a7f1b4e877ceb6d59ed4d32974e198fe00f92d771f4d311ae3caf7c92ed8408c3def7a9418aa9dcfc74d239fe242dd52fe01a67dff6ef7e13e3cb846016d02851f65d50c3d5323eaa71fbdc019dfb92459d57100d13fa5ad1454c94911a62f99b390907b20ecc715b0a3ff3f457c8dbed8331382040e1f6808081d5380959a31c9050fa886859eeb4a56dcb90a7437d0929d60f50816449547f344ad92fb04083f809fa8cc6a3bcc420dd79bd433da8a10cb85cd3643f81cf46e53433e6bc36632776efc73d285855b6c0a540286ba78e633348ec71f07d07af772971ad39875b85e63d3a4d63854f16076a3a8d35b37dbdab1c1a08184ee00df31523cde6dccfe7680c8c1cd2d69137eb7ab45dff902bc3c2206ebe2cda346c108ecd709df655341b8c9687f29e1fac9eb2bd3507b8d1664b9dee95663cdcc0ff110f16ec80dbbe1467335577bc38573d296379aed0b07329c68a99832529bd073ea1d4a0150d331e9bb72c7089f01fb740e16fa3b02e862aeda32bf79954a4925bd06899132f05d73254097f5b8bfd52bba43c43ad2cd7e9b30ee5fc299b243ed8bc5368a3e5b4e05f28b6399082354ad8c870fb3ed44f7316fb1cd000f6f1ce05dd4e7fc7cb432c0323ed19591ac9f235b8222f200708762ded8de5695484020aea26ae05e2154ec65ae355527c0fc7a965b084e2386a65e6b4a720f8a2d5aa0a12da6fe407cdd02d071853bfc91f241fc1cda55e77a14c23569a6cd3dabf549ef2ceac892200c6edd1aa640995fd08e99c62cf481ae90cb6c36efa843eabdfcbef048438af3c78ee5aabd449b746fe7ce0a3bbcf8fc6bd3d9d72bb070b1651d8fff667edbc7b5a1df01399eb6112276df097962a5576d337260fac2d07eeada453e45d4c49f071c992d2f8d56888bd7446f9e730f9b616651bf24e48f74ec67598ed4f7bedf662060d7f53cefdcf08e1e7bbe0721fac581f72b5c95384d0013e1af24e0c3147b8df46c306fdf24c1bc849129dba2cf64c07b2f4b559b39db052c2b001e4bff26f77e189c9217c0f7a2d02ee29c023b5fe0d947ce83476d4d3ad5c9fc744662de9f9020b9d4fe0ea858b209943b4b5505eb4a6c7f1dafc3231bf1723c3fa7108560a795d7bf0eefd4295f787700c281c9ee90f28e157c8586a322ff243bfb4db686b65f6ef17b2107aeaaa60678ee2e0bed6a8339e5ed104d606b729d35fcf78192fac6833d0d70e8a2d10f41e12af0f716ea3881cc8e88cd26d93c43e44c3292ad59c19db438abe97c29dcb4eac180a86bf02d10e05a85d0ce798b942d0d05bef728bbc1908e41eaf6da4cfa57d1991874e79797ff84e6a9ba2fa070e39097b965310783399dce10b171f4d0f5738f341135964bf55c65464a38fa0fa6a11896a60187de3fa053744a57821f9430c236c7dda053ec1e291f9b631042b216243c0ca376ce1e9eb04d034b5dc625d9692cdfcb7f6b13b89850bc430010ea78690537ccc64aa25bc5aecc6cdc1f999500829af26d777154cf62dbaa8c737773f0da1fcb46fffe13af0bef8713390a18a4db05579892023ce2331207dedf232f6b1cbdf881ce6c9ecb9e6d1bb19dda986685a59f952b006f750d32004ab5b9063e4e13049555b0f352a43befa97fd6e1b0af980ef0fecf3f465b759cbfad7dfca3d74ce448410e99d1fbff2b7c25426033b8d56d2fcfb496138bd95220be284a6881fe635611a371337d3a0e5ad96df6191204532c1a4222795934580990d3d714fee413380b8ebce2756a2e16124cf87d057a060c2d601aeebabef1f73204bb386b25ffec652951db229a6ba23814567fe9e1f5be099d3b194cef38b54ee8983d60d5198dbc29719bde63c8c52d6d291e6d830b65e51baa8d0577f49cdbaad7b376cd01e9add2f3aa665189d5ba11ef5f1547d308ed898889780ee5d166e3252b43b518081eb4c07b8dcd950536ddc0e94f9be88316d8334a0ff33e8ba7ff6eedf2b55a25b5452e95258a592078ed37dbed0e3b72bb108e8de881f2c2bfb69e86ef184be791fe3a83370f0219d0938a2264b0e2602a4fe7b1e728dfe917ff558a924799b6c7b48f1c9141e519c6cf64b0bcb11e11fff49d64dfe7bf6ce89f15552253a4682478bb784acf381c6c443d5295ba21213fc1bcaac51a3d8d3af49ce608c49ec7f3c38960e30718bbb2e13405cccff9cb9c47a31e36fff1eccab73e0d676364f97e6704665f378d4f464c51605a18f2c65a1e04b474b79b996dbf1f4fa8fb8b8fa7d0dd61b141c5a7c7f342fb8c647b4a334a1a4393326aef0ef50c4279aab508c6ac7fb282db265782898a8b4e4f660a65766942378f253bd98ba1351f6949413ed946174c7412cad2fcc36ff9fa0ddd43f63c9dfff7073f17b243ca89505de5f315c1b08242070b24e474faaa5a12c701e9dfd80d5fd9a62e735f0a854893ad402253fc0ab740c7b88094988f64073e05d03a4521bd7a5274db0d277f450cf4e41555ccc7568c7bb047940b373a18c0e56d1b18df5ffe892b082575cedfedf73f5deac5b5af5061bf5babcba663c26cd782ada6a7b13bf40b4ee53634cddbcc9bc4a091417e961023e7028a55ea5e475286f112e2e40cd80497703bf34633d6f82e2cffc7369af46edfad7cde5757d2479ec5ca1e8f38d6e2f7f6158385f075433e432dff6277b0d4d3fb889e8036830651e70d02f2d04df082622a3d52d82117b4ad35879c318ff66147383bcb4e229ffeb6d2cddabcabb89114c1f0ccfd32dac05e4f1ba0260e14c528838e99cd108068f9692bcf1eb2bea4f9512bcdd7e8cf6541f6aad528563e1886fbcb94c8b391afeef9b33dab69bce7c2d6e10e6aeb6ee8640d357446d74306cd0204305e1915fad5a09350dc4f9b6cd729e7b59696b5c3dd944f8ba5ce44479f72ffde0364a4c25d67755a456018462cb581b4058dbbebbd2f32698198adca54a1535ba97caf8fdfc6b0261ff1599e8fb088abc7f75367a509dc0ed0edd2f9b3557f38b03f5eca73eea5c3b61b9f6b2057a6addaea003255ed17ed68cf656146586547d9a6b394253feeebf42a5f967d46b8f21a7888eb24a90bd3d92842ac023fc39c48ca81d6abd320be88c9461a4ee78d07d7d78762f8e573559afd7e3fbe57d2a4f3b4ae59d949d829f86f58ff48e4942bb1c24360a049eca2da56332b164fef1a36d6c2de5d48ea0476d3efaa84d12b555bb156275f908e07701b219eb361467400d262d549db2d6097bc749d9d3007f5d2158463caa5f428ce7d6a3fe3ef68df8c8774471f52810a305ffd6c1c11e338a0eecd7b04e1dd15332a9f2c3c34cad511cb3eae6ba15e4059aea91248c56f828e13c2174617c39f3ba851fe91d7d380e4ab47e05d7c8ee87c97bf6068313ea7b654cf6effcc76f80243ad45cdab780ee9eff210893b6ed8b8c01fbb9e739a2a002a1b23f5e7c4bc16659cf58877c7b19b2af16e554167b3463ebeb9f4f320c8a7f95d8896b34c06f8a7852162805ba31e0029cae52a0f63a2eb7daf24204d76232d81f19ddf4aa2161eda1f9ff297ce5250ddb7b6da71b913ad18263fcbd9828da08ef84f26e7db32ad225d4897f7486576dbd7014c2d1f26357711d520400752f0222ad06db0935303ced1c40e9ccbed929e4c84c80cd1421f0d37405fcc2e4cd5a561243aaac34580715c24857577d6553a74babfeaf5accbff2a092622453f9ec5ac37075a76a3641d8fd63b8f46a4cd6371504bdd570c985346eeaad668426a1863521108098cd5ccab8e52382c2b4aef89dd6ab865632748b0224b5afdb111aa58c5ee6d920d3a658c01a36bb4a3dd389cf4bc3db953553a70006fb0eb39e2298db6422b440d4f4f588e17c558f3488153de7ebb9a1f4164e6b6c3a28ce3172cda097beb3ac9d18ba2f8f774cfdcb9f3d845de940299ee2872fce7c9069f997b6a0463997d2f52484796f26344b499bba1a7d14307f5ffb1f257ca21b149383467c7318b26d8a16113a81ef8a30cf90658c2f2d55774e3a39aafc3bcaeb0f71a10ec3c85162fe04fbac10fd41cd00e2aedd2e775efe84fa1d28479f377b433354c83282109df7059dd468ca02007a44b5cba94735934c72d29a08be94ec689a8682d78a172dc5be5dcd60deb3177bbdf19ef37b9a976d79b9b7cb44e3e7e9ff39512d61f7cef818a925ff36f2704d8538fdb7540f2d32ff124b7171b71d32994fbd5a2f31586f878d4174b850b5533fd506165510641a7f0197e169ffba79d05b0db0a4722ed672ab3bfc4b511cfba27f55a04ca5dba91d9b8e473444d0171bec6f4d8039ee97fd3ddfb4b47c820474101de84dbbba4e3bd6edfeb0bab5e8ee09498a2555c4bcf0f6fd8e6b38de7339174e89f052902e6dfb94f6b5839d4e2f9f52b23b8b5f40b64b3cdfcdf9fc407c5f379c8264070e94ac340bcf3cba589149a0975ceba2ed87905e94fbd87612f42ff48c265226f531b69dc3aeb85ec386d8035a58dbe2a8eeb5b63072270ed7e5624e8bca4db26bc915f4848503d0bf7538c46045715d0a1b22ee086a45a91ba0e3738e680563189ab7832e4b8220f4d07237e833d03d846ce1bc6257a049a06a8c20fc0156aa9d887b36edc35855104b7f6d2b6b6168ee419cdee839f0e363b3590c731bda60e4be5acd91be5dd581f2803645c4221930c00ccfd4a95bf7bfce2f397f134bd3fd26e30de3a4664b86e9d8933355ee9c717e609ba98f833b58e0efdfab517f1547742df4fa2489c8fc9ac1d391680b112ab0a0076bf57b4a9878d493dd852b4766a52e05cffa2385bc618b69dbc697e7d32b843aba33b83f45bbe1dabb67281da67df5ae9247baa70ad45ebf128c5ee508c976f8dd48615107e9bf5f106af413f4ec5bfa1f2e52d22859c99d661d422181f9228352ff3645e634360421c8071aec2979346e85069816e6203883279ed75577e12ef907981e793cd0a8ce2322c4768ad263acfb9d6afe79479881baeb2a27fc8019445351493651988c55301123366170726d64b7d23414942183d6e1fa6ef673f6ac1d83c7801fb902968ab4d003a8026a070fcc64072d2c34a1b747fbd5c3f78cfb646651d151d092d1a098618b2c172c427fd6a7a6ad67ba64defce5283c3e8dbbb3fcd73678af4c16e65e95be71b5b8144203b5e3bd248d121da545cb60abc8300c57f22621f4531af1e027dd285ceaa2bca5d88c0523934b7061c1387bddc499e25407a2fe0b43ad9aa3b782c88b30fba9a279a622f5950f0f782b6b40ffbe5758743b076f1657d38aace51578ed0c6301eee340bfe08515ffb665f9d6e90e67aeff44df98dae87cc38bbc56e3cb5f243458d4ac95527832011c927eb9ce713e353d95bfa5d53d2a631c180a11813b3328461142a784f81452c606c2ee4ff9c6c31ca4fa8359168cef3157d4c1a3e8c51aa262f9a5b894135bdcc69713b6219c2549cbec473357e8aad6822abfcf5e3ea666e337f8bd54e4125766c0df081376a00307560a2117dcf51d1cff6cfbd4a3b6580cc8589350e0c647b65336c3bfa5ff74979e9266abb1aa6e1e81e910cc0fa687e1a200b371bd0dfca50903591d68b8f1670f157c5696f84fc73c1bba3e0724739ea1eb365f7722156321991736d2ae1efee6f12306597e36b1f71334d7733e8bcc75eb7c381461a6fab88c6aa2f264b46c6c98b87f51bbdbb811d2d3b2c361e74653463fe6628b1e85c5143a5fd96c794be7456806a4c886efdc452c1db21cee4c6dee09946e29cf4d85ec4cdaa377ec979524b9fd714d103f6a96da6ed7ca05fea8e6e0bb4e15f9db2adcd5f1acb18c5b54b93ef3fdb8ce8d9d5014447402ed05b0ebff86082e75934ec1227f277d7c1c3cff51bd9203e4977bc2a9a9288f2e63830052dc18aff372053fb6b5e1293b5b8e49ff8e46a0309fa50785d2b24ab32dfc7d2addc46f2cfe5fdfb73868efeee1f6bb20efd08a64ec92f430ecb36e8a69e51ee769290e10e2de543f18a9d11bb9717507557764a1dd7e2c45d15a712131da6ddf6aaa0cc07cde979d063480e3b431cde13a0be89120b6c75eb8ac03a4bc33e8562328c9d0d9865021cf3a9ee43a3af356d9230f1acbb9f5fd446c5b1eaf6d3128d0ffaf76458a340c34b158c0a6134cbfd8ea3faecdee13e1ba456c52d196ac5e3ae8b2d54d838c74e388f5d2b24344e941dc6fb1bac0fd9901bce19e40a468bc138cfb7e49d39d345f9c91c5150028a07e6710dbaf41fc0812c6d28e1a96568a4177bd4cb053db81b737a6836a1a214b8749e032658007f583eaa7d95a69fd7d5a22e31522b30d63e86d310b3f8644ad5cf12a1bdf9ba3079e2fa6b14e36c1f46c05028d0ceb27ae07ceebae1d82ccc435f9cb5eae08368b5dddd7bc0c61c121f388f08c1d196c3104d35099ac444bddf951fe03317338b0d95afd4d209b087401d2510f83e06e16ce13c8a9b52f8154e88f7fefe4c0f82cb5047ccdeedc38128fcdd8f8b950956b7003d4de775770dea2269e3f2f653e0faa15cc9616bce499d1881daba892f00efe3eccbd3d1cc1834757ad4c6046d3fdca6a0d64c7864a57099b7ac3d8819446f9c3c0457ae7740d0d498dec132c751875f59eb9911873fc298d3a280c34d1f3c915e6281e7d4d555e5b398506fb51d6c4101a8e5be521a81c72426f3979c4bf42139b20d9197781788b5a3df44bc489ae8e2cd78205ba17084c0d08f499ab1d1852d2d6f141054afbeed9ecbd02108f3e7eba5063a84f489509f0d26b9d50a17a634d2502655bee37e6cedaa94e2d9ddb98e1e0c9265512dd565b8c2ddd98e34f9d3eaa4019d96085a3c348cee5d856217edcec1d80cfa033035022cb2a37da5bdaddc80d94c153ab0a43b587747f3e296eef1d579f78842c8374eddc07af1756ed9dfaaf462b1f7ce1945d555df4dcfd9e22c87ce358b95d84286aeb3c0576b556f8d37c651e0dabd799ea9a8f65f3b9ef40a9f6a29000b111d1311ab69f85be2d33e307d40a10827aa3d62a7744dc109b6674cd781fc734b99b6fb4ef1ac22fb458cc4aa4570dc6aaff3ac833804927d4d5a3a3ccb1d7e4f1b6a39bf8026c3999b7ccc54c67540a24b7f6ffdaf0856144cd994a450accb6bbebd50e68b458ba1ad535024cc7488124505065ee82c756d3d3b6dfdfd6067f531138d1554919e05cf0643d729dbfdf4a4a53ddfad3a8d8236103b2d209ac0b394d277838ab1e66d71ed8f690780434e83c864094a927c3db20772491840beb8d0b82f8c35d23973118d38b64ad4f0a9b04c968dbfcf2cf230f9621e47125ffd28e05717c2e3f550c949cd1ea8d453932afc5a9ba1d280b4018aadf7f5d23989ce22aa4cd5532a0ad7549bad914653ca9bff197c0d78bb807ff49b8035edcf7aa73324e60406bd0caa09f665e13aed50bae4894db91a5ce5fe2e8fd498b711da714ae9c2432089af9e441592354a742da87d19cee7562b97da7525e1a4c5ed0be46d2807de1f4ca0f4dfabcc7551c8d51d4734b75989d03ab2520b24b8f821c7ce8911989d2864194a68e3b3f81f953d663fdca10ccd46e09183764045d4dd4f921e468a12995256aa6181e05930a07a85a41973e10c5d5b5828db304427ab6f2c2ed564e9103b74fdb82d5a6478bcd4c782218748f139717fa984f1957ffaa58152e32cc812c1be55fc71a15a37d044bc9c505720acd70da7ecb40aad7a11980f1ed584294632d7230a14300f565eb5ceffe14c6a029bfca348ea5d5563e31a0875053a60440f0d19d3aab0dede1b20a0e405c1fe9ef6ff131ecfb3b2897fb976112b960151cc7f26179d379e4bd12fc09580f181b321de7a7540c0364793da5161bd431bff008db12ae07428708164adf7be29180239904817e66e545da6663ea442c66814b5a8f35f585bc4a2f67528795c0ad516d7799900c311ab63b0c75be99519aa00f9024ca925c00d631075cd405c715687904b623f56a309a2afff1a88f4be7287c82f652239e165516a66fa72dfb013a5dfe7cf63896ef77e31cb1288a43d1fd2e1f64bb86ebe9ace93a7fb5f311219e3ab7264a363e4fc6bd2ad6b0dbb72abca5ef28810ccc014e29b24dbfc8d255e94ae0dd4b9b7ac645e3d4a4473dfe70f05a8c442a7117d9f7036314c0b7a888ff83a2f5d106d6747e97f6c41a743b13b90492a7ed8b0f43a03fe6cb37e5282ca1eac1de1f39a87579c706162e29a2b8d68453f8d595112bdfe3473caf47ef48a1aa35c510c38457e491d7a929ed5f8e437fda47c722ebca376e95e0b177344bc7242bf1f0977a041acc7042da95ae310352364b39584a8f4d1e1e913cc71c96f4355e74a98452c0359f701c8a5e0bc1d65b315d10935881c6dc5cae7bbcc6732e823b85fa19c1fe4b8eccaa944b838206a5f51a83b1c1f2e7ed39163d2dcc5a6cd00384280225271faf659ddf26075ec0ce2fc4e73eca25f212d5123672ef2248616f9cde12376cc73e604e9209c9ed1eb7499f796e094b8e0367ec377db69fefd646b8d9165c76c11ac6d9a49834c9555375d455ed7e73e2638c9ff702d64fa30c188f05c30963b9bf97eb99ff3f12aad95f87d2e13aabf0c7d81f563a7260b1ebde2afe473576c3160eb08470f9df81c7c99f9e7a9ed866670e2ce5807262f774b538591b68985e9ea24394127f6ccea57a60502fc112721d24539c0fed5ec49f6cea182d58ddc4a580fd7bb460790ca7f33049fdd78e10a9e37482a64381905d0e8956be9e7a5a5a8a5d6164d624c4043a5ab2de74b7c9da8fe835053cd7c887518a2cab945ba92a126f5b8a6830243318000163a34c369f408275d6f8da78331947b8c28b9c303f612d3a25bbf6775d8cb0b467a7daeb808712441b7442fbca4effc9072bccf22dca60982234cbd30abf020853f13f76dd80f2d7830d9b4f262d2626989e81b37f7b7a435a7f3f620a95af09828573c7462544478d73a6a8556022df8a2d126530f3ec2d10f313760dccc9d7d17b42adeb2cd9b59a6170b603f725ab289df0133e3d910886c3af5591692455fb34312803b756dc32cede2bd00c7a9973642de8f607b25aed8f4ae180d6e0cd7da056b93559c09790a53226f7252d484fc505b52df3b599a9c6b4c78f6bb0e748dfcd9de522e55c166ac8dbc6a38840483f4120a90c0b7cbf471f8cd4112b73a009f39ef584c75f6ec5722e4904934d404d9f015d9b9b65bf32478ab8ab9efe82ec11c8276f915b4889d5e21b14c24a21d1d24d20032005f35281184d61e97a7d5e36482b3eb6f05a269da020b58e5e526b7620ab5b134fa5299f17cf80cba9ca610020d4a10e56ef19091ae1f2ee650238787e24109b195493a025972296e80037b7397eb0b8ab61b32404aa44f5817f4e932010aa01dcb606e7578761b3b0bfee1f423748d4eb7eb30560982de0313c220b4a2f9b7248d6c0daba5893a4cbf67ccc789a08e193fe9b15f3535c8d63337e92c253057a9884fc9e3d0010a41ff8c317c2bc0eb1e9654477e28f1e2713a31312595af2f3f4a00fdf0b38d0762dc708352f5c61d2443721b10dc6346f0a60af2fc7eeb5c08ac04343d73b1744bfc4a708b680c0ab82218fec69e2b9725e08ac14bbe9e23daf193c1838fcb22dd9eb4e9eb30b33dafffccfeb4d3164ed70371d190e73b6296e70568fe842f556c51ba543495631e0dd8f049d59d7c0440e8afda4421f723ea4a2f63611a69c03c52453dbd3689afc98ed82f0f6898d5bb4743acbf91a43b9cf4a16e608dfba11843a83c1b4cd2bee396abf797fe5c6e64480a2f58c618a2f88685d07a6cf1ba566a1efc37309ac81e7e67f9f2a2bdeeea4958af1210bda3f6bcaade06a8d94188c7e5082880cb0ab530b2ef44845c4c851dc6058958f23696d669602897e6387e6a144077bb455b4ba8e380fa6cd6bfa3a240525ed0184f7cc5c13c91fe5443affd345fe61e054403981b1ea928d7df98394141627ac828f3b8c250227d4dab070603007eac02d625ec72c6ef87b67e57152b15e3ea2289fa5feb5ea5eb2429d37a18aa90ce9a3e7be53b0719664b93e3d013c3041fa4c3b6b2fdb454305e533fc0197572da287f782ed6e876b136dcd8ca3e48a29010e8b4fbd44d452bf908c7b014b016fe8da9d4273b1d14748f38d1ad09ac4703df22cd0e69079b8659a7d2cdd0059ddeaa6f6e84e176904805b1f2dfccb7c2c46cf95786b6bfe89f7cce156d0763c768b14fb2b766948a0df78db071955bc3ad0f529864621bc1b0da1b06de9175bd1dbf0551c8f5a43654457a025a137b20307f1b64dc1dd3983f6064b9559d60c61211e0c8b81f8cc69837c2b58a0df143245b13900d2417d8d865b4c1de0c9a22ccd1404f7b6a4c421f71433537ee5bb00f629fe1b3591ac1b43b23f3e2791fd6228b797e4ed1cdd8dff01b4ddc01e4ddc7aca19d4bd497ce055f59e02307c0a814350f5f570037b38765d84f7d242ab2d8457b5e492ed923524d530bc431e7fe867b21ad92f3ebc7245c33a05b0122d38b55a11f4b8d9c8b07eb193bfb9350d145146abad7ee9934e3c2470ec4bac0e9ecd98bc295a2813d3d32d7c5e2d29fa739673419be6b223517a51131e8ab582b2a1745d44e934a5ce3d6cc975ef5e7727e38640bc1d8ab8ed2cfcdf37671d0c80f1a21ed991ccf7519d41f52492c7929074346b10c4e15c671758d11a6f15d6a983d6c0bf3b676b2e021e91b00b6d6a347c7e4c0bc659bb4c1cfd89da76c9f5bc405aa1fbdae372d27d53aeb1602273fa5658b643f103e17099dbc5445b3bc71967d9cbd83be20eefdc5e4aa2de3ab428f5f1d270b781f7636a3244a779e830a5a8c37a81f125b8ac3fdbcfce3c0e6e702e37e7666d55c2d5222397f21904d81a4a475a65ea0532cc6af4f90ff9fd1d1fe05ca0d3074ec034889e737251afad066a084222f084dc7e734433708874e0c9779f27447b1104b7cefa986f19c882390c2437678280638fa0e968c6f56528f793de8eb03dd86ae431f6e24b85eab5fea999e6889aaefffb8479167f9b5e8d710d3781fd56c0d0733f854b8f36cd53da76c1f1149b6879eae1318f239e180434cd8d7e0075be3d05b4c6015c06499c4ce7d4596d311d8682f7228c0dbb167f00f0c1289545a544deae111da9f8ef40b8c98dee9eef61a45946e7698080119cdb55f4e925153433a4f44ece508eb60434f159b806ada2c0d29694006fd026e6ff151cea623e2a4dfc850a957b44cb79f5d9ac037fb2f23fc14dad318b260109dd709203f890aa44e9a6eeb746d6bf335d960af02b261ab78531211996e5090407eda028822ed678e870465df95693012259298204f25060fbd34f492715d2708d75300b20f19b55469d2d7aaf3aa7c19a579294dbbcb260a3444ff4e5f43b6032aaf8e51e860ba5cb90d6a32d96732eb40412ecb85d817b80151c8bf0ad7ef93e23ab7eb8c819119cec1711ba53b6c298c35f6ae0a2f9f5b3216fe8bceb1ba19cffc2722739feb39640c4f606f2f7dbfc6694a1e7f5d66354be52a1f9e68cca3b907ce38daebea0fab13487b0692160a6185a93433ba30bb53962dc521cc17792ec229b3c17229075871b5d4ce706cb8d445570ff3602d4ef97a0713816d1b8519fbf41f11c9003be45008efd4ebb214a2fa8532308d721337408b72f239fd792aee6b5378ab334d9e01c9d045fe0cd8b35ca89614f089f273714ecbeda09f2e3f82ecd3c95902d0c5eb0e37bf8ecfbdbcd9bada44336c3d2bd9212ff8a73c4e2f28188b184dc29f5c585d93a64ec63102f0a4290fb2c13ffd79ab0ba4c60810dc0acb5983e115fe16e2d170f20e02174bd8879bbe7f21f4e5375f38259495d1e7803af41273673a2db660dae424d95a41b6bae7c1c6f811fdcb80a940b1f26d2118242f2134b74ad5667b3b2fc644a94283b889fa5ab784962851cdfc8edb5622e585226f3da2c6c759cda5c9b2a54eeb50c6964f6b2a0b9fba2fc7220fce66a490e3672f5ac1f12e4a4db85d9350226388d559b7aff16a186c7a3ec6f3d049e85217d40b89fc85684cef306017646e0548e321986999322663e65b4a88d4756a6cf2719a52d77eb65db0147d10ee1c2b2e6099fc9bff86e355350ad1c6bf7028452f209a095371a66b1c9c708cf2dfb1e5f73d30adadf1b01ad1ee4613654696486723fd0fc90e3b66f599652bc097ab884d9a8c4c49ff1d06069c69c7b2b2ac07d49da1a9f89c759ae4d74b7b9cd7151ab65bf5eb84302df1c33d531f1f9b237f26163ab89a51ddaf78713a692cd46cbea7a48fed3c9cbc08012d9c6818921ca549de2a0f12c4bf6f3b3943f3843d20c172474ff160822b89df4f5ea2dedec967a538a340b7dbe21b4bb042c1020b959677c1c66e4cc65dec7f13a71f51e021672b63182e302bfbdc1c1e8b1835baebdda88a93043c591423b41b4fe5b362da91104e5e8302a7008b59f014bb8cd7070b488744ed4057ae080ebb2ef03f28cdf94a1bc44da6c3c2fbc89edd34b82a4c7f2152cd7f9093af31c78eddb53864da4e6586ff4b8d6564a1b47a34d7e94b7bc7904b21893aa9bf9ff89d96c6535e284c9b2190d2be27ef67a342acd36d57a8f98013f898d1223896aa85a553fa05aa3780434330b2a8f5282ef19b3d40054dae21583c4647fbfa5770f7cfc0bfb76cd321392501636b406209b4aafdcfacaa86f5405fd269e206fe0e2fbdb3bc6682139895bf80904b82d8d47f1b2925db1d45d1e05b2252ec8e436c908fcfeef2b210a7d130eca3dbb79103d351f600fa439e5ac31709413690464884d3f4dac44ed3386ea9447e5264baad90f180e84df744fbd00761a2ed31818aee1ac3552d877acbe997b37123d2b34546f68796842b8ca457bc8dfd7ac1211a3b7e1ed2212be4d513b29f901de5ed72d69111dffa63309ea103d9dff9aec4228ba68f57d1ead10b6ac6da4c886a6580acd659b4ffd9fe4487b6a8c169fc8aeb6e2aaa1d37d90a00335d1544a8609a9852706c06754f411a6a3a889598fb65135e4149693b32b3f14ed5e35a1c84f488ba8563eaa1b275189e93e30203a822129e1a4bdfa3d1446d71ce60a54a18fad5b47f82d61385bef18fe06657e5eb9a0e47763428e2042322f0005b5a09e726df6c63b52910ce07cb3afb6a572c8a35d37ba84a8f769d13fb59eab640eff6b29ef74daf30aaaad1551fc2e596779374e8edc4db11b7bfa20dd5526cb1f7206899cdd1e82b39c982d471814020d0145995aabb7d6ce89175ebe4296d62a50605d87cf3c3561db345adbe938324f0440127c3e3065727c87c597230e9d61ef2f3d2f2ae54bcc400c25233e99b69163f89de5a20b669140b1cbc3ce4c50a71fb87c58fd8700f428f62114343edf1b5e3ee5e0d29f8c12c3089fcb6d97febe5c3f7a7286facb5b0c051bae84547cb7ef281fc4097b3243a4f6f88096e0e8611580e12ae41aa2d546316d157f8c17c18e2968fc160aab26e4983c7ce80a68032fb594e19fb1f3d621af29e5c250ff5ddb034a33ef8cfb906f729fc5aed2a7f7e29ed5eb1b5ada6e3731be196d0be72f2e35fbfeb8e244546bde734a5770108052d9522b6f3eb6bb91cc893d007d7a8cbbb6d5595d142b6c106937068d90b5bb7653917d849427b6a97d085102821ab070017d959e29b148f34b4462fc144675a2e7297b7ef3dacc96fa9d8d31445ef808b65ac7629e40bbc6019246884692426763d5c2432165323eff8fc93c9c643675b741ca0f65947c92f99b1a9d0257d544128684b199a55df89578648c631ade62f0981979aa59ba78f7b6b62b06efcd7120703cc0128d2ce7d6f6265b50be1b2dc9abb64c8b7db560f044209bcd2174364f725fc70ebef7291de3b688f31e7d8a7fd3d267c6c8135d423bda9ff9ed9a66ec51761b93b12f55b8550be216582124165797f0d979da8b56563ddf1a9f0404f549382b8b0b27fcd0c080d61291b8cefe895f366ed9e48a5b59c0bcfcdac515bcfe5c6ac5d2186ad5b958fc9d3da291bbac8deb37d41df18d0391efe5dde7c3281a867abc211689bcdd10277263a6a47bfff3642920a7be89ca461b91d7a1eefb43eb91001aaec05b15e28274f4c1d5b64f801c7fd2f09b95cb8d95d699ecde54e71b99239bd16a82892c740e162d2a492d8ebc6692eac96de581b9227e7b8e07fa77d8fc65d0941b01755b37ee5e284fe8529797fd94f1ec4ac46eb81215f7f7bdd0e8c9b2ce425af2d9ce2f6ed7f28da7baa2ceed7495158705b443c9951bbb7b8d24403e712e0683cb579e75845e9fde1c9a334c9c7f6376cd703f5abb15cd1dbb545ff9587b4af91ecc2cf028303103dba8ae8ea7cd3caeed9642a4e31af84953a7f81b4e6db40833ab92b5add9e08732298542aed477dd0cd6111bf392b46fbb143b346191249605330e5bdd4edccab941c92c28370235d154d879682c9b99a02bb81224a07269fa9a977a5f47ae33874f471f521308652eb0e11dc4fa20436e8a761a5d8f5f224754b0d8a29a0b110b64361ceab2dec68eecff29cb59ffcdd09776fc8dbe04e9c76263fed5c943d2ff024beec0697599065ddef56c76dc1b70c696e96d07a69fd695d8d4749d29be7bcc76dd20b6e4a2f60e7603f4d03551ed134d658d3e3152ab4d87de5b7518f1606a3d34423dfc428d4fab330860e5924ce98f3a79ddae9e42c3494f4a6595068165e69537d41c6d606456ebd90a14c42d3ad4791b7e6892d15e51cfa2b871e0c956c457daa396e53de1a9251e590575a85081e5e2394a24bfebbbaf61eb1cccf6e17f0a7d60d81db6c04c427218b8dc2ce633baf6df42f4d341ce75af9fcea918eba90fdeddc4a7807102cc2cc7073b02f1dc25196183c2d47c2f41ea2abdcd9fe4491e6370f019783c2f0db1ac602ac0fba1a2b02ce75af66c8ec30f226f796eace4c7fff45546b718f9b57aff69b2d7cda29adef9394750362f30638d2f8c36885e4580497c5b12fa67eb73e00149b127dd9612bf7d231b4ef7250b9a0a56609145f7d8cdc15b4c88da329bcd360033295f3bccb015ef3cf50a69ab24aaa1a08234eaea527eddd8e84b95df0270dba59a055029435b8e450e71d786587a0ed868088874f64905329a2207e93885f0d9b1b2c41e576741a0d8689fae7f79dcf5fefe0d4a510aaa01c19096510d349bf6123243c7003fdc801a911a17a767e72f7c652afd6900dc7c36d305bec0f7b0b6dd349fe05813e13fe96cb0582fe7028654465e1f6a71470ddb6535e864229985ad44258626b30cf7d3eef9c432fb7a2491d90faa84d3d051a2998cc03d5104a565439ecfb5f78feff06166ceab51d8d1ed2ae47c1610adb159cb35dfa08199fbd478375f53b51aeaf379a635e73d728726e3ed30adb625078dd52dfd4dc75d0d4ddcb1e51d46e3b39241a0e8b160c96d1c590ce52188badd0b0b93046227b3434a6435d8f439d94599123f45628be4064da6beef381828e8bc919691f71e2791220ac781ef1a26b26bb01169ead63452972137282bb96275d00b7894592cee0965b2d0379a866bbfbba728409cd90ec9e8d3503d70d6787f4d2ce4befe2d9d16b8b3ef4010a9e84af0a1e17068e3abcbb45c60d659ed614576095abcec835082ad048d79fedda670c11ec112a58d151e3f1ce6d092ff7b2ad1144f4b56b8df7c5544c660c7f4f0bdf1a44850f637f467777a5c2733456b8d1428cab21ca1b92000b8cc09ca946d556924b05cb336840bf737ff8d496146daa3617caee209b9a38a5f11bab4248a5f31a00de1b5c2e9cae3d73ba1391b5f4e4e8500a2104b1442d30fa0365ef3dfaca7829546367f803a821dac82cf0c73b955398b0daff7fb29eda87540c3f56dc1453c60f08b6d3b763101928241074088a56b141c233cc9b7c4bc53ee27d65a33f2dee647c080fe6f3e7a8f92514dd7f55a33945d523f253f5101d2a0e0579273ca59fe47e5e8a91569df1ca82949bb2750e1ff15936916ac9b1903717c3e1e29c33d2988623a4363993b88c772dc8e2fe29710adde0c816f1f0c1bab62d49325d9255fd011c2b4cb1939f6584fe5a5e285b5aa6f4dd00e6a5362917f7fb48a85b4c4a69d2dc54e2e8030570c0af6993723f5615f3e2f59918416298afd4651490502bbc02a527bbba2d1b232b0f5bbbfecefb3a809427a770ed6cc9b624d05144c75a84f4fbfcfbb2ec284e7e59bfa61c27bac39177afc1132d23881f013aecdc0c3cfea7bb0f1a5a9d310e9e000b76c8fdbd39d65b3cdd3f8c310ea9cf07d4007dd00a7e8c98cd4d1310f67a1122251d8555dc3ddedebed5af0f6baf799375c1bab3bf4eb5afb4a6b55672272f22ac9a60c5c1c0ca8949b6f11b8f10786561dd2d45d2fd2bf96284664443ed7065ab15b3eb8730230f8e81065c8551fbc13dfdc72f9514d3190d69ac15356a4e8c9bc79a3bf0daef2838ae29a8d95667b926b39e960489fdc6a1ef76e0efc5fafb117aee10e01254d1203139021a5ff50b3648f6682fa840f46b41493986e085abcbd8902df751d56b59805086d05ad1c380ee64f2a3b10bad814ffb3e79e41720dfd56b922fda0bacda87883c5ea3b448e4d306d2f0406e1aed5447d79c0b0eb85a7bb6f81ab00f04235f6dac8f471686298329212098e3ada59daf6e20abcfb16b69498ba01df7dd0a51f4391d8e179122c24f04801499532244909d36b6ab54a9e4a88c09d9e0fd060d89cc5868085dd96199856bb31f8efd375ddd2f5f145d9d1663865138af19697c4b559196127f271dca973b5491123adcae4043c101637c1ee2c728b88901d3e7a5e4910889930126a051c0dcfe48b1273ae14413cbc7461947faeb76eee5663fc36851b81d5a4232c04fff4b107b0b27135b9d051ae7de8f0936672612f8e8210e1c621f1c49cb20f903f8966b0635d735e83e6ead13f03fbf89142d624b434176c6f1fb990f88bad86d199f5cdcf429c1fbf01ccad20e10d6470222e744f84b37d822dfc3331816cf25da0f229c791b84c554307661761f80843020fff7316d367496366f70858f20bc6a115473784173745e0c1974f35fbfd959264dfb8a393e0079ebcfc458b98e0444721c90de407d9b7e8a7d0e6147aa6e2eda5d12069bd82e65ee397036937a7eea65dad66f84ce411b1e23dddef2aaf621cb4085c53e52c2f5e5a1e6f6d3e00eff2a16c1a500b7eb492f2425781f8b68e179c25c9ffc1e5741a3abc773cb73955ce8ef557c2d7d616f6763323eb7f5c43cfd814fd4ed192b027f7d7ad9e434b5cc78021b3c43287f6c645b8b9b3506737e642f79e49107db6eca7fb7fcecd780f85e14f7c5d97719d4b1b905a21e712696766cbb63e45d9ac49345a4cb939a63cf61c2a07238c72a7a7d48b9219030f66271482f9ded8dab9978b308a5db0556b5c9c36bbc487523a373ca953d8793f9e6add0737d7acec2cc27d957d7efd8260c57a05813d0de2888a35b4b2da9adf710bb14527cfe6d52b1ec33489254927bee00985e6158d773e8054677f1445f601067de16af12e02852453596faa3b29d9a921ef308fe989781a1ca978221e5c981876594cb3e4ba12ebd5f265625709e2df39213277e635b09178540269b0c3009115e3c07c0e48dd45cfcc95be4a9f48971172bc30c10b4f5ec24008174cf8570f8449ce98eba05c5b6f6078bc1a17c3ae8a4ba6abe8be41446c1f631a09691961574f8147639a4676928e4f17cfbd51f6cf4952f23a1e6817f60fc6d5f69bf98c59feb24d9e817089a2399df527462dfd375cc8275d0fbe08968e8b136877119a833b082a2ea2d8afde38e57996b9fdb3582cf403e28d4d2f5b014a93a08ba5cf7c19df6600d2d4a7b1e929b717ee0998c7a0367b548af66ab111128a8f7d604d8d7eadd0eb8469db4fba6c273aba2edfaa41b2257285de6224ac63ea29eff77ab2a62b0c0e56c34fb09210b956ea3135ef842905e8cf033927a57440cb07312fb876c2d0c3b7b026756f9104735345fd05bb13d4f21d978f3f449d40e00ee4bca1380c2765188a3abec7520ea878f258dcdfd759005e39698a4751a8a0a574b01b4902bf3bdd2e465d236fcfbb04ceadeebb6209c0d42e14664c1de80d3ce65d103693eb906039d49a2c95cedbafdd0293949b7851301163b80ae41e30cf30d110b5bd3f94b3739c3de758a176e87b90ba4155512ad3c3dc8268375beb95c1362a95747022aab5e2965393787478e6db794cfdfd12b086062444c21e97bfee92daf0be4ef377e0d4a4558f88f8b73e9be82237122f0aeb3792bd7bb5cba39a1c9fa51e988bdddf8b1620289238f72901e1bdced61006112d1357623c097d78ac0e47e3ad78fa8421edebd0157bcae51beccc8cb5ce969cc8f006e442b50a121020260763adb6ac11f642c4989e5060527b707b3c35b8dc6feca5a712590e241ae079915807592780599e33dfab0d4dbcc775a28fea928b8e4a8d1eaa43120ed8427b001a6034ef97ea41a016cf202c659874e4e6d65941ce3cd586afc9233679a3438df88267e0fef63d50a58e7a6f4c4dcefb7fc83783feaefa8213ef8bba0c4b6ed067edb626f3d34366bce388bd9d8b42a2df0ceb05774b1ebcc85543a0deaeba1149c7122184f80cb2181315145f7f0f50ce0c1de138315325aa7f43be1da26be50ca0a6003b48279f0a1c97b14b664f2d13e94cd3f05eaba85ce3b75efd9f14abcdce5a5bc2fbb32a2fb2eb66fece2fd089166f7475085ac2d8312dd0c85bc9c4357406cf1f4ddcae9ba1f0eb32597b3611092cb069cd476ba5ef8c06728d06a5d882adc76e339d67ef3507762aa21e557064248848572163336b793125f784c88f80afd2283b19c6a611dafc97542734132ecf01f69683290da06dd434253175ef04c7dbeb6f48cd2e1b072da6fb98e736b8bed7ee71513fa168600fcefe9694254409c5bb1d5ff2933b930c5222bee50a3f7d913463628638bc6378c83186ee1d6828cd0de2d50b086070c970dda9abdfc8358610b532f38c1d94183d20349bdb128dc02cbd0cc54a9b209ea9b70a6ba05298589ae9b73ac6f2663c7fcb176fd71a8406ea0ec8c5fb15d5c9771b34a50e8dc155a25cfc2073e4f46a29854bc956601b52f1b12c7c6eda429d8589aa3b423829dd2bfa22ac2c711b557b15c1440f6038b1a7acd7e90c21cb42d30f674225393aa5021f6bebefad739c4e5f27aca10daf1cdf645eba6003d101771ba7ba73779620e9f4433be9550970c3e0736949c5e0bf4d91a5c8cb52d961409a0edec6a885be8b944ea7e9b3778e08e21a03be43140bc51d523f1497bfa21d301814bb1750183852290beb054ac3a7aac779dfcd26fb842b60c33e99a1f8730e9a1bcbefeb221b3e9dfe4b270034724571c83b758215cf3a9209f1e05a5548caa47fec3e3cb4b63a08100274826d34774efc56f4a2a18d1e4dc8ae3b2bc17a19441a64a3d4fd493facf03f6a550d7cab62d90a75e02c8a5851a18f84989352b1b74827c3357cfd1bc66b19877a280f04b49fbe9354b350e9126bea2349e7a7ffe29ad9e2d246cca2ff631705134d2331305f0cc6fccffeeced4f48255a44cc558a3532762a2208caea04250806fbee063334f6a6d410fc7a9fea3d8d3982cfca9919d979e8926a0d55face17abff148b9d86e75c1ef101c1f3d3679ffad492bd029818551a25d1d7f8acf5190ad74d04e40a1e14574643611144e81adb00148326a806028d0e49b35961ac1f7352399a58421afdd8bfbf3a210cefbf3befa31251d7053ee0ade4edfb3f3070e18fe477e7c1b92361033484659d0c02df4e4aba65ac65fb66259637537184e048ad1ee1502a768f1beedf73b156b795ba15e6930a721ae54b2ea516e844b40a4ba01e1e658dcc1c304beead1f4787ab49dd1eaacf072a1eea4664a982c1e9ded51cbe6dad2f4c73935295d8890e0da080c20a65126fe271267bc5f5dc402e5d2d40b51bfd0eaa8ab8d0f202c2382d19910e8283d4dd27e266899c1d3434e1741acc9323fa66ec64b73008ed55c77c7104769aa0d742d6749f6ba4fe003450b26c485e2c250ad825ddb7f1225b897c5342242dfb1be65d1661a718b56fe71b004405f86709b90a0d3c220112dd0674d794d12b2895dd8d92794ac5eeedab7090702139ead31ac051643173731edf33ecb8f0908dd5cd97f2ca9015ad53439f78c41d8f53fc8baf42950531153488c66ca2ec10e8c0c3d1dc0b1e7f2644912cea3431aa71f907243428172611d3177b12a5509fe1d9667c6219d1827b85d2436093d10892efd2c7db94cb9ed632db0fe653f66f0c63edf1539fed9c40108d33aeabbbe5390981e33a1ffc373619133edceac0100991208fc6d7e6aa07929fbc3200435ffb0c088789953f0a2a298dd54829a511783e7247c22cf4c55f4ca99d2fa1ca503a51749937c7b39a740ee6d8645878ccdcef2d39fd9532184a9c253705995c9855f5946df3f4ddced44024283d88980ba36b260e9db98f1ac812424e5f4d5d19e2e1608ed0708d5d1d49882e9a94af51b0a9c3c293c15e77c23d37a6d1d4fe839732e16c4079494881848b5709802e46c223ae92df02130ea919891ad37bc439171bc91d9dbc27484a41fd105565dab2dc3c87a206d3671ef352870645d4fff3eb01fadb145e8aa499f4b9aabb1b85bbd94d77b6a3b2d60bc6d7ea7454064c6d778730718e17a239d6c22e5b432763de02b7408d2fa2975964238707d717c11c386e336aff7edeb03b46b8cdc97ba9c2dc90351aa8e263c36fe7ec26224e28b5c9e27eb7395218c597481ec444ca6d2edbc434397a12ae1254d1ef47b51e228d050fbc70419072f668334f45e6a9ff877edd4c6d21b77fab632266e7656bd087d7ce51c31aa927ad5d5f156c0fb2811fd0e698ddd4e95c13652713581ec27c7f50336d4eca2af12cc34af960d93b7d31ce464e50aaea359609f12b7e174f7cca67917ea7462bf287ef7f7949001c4a61e5e81d71a224a87ba58d9d961f51f088c6bb199e71a4f4e34a5d68561900153bf5c1759adb146477cc13ce53eb25cc69ddb1ec9f6e88927f3f8a8f9632f92f275213ea1af3ab35ab3d04329b558dff81585d8e1d3ccb0d0fa4965d798d4ca9c99b10cb7e28ad9f2e52ccf6a9e81dbe97d778feaa6db62dbaab59399cf2c219050b92d5e06e30898cccb62248d0aeb19b267db23df153844a966b3405cb8599831d48e52f3b92e03aaa1f3ed8f58041e71e13559ee2fe6034bc7c7df7b72ccc385b8140c5ed4efe70440d49161d825efd78d17f3bf707935b6410add425f4a80afd076b6152944cdd2ade808b8d693dd8244d67adb44bb8d76b416f096cee3eabce4762fb56d887b54791e852f44dcabde0202dbe43e41c48fd83b3d5e538063f74771d0792984c0875cd09fa423603d536fd38dc4f84832308866096cffa2b1a4492245afac8a108cfd13d2541e7d04da6290bdc3a082214bbe66202930b503aab9ef2af1fc7113f2919ee04c838991d56092b615d8503a5040f19d1138aff9d36bb9e25154447b2028cf9f5478fc49805f2eedc9e95d6c0a992688843743f379f20462978d9ceed8c60d5d9bf761f2221b4eeeed154e1386994bf2e24e3efbb6850c11116797ff6aed48e8e849caea3811d03fcf8e172094ed760913bc9f46153bb379203cbf52f75897c112f4fce5c241e6ce416eb231932368cf44cd9bc2d0ee680f71078f4a41612f111f0f152faf1c3a247804da6c30880148ce583c427bb9d166d121ff70ee1a372d0b59fe5afdf15eea9357e7c3fb4d6e39e82ad35f3b7332102cde6c7ab238d66244b21c033973a0938e6656102cb8719ece79f52a2c68fec7d9102fd93f6162a7bcdd7584fe12b1251121c0d0d0119f11405f20788288150735d2f9ff9c542a4ab40e2e1937f8a181cba4ba503ecdcfc57acb43afefa5f8a86a28ee915ee91ca440ecc9f40ca82554ddedacf2dc07d080e28eb972a71c3a1f44a8ad106e066f2400ad3210ca649debdf53c3c643be62df721910d40952c3eb63e315732f89d1df065b9afe7b982b281ec1db2f0d41a0dd6c30599f974774adff355c35ae2f4af183b277babdc776242294635a25879d913972ddc0764dcb5569828da077fea8410e717e90489269fc2b7a48ab1a537a7b097454dcf7fcccd731d4e3acf6e7a58a84ea3d5bac3b23e0f2b225fb733bcc57801e78597724f321a851183c749b5cc72f6e38213fb18e9b1612739a61aa8be3d2909b77ab23562c5ac7fd9d562b20b35474306caf72aaf86f29f8c572e7c6d47db193253dc22dd357f135d1592063462fb9deb33ef5ed9ca91a820234450c1087d5c3a3f1f194f274ca9e8f6e6063f1d91974aa0f8db5e981ffe8abb15dee73a28a0c4744df0d6957957407ab16a2f81f764b9c006d00a1fc3c15c7e6534692c341f5a534223972c7342b0451467d770c6eb25890bcbf8630e36887588c780f5b0df55afc5dd6110301666191084f46db188fb0cdbea4f5221df8397a86423c4d4c3859734f9da709b90316368a004c3bc25b4ad6245af1b595e39699e850e47f70eab4d50f102489c1d6ad22ccbc04e0071355dd5b0a4cb9e6e16292e2cb587ee67e5310303f846e0d8c09a64c4fa77bfd32bb264c99c772809da731e0ddde4d739d77122c0fa8d8a5190fcf62485d84d196436409d244c747e18d11d2b94585c0c0e5dfdc35719c07379d1e19f7384e708c98c83baae264af2e039a0c621e476ca678f1fdb578ab0127bf2381b0634bdb7f07331482186cfb51b73750a1e290b5d594dcbd41e43d002f271edb9548436b411a9036e9edb9cde5666657f60269b2d23c4f7d9a8c5a449865c5ee33ada152a57e7a6c77b591f5e97bb9913ea1eb4f17b34028a2189cadbce72392bfba55c7843d7abc68056b7415b12bc60caaa8430f8ecb7cce76ef9126dca638275ac02cc2765b0535798d8076cecde0ed598a69c407a52cfa88dca78528ac2ed8a4decc891291fabf5fdb1cb53fc61e4281ed7d53c6322f727cf8a8f6759dc2c583092f8ee91767f0461e750901a879afec06eebf054bb42075a3344aa0b0a4436d7138ffa107466c6ec43e786b25b2dc3c3e3eb975fde775dca3ce503e13ed91334390cd8acd9094f7b45694793d264783ddf0cebe98d33f2c2d50a13b63064b910725ae9bb8731c84786f9c39aaced00dd0982fdee3b955b99c3905ba4472e4e109812069e4f50b90820bc75222216dbda55d68c946a45c0e13e55c6683afcbba11e5c4481523434ba2c8fc752aa7bb9a08925993c20373be6e51172467bb58cbf481f200978eb5f9d50028a561705e2d3bd244fc9028ae4cb7eb2648333cfefad9a4ba5d85ff38fedfbede799c3161db294ee77d348d593fa682af3556a744b14e493c667f02a3ec517e139bdcb87a4a77ea73e56bd228cf32c5a70b9f8a89d517cd76d4842ac0f3ae717b36e3278b6d97a9b110dba9a9385a99d3a460678150c9b8e88e128acecbed07763aa1571754ee738150bc64b1a89dbb09ccace004cc6ee0f965f962f5d96c7e0cf398432da744f3bbfee3118ef846084f850f9f5a2a54a806637b7a4a89e418046d0d7383caf8ac85cec4303e1e94bd0886084cb5435b53c8bcbd45bf55f6b8e22df0c641f482616632990fd410e1447ed84d8044c73f3c9755a23fab3120737bc6ff666c8d2f3f7d96a15bdbae428a8dbabdb3aa2456b2b81947c890362bb48c104db872c49f793ff3ed2d8161ed5f1e52e891f784a53e88f68921dfad26f2f69bf2ab3652a0b0243cc3a5462f9f6f1916f89e49095c6b403945fccdb10da4cbb2f920acaf4a4f38478ed1542f0a6116db9da41eb7f65c701b22a6944e222093c5e92f0c565824ef3c1b8eb47da144e82e4be3eedc3bc9878ce54c7a8f5ec4ddd0c53153e42e4def02a9412ed9389e68ee1c7baed5a8c1ca61c0981b118866264388a348b72dd91e812e467354fd3095786030ba10a287944893bd176d47a464d45e37f4cbbad78caf3b9ad0c0647c504941750aa98d6cb115c3532f4cc02dee481cefe33d1495b4e13befe55dc90eff4652d37a59256c9bd3b656df03222fe6b981527d085c3332f600e8a2ba89edb76a07dd72df61f0c0bdf518b28903146435f1e8bfda05fe1f3311de70843c88575352c5955bf2768cffeb7299c86bd0e6b2c85b836f25585a3acb8130d4037a630bac4f1e50f211658c5a16c0e1b76f61b42acb403e9447eb0c0d30c5ce396310a6401c018d53be3d76c4a57650f817c87c762c018179fe968b1201d5ec0b08e75a26c458c21951f22e05f460ed71c9aed316ab7f25468e69c29be159445090bd4687c581cde2bc091f0c30a3f15ffdb0f201b092c4b1ac13074b603a3a0165db89aaf3f5b174dbc88278bb67c322cd4ee60a0bc8ed34afd4033082a60f3ed089bbce02dacd4fe34314116c75ecf85688ab49538054ceb70116455a698e70c0356bddbd39b853c565d0ae994d04373941f7057872f5d76c24aeec36ebc0a4094dabe02bdde4a5cb35ec51c3ff31b2ac5769d702557d00d056dac5b011ec9ab6869390af86a2b533da57574f336fb25e3947b9dc8fad3911fba776f4e9acb43c59268788cc7d3d57df8c377c77cf5adaf7d7d151c44b9f74c54970337d0578d1126871128fe98c2e9d506be52e9b8a0cb44142cf8ca9cd65a31182876b2b675443a4ade28e20db8a4ff9026bf1847e954b7011cb0ddc211c8a14e8915c4b8ad3bee2076f866bf6e15f41f6961ba2d255ba24b1297f95d3c520a9bc205c7cd840a2a09bfc1260dc07dbaff2b458ee6484b4879defb4fac4c7ba1b10344c1b095e1e849807420903fac27d6b3832e3b1f0839406abea95ac91194fd7861f78b541c6a5500e6258a5d0d9a33a3c2dd720d432165672e35ab403857f4d7a3bce476a8413b114b020cc9e5a52d0c9bb70049378ba8ffa84deb478090732b63fac6c5e055649906cddf9d4ebc203cee8c64e26000aa9e423461c7f8d53fde104d6c36fe85cb310af8affcda5ef2bff63d803f4fa2e27aa6d2ddf3dbcd0a4743f91b5a51531f5811dc6cedc0b93e31c8ecfe175f511c9bf54f9bb5b31426c76e12bd61594ee69f123f3d424d9f622131c4b1499a96f0af48810146c0124ebd26999b670262159c759d9f28f233beca11de426382584bb4f0e0e1ec80de45be4a4c76a6e0d0b9f3ec364db70f34073af2ddba0418b1e300da6e2da73892c8c541d55025daf93f68bda9b883af9ad7dc2484f0cc09c23dbc95457acda6975ccd655331339cb022f33de3381248322c38c21e8dad3fe76e263514a7939ec8f591584be45917f86d372ebf7a6f659ca422c84b8fa1f015070f8ba196ccf188d875832150ee5d0847cab9edc221f6979b76fa3a4f96dd2c719a17cfa8bfcab05f053ee37088c47b4b7cfc27390470824e6f2a8f10bc509604d7ff199be27fc07aa049780aac48249480d218c715ea9e3234d8610004403b2e6f6f27718dfc33318f32c5ad8c6c5a776426c623dbbe34b69d59f6d17aa089d90acb8c5a828fd18ded578dfbf305c6337a42a04a7deeb417946e7a270e12d7cf2a36809983ec679f14f5c73e78aa02de857fac820ecb76369c65c3ad112ecd8c18cd7d1b77bed6c929a7d2074f1932be85472b6e58fc8c1e03160e63f43eeaf4f158615f7b4a390b47125694548cf7f7cfce0c3163cf88b55f20f42ced38a91d28d60a4d2237fcb989005ca150c90ae2e61819a2917b436c19c79f202015eeb72e731e3aa53b1c7fe9643a6cab0562980a3cda88f7ec08eae20820252eefdaec1382d91c520583bf0d388be92a29a2393569ae0b60d1e0bf3392bfba08795fde928c04eaeb281a965d2f21fc7acfcdea9f4b316a5ac6f967501c40f6649e7c1e931caea56ef484e8371687a22a1e1ae0c8612fb45982cf900d1b8502d3945bd652eace4b4a9276a04cc6a6ec3ec7412236b84af93e153874e2817cecbae3d9ae992640c88aa262294aa43ae4a889a6e0af2ed4979ffa4c03d835708311e85bc426bc05fd9a4827df9767d353403f2a7fc1c0b7f6aa2a12a04ddf3577c89988687aa02eb553d861deb36256cf78636dcad3fb882ba5a527d91574deeb2ad31ab7b0ba6be9509d8a66cc7fadb0c3c0de2f830bcf2a232656ad21a0045d39e3a5533e4a9fd8249a75c7655ea92ad7a5ed8acc738abe57e89b5acbfb18bbf86bde5628545b66dbd91eebfa493ae4d97da56be8fc78218549f5715e40be24e7e199b5d75c018af3737c06a9391c20796d9968cd449a46fa99c3b042503516e3be7c2d50610dfbc200917f75cbae0fa9d40c5a2d6ee1b985ff4b908224deeb1825f6d92c6f60bfbcd6c7bbc1c9c07562a12a7cec43c491297ee36b10f6894741e9d0bd8fb3192ce588111dc91a42015c63d4adb9f6a58b273f1a46d1f05f8e76fd5f0daf6ec6b3fa71e3ef9460e65613f9ffd70acbd5e75b2b6860b3fd4dd0fc18fda10ac1e873f91cfc0ad8dc6a87efd4032f694a94c1aa305af0ac93fd06f0f7f60a4ab1215883b774b1c056060b18b962e5612e1ede5644d406379878d936111f9809aa6cf0194c8f47de20dde3779a7d4d01f7befddfa4247f6883f13b688438f69dbdc445ac13643b7c8f5f66cd257c35bba46eff3fa4791604684ead50f24d4526c449c8e99efa0e0a3da7018de80f2f34997f102d6d1c436f74659bcbe3368c5f24a23cfa5e13b28d50e5cc2a206f811d64b6161f97ce281835d55c1f0fc614d7b14243b480fb2e06e447ba5243e9c9e0ea632c9f36fc129a137f04ae8b01cdd3fb0c8a0cf8856de01debf3c9f5b601d233492d6ac27f8424409c6d3e2150a409505d727193f4f99fae3892f809c8d2ccc759c969b513c8cb610d39970a620f53c9ae2d2dce2b3e80a6249fce24c157f9255881ee99999c0381a7f3f8f9d26b57c63f944651e56bc52004634d046776073ea0839c6c4ee48c88501f4f683b9d2e138d65de8f743945826134830517bd0cf39259324202de1a9ca1c2f3c0ed6b30967bc61b727cd28a9c9b36a8fa4d312bd61d293563352073814bcf7bac07817cff9648dc556618cbdc0849018c1df79c82f499c72b1711c8427c9787fc3967b6db4a32f44c9edbff77391a46fd9f15d436eb231298045e61370ea1e426ab27093781bba71b2a015e5ad64044637a79a9f1f476f0587ce01ba103a6507295632eecc2081971885aab4d1364817c95c3eea551fe108c7201345ca57882014b403ad3348da0e476f5c81ac5ee5fc3578bde6a75295fcac9cd5e894a3d2dd3fc600d44f2af9c53b3cd327fcaf6edcca2aa5bd8add6d01ab7792512b46ad967cee94191ec97f5544ac3b3e5915a7eab94b6e803aa8dfe7348f2956aab4f8ee267ee1cea8853b35f36958de54fcb530ab54cfe17819020c059644239a95dfc6d7d53ab0dd132512045d6a43df3ddab32114e083a32e653460e10fac318087bff9eb9136cf161ee095b4adb502f8653fc3425b20cf75a0fd44ebd21af1e0eb3837308f2997116f27da37e21b9e6a8f5e0abdd471150bb359d23f1cdb2210985ff3b4b26170d60008ce98bca1386ccdf2ed14d950f2f9a9a79ccb4d692c4b91e74b8fd9d479135b2df2c03dfea8ed6c92069dd0170b43f84c04bad3969a549b57db435dd6823759a070bbbb0a296e193ec2ff9cc85c24249020f2a75ebb961550633be07a7e0a90b4f675fa9cf265fd6580852a2e73f920b2166ca3c5ab951d326906b96e111d3276ab32a9129a83d9ec09404b7cc14efbf30c71f7b86103aef8bcc84fb0fb5a50eed33e98eab7c992639bb9d9922e989dd78eb3f16576e6d0bf223e6ff22b62ad004911124f67690f80c8696eccd7916e1ae4df1f3425dd11f4e6c81b19a9a117969c405e2d039a452ea13ee4d0edbe2154a2a2bdfa88b8bfc26130380398c5e26b44d0f141c745cb9b3d5520a16f6e57e8ec9b0d0e7a985d04ddffea7ee86df73b5abab84a2499766f0c8861689331d4cb769bede13b38026eb2bbe4882a1909ac088bab49acf0e5df29b288c299ff68813dfd3e35e78f4a7b980d07797d1ba6c7628a5e3e801909e10649b85a7ce623dbc7b3a5293ea87d14672beee7ab566c2b047055df7d63ef19a22b3e2c89821e1b5508e36c0fc30e4f484c5e3a7ca5f38b3cfe2a7ddfc43545bb531a811514fd3bcb2c6aacdb85354101a641db205ac9d2bd3210402427ce79ce40cb03e3780c70a2370f47dfa72df84d42d07227a3e294efd2b112cac97669467ef9d468b1444a25924045d3aef0fc4054f23c3a03226a1f89772f62aaabb3e76ae2fae5f8e9ad9ef621a108080a17f4af2df8a7a8c059c2c1bd25369e5bd2eec19d20c5c20212b629b04599119cbfa65542a1dbe0cb7f3c0a20fab3cfdc6eaed021c34cb277ea612c3f4e4791d5f223dcc4fc291f6913c2b0910756f4de5fbdcbb6c5f91f87ea450d1e3e04af33c66d6e631343cdcc23b8c8c878f8b710e7bbedb02a5527062080a17759f5605cc7ebe26662685fb822379d2cee3dea5680ec80141f0d1c9e078536220c2ad4261314466c211ad934cdf8d459e94a20211fa05c9c05f41022001471a4643c26f72a05e31fc00c2bcc98b505c90d733bbfb95378651c421bf79cd14a530e23d2c35c3e75426de510887385697629ab570dfef2da8858f8133624de84978e7b71f73e3db1bcf91f397511ac0c252225e322d09bea87e80ebaec5b9bcf5c05977849bdc04d1635d20e870a94ffcfeb6def93c6c0bd92dfb577b6e5c79223fc82794f2b41466a4445c30bd36da72c22361169377c109c9abc2e7fa24936f22104eb2da128f6189fd085d5b96515e5849c049a40c662736fe35f30e23625d0b736266709dcdb999444c5b16e788e2fa31ae3781939378ba9d74f7bb5614983939f388306ee6396b27dac32356b5e46ee8002c83c95deb0dfb83bb432bdb51387ca2c8f9b613c336f39b9a468e2c5ac74e52b5b33aa8ad6bd437a05ecce5aaa42ad6f2c8135641b8e67cbcc451267fc00b890e9858a1825bed2d0efbdd2500c92b8ea1e691948e4fc35a03d039a94eb92b143ac04cb2b48e65f26a815120e13a62b3e71264bafbd3c24d1794565b95fe45b1b9741407a489f29aed70fa7e168dfb5d5f193dd8c67d1f7375093edf4772b81a186aca7afdc4847b76937d392d044685919892109ee4891672942d29fadf40e8605acf8171d595b8c1e14e0119a85a9000b9c50cdef814c07947b4eb247c077a8aa0b89fb3a02ca2ef856d1f0fa77c2e05aa28d682d6d6728951d23e7d13ddf798d933cdf4dabbeefd05fabbf433233085cf53eeb4b824ceeee00bb4f3daf2727816b31834b1266cd69108342d7bdc1ea36b00e843869cd866e1e07a4687ae89d1370cda29724ae2dbe07915ebf0e2a91662b198a56f2e8f6659f49704c1688e9b869e5ed6c6ac66884316ece3b7935b2fa48673dd5e12c4c369467ffc70c9246c5bc1e6d04538b15828dd993708cc4e471d7d7b16059e86ac4acb184c4d947808107d16c0356a222ebd945e6804d9067a3b717120ed61173d5ab03c9790cc4a338b1f5611b27975f38b230aa225342f896f8d8468c44d4bf1db5c5d187e6842a94a64640fa1e2b9a692e54c6a51c2f84ec796c8befcf55251e46ec51c3404e6a29bb5203088ec7b80c280b3a5a299ee3ddb80c7568eceb784f330c559245f4b41644dc7d001fb3cfb88087433035ccd2988ed3a31822d5a463ea0cb81f2ddc160fb7eb6963173a03edf285701e0e1386b8aeffa51f7914e652abe070c4eeab9e1fc7b986a7ebfc3dec885f7cefcb5739998ed92c6466891d9f40e258d91a8bed7f2167d9f46d70bd151a4a39b6bee495b35b13b8cf9ef0452bd2dd937803d7cb68cad639d27d5286c6f7fc5d8a0330f12598c4ccebbc506dfa40ba1119f29bed27be783259803fd5687c184e8a9de2884861188d7bb3cdeb55f7ab8898923e28d044fe11a0a13028059dfc280d1d41a3bf206af4ceec9262d87183ecd52722413abd692b8fc9230d18aa9a931439bb50f65a9a6732292c542a5b0d332c35baa5dc3ae8e9e5ec78d77f1d6b1092311ee4368bd8ae54998556d35c88a03dbaf9cd8fae891afcbd8a2874f9edeb5a7b1ebde27e79175a0fa468dc380e9bef20a3593c7658a8ea2aeb46b8564d0e4d09daac3622eb2a4ca485bb0190625c2c8443992c6c1ca1ed50cc9dc8da299344d5da64060a6f1194e174aed9018a4a92ce63eec7c0357450060cd58e82d3fdac7380aae7749d61fca375934273303e99621c9064ea4d74db1a2da08b04fda6733254f2b142bf7c20aca75136ed19e8d832210884a35ada8f29d51507a3ed1f84fcf49aca0854f987c407cbf9512693e73682576acccd90dbc329c89589f0c19c7e6d73820aeb5309458182ede7a6fa2230ca088c52462ba18a4bc729d9ca37b8d4f1df840a7766cebd27658202240f2532073c24149ddae19109cc1ba06fbf1a3ac51584facc8c2d39e4a4cbeab82de1e9dc0cb30ac08c69c20bb796ceee59d77857889a6d1cf2f6a5b8531c0089f52399c707d842a7cf52165af01a1d73d42cabc36870b636e55d868b5cc44450353f6cc242d79d2a5083d889e06f2267bf80451648f9973d30e2085f1f77905d7b3b325fad48a778d9050fdb629e6e74592a97c5b7c3f77166e56defa76a9d7a1dcb927d579668fe6b8ab65f59ef031a3e886d08243a0844a6129255c997c17c0045ee78ed85c9c48006211919442c18875e734448be774d95c811dc9c3b26eb5674ee7f54634d81f837fe97dcc45ad9ba650cbe3497d5c030f021c662d56f08d0cffb9e36c8a6dd9e4ce568ec164f2d1ccd59a9a2768b77b9389a661d61ae4793f53b4652b599a4529aa7425a81865f5e265b2747d3e115143e66b15605ac5446f64ffef5c21887195efaf911f01977a42ea9e71e40aad01ad064fdbb6909f1f8d9dbbd520bf0fdbf0e04d57618527cafc41206b7b3b933753e874926977d318d09d40d2ee901d83ea68d58e2baa622c5e47241e5be96e12d638e7baccda99cc69bd89abeb5ab9578d40edffee9edc32ec557cc51fca1cd01244ce1aad0c9d37bde063a7afca52b35ed7221fb2ae8073e12c468d9e62324ac0e92e90b05d9ca682ba0870c6a56ca2922f912fc1dfdb42a600da00827d7331166a45f3852a1a58041ff70d7268134ceafec7742f7742aadc2d18dc643246a6fbf7084b81927f3d9de7c5717466a5a3f38425b62379e92cea30477a228713b406dc94e2608e72a7177bdf1b8f6b5e939d6a400ef0d000f8b16d570035750014f17ba13bd014f4b1bc95a95132ef1c015941fa116487ac57a85fbfee084e6ed70b1b37e5245a39691125fedc9130a9fcd61ac26e39e46a427dada03d33ff79cdca73bda323609e97fc764c106a40de1ccdc4a09713264dd7de616a59b75e0f4c4a66200eb805a739294ad7e5250a153effa0222227bca5156114e7bcb73d71815a14d2a9ceeca1a820c81abe39d926585be5e0c6d23074fb07ed8853ee9c9bbf951a169db288466d9c3b61d146595162e1f4ff2f67d4d3d8bbf744445d439bc7d60ff600ff4daa9196b2ec219dbe176c0101bdc27229e883f0dd6e7493f22aeead74b5d2e76cbe52a8ef1419686e5ce328c6df263d916ae70dc88ca585f2a8bf9852447c3ece2e63c2bf57efab79f037779a73602736ba897fbf339d14b79242132ba85a931ee58edec713e3d70282ab81afd024562643072abd3a6d00a8cc00ad49f8eb871ee3f50d68c1f1eb64b3f2195ddc3da9186dbb19571299c9979245f0b4b57d9d3903106f866948c2f7398a1661be118f2b82654cb06fb65d344b06670f0fbf87fe37aeb72eb47f3fa3d8a8888f1f180c386000ed833bc3b9af7423aabf2c4926f65abfaefdbd5f5a8a2a341ea2fec1292743fbbfadf3b429dd1f93843dc17f9f0905a70e74aa414ac8e321b4eada782bbb3840d9758a664d0ef85f642ff149f8b532effc05a8bd84dfb0aadcc4aeff326ce9f11fdf66c9270e7b53470de804ba12f3aaa096bcb50013752507e1c737165d0076cb462ecea5caeae58c867c683fb57cc672c9c8a9bf95a8ad29ca117cab733d99e432dc29a3050a3325278316675e4a80d31977d22e1a9a886e2bd9c8ed184c73b4413a7b81067c48b5bcf9b5b5699e7e03762a7bae33fbe18d98ad982337ad836a8bd3c54a05b5514a86988169643ece5c6a2c05736a2b9a5c3b6e4f5504745e6393c0a20e25e1f3d8d7bf5a1272aea93844577ccf876d1ffd3dfb9ba89c815b450d91b81552326ab058c5242fa184cf7544204cf68c57a191da1b824ccd5e1a544429dd6538dbe4c9ea0357a735b54a142d977018e113ee90d281a8608feb5f6db94367bb9bd95f761a5498a78561d53bfa9bcc6f93d55e75084a4a932bf8ef2d7c2022023178384b014a7c4153e7f6f2ace3bb5807e992fe2b3835ca38f505a31b9a374adb8c6f70ece41991d41eff7b54460c93760a7e937500eae96ac09691710b4f0ae91ccde722eb3451318d4a66e2e01f6e14bbe2229e0061ab7afe345565df51879480f4226e8fd4b1cb207d36735356062a1ec9f7c9ec522f4729f9ce8b7f8ccfd4cba8c42a4dac47184bd8dd14bec89021effd2ee7b3c589cc29bebeda4088689d0746ebf19c09f8f1130bab24fe727a40165bb38a159fd7f8df20c8db22d862c29d88ef357e49129588696f59b2a472a5284fec352eeea431683f8f81ace683e0d8d69e3b4b34de3021802ce8c1ff718ff30863c256c7bec627a37804be11334c0e78e628ac4c7b5797e1e35538ce515b93057d2c14a0f0541d827fc3d610edb6a38c1c72bba1414497653242a2ce22b476956a7b6e7a532bbf4b36e9d1976caf69398360971017b9d0130248548dc9ed6b0fb79ea04d9b1b12a10e2faa1e40bd898d46424486eadd36f1d8d681171ddb97cf33bdef1dc54aaa7c8f67e2021635ba61a4e32799a81553302f9003a135107fec536f20c19b873e35148f1b31ff6a48f4f00ebb66fb41266a33d2f779d0478576f2721a0233f01b239a817b0cbed6c38c6498cfcca2e751fff05625d7562eeb2c7630f29b681b072d4a7ffade60a37a86aae865eb2b446d4b4683e87c973a286c8f66d3c1da28763b851f2e1ed0abe54f6618548fa98376dd3e0bc33e384d56229314da9e33a33d463da3e6173a104ada3c5300653e6ba0862665e7bb24c1917ef0221403dbf605f9216786aef3a3a9aefa2be824094323f2fed0cf8b2804f23878214e95956cfb2f2f7805433145f372a3332a091df02abf6084694abda35852f677d78915fab234daf0e6c0cd59e17b3e631bfb163ceadba272b960c6fe580c1dd730af3008b1b90b7b67501f84bf21257ceb091aea5e857d0073d7ef16e81c5e01c39874592ec8142940dc8993f0aee4ea6e0b572b2788fbab58e54a5f77664df47d2b83e8301c57fff4378a3cb2c477aaf1aa450b3bd062a93b07083e4bca0d502a9d45de459e0d019ad18b21286b571a2f0a0bb86cc0bda713e34b37408961197821883b8a96a10455fdad0ee5cbd8994176234d3543bc32840ae63a30251c0881a5853d5ad6e39d22b138bea012e83932364fa723acc5e20b09c2b768d6b7b7fce1920a039ee06b7756c4b9d512bed1bdb61a7882eff3d66391683d160a7593f83665c1b94a4606ce6370e11e85c4989da6b020b0622f1a1a77b763a97a25847b80c82f12f622a697c88d4160aac777c9464287ff0ddf6092f082f8fdac92d4a17d415e3e8c709da846821bc462dd926081d4cdbfde4bfa67456182eac61100ceed7196e4dffb11f1c700f6aa1391b7884e56fb579617223784695473b1fd18e2d788efa0511d4f0bfcdf1b92fb425570fb13d2e2ca1f37f2a626f6a008b509645a437b554511cf246e1f51edf0378ddc3f220fb24af5ab9d73f058390372cf4107d6ede69c4d5bb767f18b2a11961eec4e43dd49cc544a6a0ebf32b30f201dd16b461411ed851b7e82e79db57c978db2b7965a70c5a180790db671e0860154202500d0c298148163b711d5a99b59f0a96032265d6e89a7cba57543f14dba9fefc14c73790f2484a45a899063139f4958b1c806ff26622d5aa49d3abf5ff82ca706d40b1e51f2b6410e05ed77f9fbc4f2c34e4546eee69ddb45a268e005f1fc1d62366f471c36affd7ea5a02f17ae8532f6a843275f3d7c1bb3f4fb52ac73a19d2757c188d737671038cd0b9a6b6813f0f3f40505c202465d3bef2b8e789567dbe087e2385011c1b5034575aceaf20f062ba865ca11e451fc8be808988ae84d195b6603d5fc1079a803571dc9fa81b4ec2d35c90ead53d9cd59863c66221e95e7a92785bee4739d2590502e21d4198bbb325a004e7e94010bfb00ca5d4493c27c43f7eca4d04c193ec017888ea2bd065e89c4801dbe4ab505ecd1fd1d064514f383dd1d4ccd26a97c86b7364f4da668175923a6e07aa52d1f0d358fe75785bd1a403b21b15cfd1efe2e1efd0b6b03af698991acc1fd3df6b59adeed7829b5f4645f8ce1437e325a01a4a984730e4406f1943440271ccc7424f11c3023a95b77c1834de0a6fdb98c02329e55a73712d23b660ac5415f4b526bad5a7cadda92e8d4395fb05d72b2f1da8ada92dfb75b3237eb5d74d97970efc72d68c6640db1a17b6e0f5683560f9dee1c7a26d40fc66a22765e244ea9980d03fc071fc2fd902a473fb2f7c9db936353b3ce975c47ad7361968ebebe236115a7ccbecf53da56a2beeb56e9bb2796027260f9b0663ce96e47fae47eb9c8b2401a26c10f22dfefdb207555ff66957a384adf4269f1557e704a8d83ae592cc70c853a261d9e59f47ef97478eb65074e1c4a9c831eaadb1e337761660581ac3847a1a92c4ecc88192ca254fa50e6b0b695894cafcec7b6f53a59320c6fa8f4bacfa33f3597371533235629b3f0172d4455bed34c5f3cbd20142b7139bfcee471c145946369b0fae4e6e20581b9e537e86481c78c47ed7d7d2c52e22a3f27833560db7013f74453d4a407270205e169871938952113668a0e9364412c53412691a96a80146e383c50bd15fb5e09a1dbf35375886d3df4e913722dbc7c4e1b8d95a4efb6e8ff629718b32e118efbeb07dea88fb7bf5e1c05ed7a219aaa1b8bfcd6f6ee6752e2f22d227d407a476bae089935e76831619c04e2fdae2501c31436a4b6f90d19cb63ad4a21d27a536c64b6dae157cf7aa6db81ba3d3b2c15546afcd9dec4dfccad11dcc952f5ee730e1ac060f9f5501453bce7a612cf20c78ed156df734755e81178a48c92fbd205218e221113a25cfe71bdd308834c705c5dbb0c308a1a122ccfee7043f9a09f3313ecf2df674548e4a3e1b32c553c5be3e7282e6e108608d4b5076f255d8cdd916e3ad8e7f4bac1a5661e92bd85c1306a6bfa2b32f26fa4016a6e49bd554f1ef9ed453ea4237a21a3bea209e86ab8bd4298064f549a46433929334aaae77abf1552b6b269d5e9227a4092692492b902df155815d4769a486c0947e98ce6b4403eb910f3c2e367a11794d2b972a5b5ed87ef18ae987f3b364f076369e5735e75df5c1b219cbac00931854f4a1bc826ab3bc5f26a833a0de21a814066058a27c1c1ac9f4ca3b47cb52b07df16cc1bec24ea6399bd066648809a6b1eda53c7476537a34c4b28d7e61dcac808aa7b63c1f9d7a4065c8c7896d20e0c6a7b17ac9ba0a5cbf2e3df9a2a5486bf2602c0e9c21f2031f0e8a78cfe8aaac287ce3632703561e3e49649a7b43d992f675beeca0a4f3290b52e108171b949d5be5f238aca0db434791ab31ba7ee20b590ff8682a087c16927c0fd9b5c87a69d4455b1085444d568870ba0fbcf093908bc89eb1d970325850a18e162ab2ec8482ed807a6cb689b434c547e57e1860e35ce0dc54c759a699e5be9b93da686c7c674d439470b47629c9128462bc9e48b94bb68812d35b411eb97eb12f4fea4537ccf01349d50e1f0f71ff0d472939217dcfb6d01b84fe40bf49ff33e49b4aad0cf4ad38c24c7d1bac4ab970ce3eb5306b7de96e6c4a9dcc86df14fe150d78acb04d656b79ed63f1f4e73de90b5ee191aee543d052655bb993dbefaf5fc4334383931671e110fcf28fa3977168cfe253c3adc96e4118e3384d59662f19d77e7b7e369b3d93ce89a8ccf09d35d676e36be535ca301b44cbbd3b039e8f8f52902bfe194ae7206d2c7466081ec76ec2ccd739d6e4925110ec6fa86c361f019f6b1d315d346424bf8d25d0264fda3e225bc0170fe379319a5f9f87f98b433a3c45c683fed538bb5279b0b0850b9bdc0ce3906dbb13933d8c6b45c144cb725ec78cc705e882e060bedb175b66ab0c44b58aae9391c23a6b0ac09290e259514c0a25b4a6d3da896c2aec25e6f659673928c4606302acf5f7ba1cf7034bd49de38228b6e830a27cd330b52e1b0163bf15545addf9283798781b9396e83d4c6029250dd5293f240bb48f67f2eaefb33c8ed30f52de4ca518d02af30c183b9ef5f79a57aba4a7e27c65e2d91d218da50f1558f64148dc4adb04495a8e0a044e4290aee41aadeb9b4aa8e61e15060a41c0d2f74cac27850be3c71808a3acc330577d42ab1ba94a7d3ff3afb9d14d6b4aa964f4ed60934237f3fd8d4d911299c1a1a5f591543b863cbb1f5cece3a49858df8ee3a690c486a7ab3eda93cb71dd1aa26cf8732967f98070e96604e392a7932df34b45868a132fa6e961f8a1aed263bae09464c19e123a4f1ea77ed554c4cd09a5d2654640b030ce3508f595fc760968b7e0c6e1f6e1d3982bc1d618656dee40bcd7a4b649e0b6929f3068eec48c68a71e3b0c53df1fd5dc3d4d1e92d60b18773e33c303526c40a0d7d7a29cae564cf62c0cc4186700b71a64ab93d05f5dd2533eef86463df215bbe77a1e308c390ba73c1e66ba5eb34726a28f0b5d99e76e84a57b882d962d82f877cfbcde9e6264f7f49e1fca2f96c91f0044458f6830b758d3b3269a0ef451bf1719c36fa2e20fd048abc6374036939a5162dfd08b3089167a806b98f9f583adbfe0740186dc8fc572687a18131e667a360a2d726d82a3c20bbb4e1065ff7805794c51d18e6ebc542a839a38b7a74d17fc901efa006f0bb6920821076ae6fdc061889743263cb5d69af2359c056c4e81d736e5cf9c8463e2caa8e13c2bf69c8e4bdc465d62557a371a22383b550b4f74264c574d40e455d9351014e358f8dac480621846d0f7909db6e5b4e7518057032135af181472853ad213965638f2da05e8f8ed04dc838529d02f384c03c58aaa868de494560122941266e80001f1753f93a168ff5f50732d5522ad738a493d5296f5ab3ac780fbe842bd89a4b4938f5673b4b820351b3aa57a088179a686d635f709e0547d6f2681bba2569912c26aaa83609c47d1b064349a9c10948f9dbf3873ad4a0d3d473eccaf9419fee68fdfc02cb6a83ce87c398a83fca05b0bb611d48d68d9720b35c1d1518a2a523c7c542a03ca307e807fe57bb42ea89b2bec774be0a5628574a73ff6c98479fcf0af1b9b1dc663daa5ea59f20c8e245029e040520a3811fda650e066e932eb22625c329e7a7730fcd2b61ff02cb4ba17eeaa4024ecfde1db32e7628b654ce26685f591a9d9b3c4722b706657cff05fe7bd12a22700cba956d699335bfc701a7815b03c010556599c3745e297a9b19f88edb95dd786f791a6a38b8740c7723735819e4313de838d699b3c49e52906583b6001b6078546bdcdac5d71961ceeb7a4865129a273e8343ff38af60c5872f330ef7f00416c7205db36ef6e1f7109186ee56120334fda6b18b52fde32061c58b70c76240e0ca5f167022a333a430d7349f074334b4dfb804fca90c4c5830c52775b9f6e93ce4016181c0e1ec34a586daa0411091e18f45d65a66cae4b5f30f89be80f6394daa289aa429189d8c61dee067b4435bf05e4f6854f48aec464a76bab708f6111676f73454b33c9d36e574c78a2046c27f19a6c02c5a848d7517f587c46b7fe62821798e836ee5d1746165a17de3588a4b80876088dcf4a340089b28b25271cc74321873cdabda0523771a36a094fd415025c584cd22e477fed93067b1d1057d6db69ef789c6298fef6aae96b55605e42d1c103699e1f1de5c0fe41d6f345c21ab517e7972a8790915c51f3afe335e8e1d940aeced79ea8d59ef4151c9d90ebaadd6b5601bc0f569eb3d226c9e07eb11db22133ad984ff651c7d0544dbdbb87689461a51601c4b0d74f3b82e5d4c7acdd56226d2bfaa1decff49bab11595b08cdca1c08258aba4090b4acd70a9118cab79bc49e24bd57b1822b72e214a09dec6dbdb2f21dfe3aed8362d8fd11a7f776ba83c763d5e624d5f688db918e330cde692bfc5358c5df117b056e068594e72b3ea99f917cc30c2d76611c66a09613aa352098f55fc4d5b1798e6373b49d1cea44bf26917cf21456318bd6845ac6befee8aa38d2de1be3ac9b8903773dadde24ffea37c1c3e4f1a277b9111d1321e85c42b2cdfaf8025150307d24e9c5e961ea4b9e0c96d56e1087255a42b3de8cfa723b16aeee4bf9d3f4faad9313651923e8a8126c070c393d34d1b5c904cc9b46512655eae84efac2c3955033730f4023e26e143bf10ab01c62a0653bd423f7c60052593eb90e252209a8310b1193bd4f9e6733726f7fb29df7dbce9747ce9352ec60b4e75a642b2033ea99a0897f968df158b1d3283c2eef729dc3f52830e9e592cc46a8989159e548e94d0ba06dd0cb96fd0edf1223e84675e409b36a78c127ff08dc25ec875607ab8b7037970ca26b867b0d14ec343900cd09a2971267cab3ba444b2de49ce833234e65da0a30c14cd2d262fdc43e0e2d3709a8c886a0579a3074dc0b63197ad610719e4ea6e661e07ce62b93375575ed55dad3c8ab156ddb3f165088612022cc8dd4a91120c93528ddba6064b1d774a7c229b0ec12adc64435d7700b70d33d05ffaa231bf35970f1ef140ec8c48893101ac14d60f3d6c00b0e3d63e32990dde6b09aaf262e3266b49ece1164662a6e18423273f073965058e23784668481f5dee66fb1bd42207c0b4f39d0cae6b9e11f4f67fe9444fc3c1fea43ca5b358706995b0cf343bd0f4a4e628379307fabb88ea16642891ba9ceab5ba450d111ae6fdd2eb70704df77bf538225284023db982767618d989b7c725f504a3c276101fdbfa19b65b60ceea36a891dd87e2459de15a7fa80993d88faa0a4e3cbbed3a3f88dea3723da59c8dd0e19059d3482adf5098cccf6c4de33f2f4a8cf3edf8f9ac900bb8fdefc6789f729ebe17586cd50abcbc5dbc2b8163308d5ec3c7da88fd8f2594540f21b9e03980f6dc239bc5b40ab54cf496f9a08bfe0269a485e4dba5dbbcfcd6d11649ffe22c0394951bc58a6c9e2453cee79856f1e669d03be9d7e664b6b50735867a797f645959b9a1642592c9bedc251004023fea9b6cd390ba7d5a1d8e0d2c2e708eec0631da1c0b518f6930f11711553556186adce30323b8de169b09cab8cbaaf0e521d1e139347879beaef74f4c511c05d4413a770a635d2825cf2874e538157a6290d545d5f878e74c89b48e64facd992a85d53a3bc414d4873fe6f0ffe8f410072a4822843bb119d94485dfd4034d86f53e855a400a49e19f3e3c4ebf9d18cf6343aa63cf3ab4faf720653395e73a138433fc1d4e364a929b1970829b69af817f6a7b0d4b2aa8ae1e3d3ac1c6d3aee05f18c187f06d53ab23dfd6ead4700a269a22593056bcbf01ef54603a89461122425df5ff05f5dcd8b7c31eb8ef158d0fc790726edf5ba51a4bc2068a8d06b01431256c700fdf46ea90db8d5da99802dd0d56e234b2bd1b19091e755a71233ccb114e96e47a2a7d840f4ad9d7d910704e8230f7a321984dc1b8c36324f39d01d74644d97161eb020a78c941dbfd3dc49026f02345bf535ce06c47703cdebb5afb773e114caa09216b52fea1c5c4d1552b27d6b6418cd3abd0e4434eacf35c90fb5fb363f2e70d92243c17a4f82ad64b4e3e1ed9e72931dd1caa4a107e17dd7c1854a9c166562c953da5cb5758ec39b5b689056d94c24aa0c61075fa6484ea004c5c215311606c676ad6412548a0f5ea734fdc625f56e0f339940767716755b1a3521b5774cec272049a7eeae77d627c407dcd125816967f51432a3430df857630c40f8b8406df2edc32798bb7efe2b8279bfa64a8c274fb7e7b56e56bc2f4a379f1bed3256cf8f22b623f66f6b61e2356fd1a8e831146922ebfbbbffc6777907ad62523cdf0b0bebb7098c48823d2c9f19b0177ca0119f578b8a03738c58abd2ed999c72ca3a90b0a1851a15c99daa423a4b5c920b1a767fa5de4201e46658a9289be6927d06c922cbb04236f07c00cd333b16e1fc8312f632205962871e617f3220d7fef600c86bf82acbb0a5f06b02baf986283b23586766bdd55c619e3e4ca99c6f94ff57896db294e48bcc17fcef1e736e09b678a7dd0976962ae9ba855238de8c99c215d7a8abf9b61a80eef39284a2ff76355eb7aad561b41244d197ef0d6a7860fb1b7e3543e93aa766a944cb7a35636d4dae100c230c53be8a9a83ae36cde509e463fde7684ee93021ef58f692747a7479ae494a88aa2e55b6e2cfb4233717318e73010121c07a21d1b39d443a9a5ae5b37f51ba14b35f41f65fc91fc3a9d8660ae359eed8e363682c47c1f46918e585f9d030647a2ad15a725ff80e46acffff3ec037ea7e097df56a3ec340d9edf8a16dd329899353bc4d14bf9dd04ac6b22e7383078ce3a5dc048032c7044468861caab9d55cffc56a4bb54365063d41c0642236b35e539942443d4f052bd910eefc30eff270f42d576458782911b8a1e952e71faa1405bdf07804d76584ae9b7bfe7141b7e36595c81b837b851d0dd03aa661252b71d969ffe453e88ba202a574b127895ae3319224f1d704e09f5c91d3ac41bdeb9f467f12426d797efcf55bffb20c42e8592d085372b5cbf198d4d572057de99cc2700faa6bc4dee3daf483cea7bab9dbe0ba5c27522841e9635a887bf8a4e4af09ac7ac136f7ad01a1bdba9558193dd99f740da414251c991c853dce5d065db17218f58c7590019cb06169b4d7e0d40829959b3f5d4947f34ce792942117ec174c2528910129d8f54ce8b8756aa5faa7a3dd1c5d31486a52a5b80b42b9284539ab559ebbd8d73a57ccc7e96b6ee5f54702312ed52f7f908dc22d7e1f2b7b33adba0aa7192d22f69b47f0b71b145f110b48a96a58100ff56e05899128e0b26fc2f634f968cb5f41892f3cee8337542acd9abc223e609b62ae7b802ce6681f5bed3f71c63dba4edb32798ad7bdb28b3ba36bdc3fbc4f940e80bde0493fad958f4f861ea883caaea51792ec3404dc97d74871cb9e8d8f7c4e0eb8cc50c4e9b70657e8fd6616b129921d3a2ae7ea57724d387c4148279240a17516091fa8679701a72c4449299e53054d79e3cb2946b86622b0f9687cd184b87f56e3b60fab72968f83b5851c127e8f03379f93ca22065683c39d5c34c33f1bb7fed1f8dbdf04b0290a456ff881ba03e5ace93844fdb87d03fd88ef97c74cbb420e05ca1a895af17b4b13d38bb27804dc94146013f00a5f74da32c0cce16fed782ca32ce771def3bc83739a9ec17ece2714a9b9eede4bb4275d9592cf6d075dcbf4ed73f0f55c9b30428d2d19669ae9dcaa3175ba230dc0038727638c75f1cb54cfb3f55da97cbe0414b154adaef9f53ce335c4cdc89c8d39d96e974899525e5184f613f62052dd9641d361da42215c5247b473f968d537c9792bf4a3ea08019eeeecf6a325f62dbdbdebe6bbb064e02224cdd4a64c6d7775abe38dbf037dc5767edc98b2eb50f8eb496fc2675426961fb9ba8fd0749a96b115b736d56cc664219928d6fa5de67794b92fcbec0e5fd36221d557c22c23f57e6fd3c0b74da5106d323c6c5698e0aface6937173eeb2737fec5fc2132d865d7a57c7241b749a50638edbba208c123b6913059c1ed6835cb568e4a3675cf2092fe98f9d890869929334d5e801f6652f21bd653244078f66b08c543734c5436448b081c0921c527cf5522a6299053a05750aec95a60791b899441396601cc7442b647307aa5862c2681556739f6698a81a172b79e2fe748c6e554726f77d23832abab7176d3e57dd20a5f048c86137ecc7ef37eaa81a3e6f046c0ade4ec95f665ddb472c1b05eeee10a68626d86bb92fd360f68789f685c2f5aa87d04d6f0866f33dd33ffd98c6fa9d8ce2ad5c14626f163309917170cc1cf7e590dc6539c53a9b6afcd288a0fcc3d9fe6309e5f7d7f07957de25c558410eeeb2d9d8e6db03878539df29b362031ff97c2ff83d216aaa2231c22910b82421351c0064e1b8596a33520639c44701e08717067b7918ef8d8d8a83d0ab53efee82e9fec6fda6c8e77f28350c27e86ea2a92d5032086ed9807d30b9b5bae7de79fc41ddb9cdc5fa45b07148bb6f86dc7de97f072324226c6c00e77bc37e44b8edbd78738e990644a81ab9faef2778b2d2bd90e774d185ede1dd3963b81126ba7be580628516ba474bbeb5aa36741dfc4b7be22485b1b1000df9636182b3d7be3c7d9c613cdfacaf69308509829003e8763ac8c5ce55ffa911adfeb559b27a4bb6ee4216697d5f1f7d709e9bf98b87cdf19a65ce78e64d04a6f02e7903a46916a1843968a4d92505903230dca7af1de1b97df810907a1a25113dfcabf1b73509ee5776ef8fd508705f640cb914787f3c593805fe315ae83d667ded50b6441ef8c87f3b451cd81a9a7ecac3b2e1441fd58010d61e7a6a208b3afdaca369798facf138eb0aa2484e91bab657e325c5a7e1bb39fc270216599c618ee68101cb4b721b07afff2c0418bf2355345b3f284cb21562c14c584002fb19dea6a534a44c4ba3c1c00dfa0695ccc55516f48e1c3fb89c71a1fce27242b31c0b70091ae0e8df4b70c841af08afb82adc55a7372c584946b1f41bef072cf9bff826b08f8e3f74e8b440dd35cc9f2664e758b144cb32a1b882e0ad75d163525599886b2e0c7d41b14ebd3472cf91cd91e43d0eded2fbdd470080a2ffd4437a7202a89da7877eda494aedebc939077272b8e3a429f38cbac315d25767a3af419925d45427d7d314563a37aaa1c324412329dc73353fbc806f9d489cd7077d9e17a00a23251c3afba43da005e74157f7df4efac783a4d56fc0f6c87167993a0cc483be5fba958349b3b060f52b41821a9b28e35806837efb40dc99c797add226d3798857f329542c43c0c1e36f30a73603529ff95a23b5404d22c52093411d538b927a5757a39bb5a911af1e5e9aa34edf85bcb33ad9f4e4012ad43b011947195ffd9901632ded3025ab64a357c7ee4715efdcbe22e9208e0de349503058f281a25ca4a776a4e03026cf5a78eb1746beff12a5ff85b606c273cc9458c12b17168d5188e5140287601be064f8c3da2109aaf92646ad573fb19182f480c975b027cf24ced1a84ec22aa5840f9d872b010726dc291bfd180b799c83bfbc265e0f36b0eceaa221cdcf754058f3ab740289eb9e46cbc2ab1b904220c59fb9b9466e660f07b0cb6c06931552dec9949ff0b4fb2ed4e062bd8d45735730215c0b13b61753d6abf4872f439da4e45ee790edb05daf644ef2b1dd0ccf399081a7e52f45370c25bde18d833915f24f58f949cf6f23253c6114e820c39eae571cefb081e0965dc9d972bf0fe895b8bec728eedf1592013cd1c9860f5e0c0c54ceb84af8659654554ffafbf47140ad2b016257b5c10cb697fea5e2eb098a1a45a7e7248557424f68880204addd25e696070dd88b7fd62988906431d1f335aae6086f105b383e7a4ef6229aee1e7943382752e460ff60448aee9976d822104eefb11fff33cfbf873a9d6915e34a358fdcb8e72410f368e2ad39908caa6c05ce4f79dacc520f756a7aaf20db8d01a04c31cd27515e8547f9c54b7a82d22ba4ea6bb8f27c9e1f0cb74a18793366dfd5ac447a7b642c11363bb19a3ff7d9ff6d478a56eaebec7b3b8f7e40fb60c71110dc42f177a80ab24fc5f948fc93a0dc0b8c458593fbd24cf94e33c8a7c8cab1b9ae8de628c43129fcf88d43290e8c66eecfbe47861b471cb72608646ca9ab750737809f283c0c391d08e80c816ca7c72d3f133adbfa092ab1fa3b35e388ea58f6c89f6ce426a55dd5dfd1d1c8965d3f8d1e6f8f79b16fbf9d187094ca6bc3cd50eef6485df0434c79c67d200c3b8827af69b3bf71194cd52d7c73f88ef28c3c421c5dcfbe14cddaa121c5409c862e837c845f56dbc09c7dc5f9dd977ab21b0e447d55159a40d0e4ff86a783510d7c67f82b835b0f4b58df67effe5a3cc569fe42569e332368bf4e72e5b082fdd34ef72ea8c50028dae836ecba00164c72abdb2e93c76dafa3b28222dbb43dd6a58e970aa90cf8ce9692b48efb761097c06d1d7d3797e72702971d0924443bf1ad10d77226bf012bceac3dc6811ee452dc772e920eac8c4d043716a2f41b257b130d46ffafe0784d359ca1fd1787f186fa923cb4d128edef1642f3c05875bf3841f05c9383240308822a1901d770383d3326cd0d7ca3ef798b4e23dfd2eb0e03383449ef18da38e98e7f7e50e126818dccef0a741ed27b5ef956d2dc8a0f1fde0644960a24369b1e80a6df4fa268ef7e5d31b587a2b15b204efbbe13d02bf4c25cf8b31b3531822051e8cda383a0d2aff7fe665cba08757f25a57d4f36053e7254ab58865336d121bb288fee2f1d4d3001a323d928908e93491f24ce100a62a07bb6448f4ade96b9d3a620a2aa40ecb08eb6d022b5a52b3091cf9a0a745a229a8bc78d91fa0d4231e358ef60e85a5fa996948dc0e853eb87c17d3bc7b952b34e69f54ea4952f454c16ef7db1b9804c21a177d23cfe6cfaeff515832c9ffe0c0ab78bced1b7daa8c4df5cba07dda3aad5ce7b7db87c692c85e28cde07d222d827d61c445bf7ef35185017daf48555d1208ec3fcde5bd6b9333ca9b5de3263df2541410ff982a8694b83039d7b0de191a8e8b19fb868e75e7a9d07e600fc1931a859dfb70ee67ec53354ee9cb82a14b213aee97f7316fc35af90f9a0a1a35cb890cfb5ef0da68009f882c28b9758dc7ddc91b64365892f4a0785c07b321f9b69b61a94c0550ee31583985d0ba9064949e2a11e2a02b6c012ae06422eac545ccc811bfe0907e1509a2d7125b945b0ffb0ef811309c03e54718c62515a5b38629184bb451245a5031d23065da75b02b1e73fbe0881543d9214fe83a15510fd66eb19cef8cc6b77df7c3a7733b39775a7b718a78aae04bccce6e31ea08af841afa6a3a9941152e111ed43a825b41a1f27bea367f96a7db6eaa8110f3a60513cc610046395aafc44ffae2bb97b576f19d5679c7c01d47c6055cc01ba51885d0c774f9939117490eacbc85972067eee8319bafae2277450a3a9656720840be44bd59478ca63a3b0bfc39a2d021b5855b1d8015a1fe163de410a722053fc34b293ec657a8f428adabd8d3ddb9805b4bcb78c53f1353195885eed2f318c53474ac83a7a13bf73356b98df1e67755f294935c015c180b84a26c97f2532e0f41b5287e43da4f2d608dbd7addbd6077dbeada8b02447d85fe33e0f44dd9b465fdf0fa07f4095d53cbf2b28471240e7e0c97105606e061b23b31becb3c553eedecc2630df86a87131c0165c781e2b9c17aea7d405955dc9e141965f22113e7977687c2aca722447d2ff99b54c79dcd60262c8f5d82abee3c7643e200ad9556995013199efeff3cd78050cffe0d8c757ee56f940eb4461c4d5bfabb69bb8f3ccbb6e031098a502a440c2312e734d3144b5474a4adc165b0699ecb0c7cfe812efb749497baa5f918e5a54537198a521701470209bc79854607809130af92d1533f6e5b38018bb321da7044770d92bd7b98856b73f05f8a4fb4b8b9b1b53afc02f6f856622a0203e297457a921b87d9c544d4107b04340033d8b0a858f3b44928603c5d665f3d5cb4cac0ff73d846e1eba15655cbee363e4d67c5a01f1d58b311c27057672f2f809bf6e82093a4272d923833af21591e04027383268bb70d85c3d72497d3bfc09839214f241684de6ad61df436b12ba6a47d5535d31237310b8cd5a532733df6cd8d4f5e30d977ca6d2ad39cdafaef0aa647309a18ccca69edccf6923df4d4aac6dc6d8b0cc0daff8edc73c601c6dbaf41e9b4094ed7210bbafabd8b0201944c0a7c3b56c87e89ea6a76dfe8344452ea034ab9e9cc7553df979edd32fdb3dbea12c4fbe9fae3eed354fd4beb54fc46630fef04090fe1315d26a14031d4f61e04230de54156d61c8a420da045951d3f422b7175ded796917396e657fdcd3c86739948fc3595a8c77f6eca66fcfa91880c8c7a72c0f8485d1506c10252432b21a2a4f28dce8b28453407469cf1e877630e4e6e69522b038e38914112b4cc5426de928fd1d05e100f7e4d93d8d9a75ff511a0f1b9094cf913158a58b2fb46fdd8eb32e4d88ac82897b5369422268f81916e32d11f83a3934456b9bcecf5357ecc811d6816d65bffc0777fcce41a9b20befa72fc74b0f5fc67928c904d2333844183dde5500bd7f46bb274b14be517936e25cedd57f45d803e0915fb66287f736d17dd9acaef93c7c192b0c95c516a48f23dcd39f273358499bcad136a6ebf1a12300f35f971be95a6be25b3c0796f1ca104ccf0de3e3c7456b97038cf7ff20dd45222e39445e2607b578b9bbf57f5c9a9c5e0b72e76de9679c7023f94bdc17e644465a588a36eea515a242452f0d8fd3a1fbcd38e66c382395b79e975b123c28548aa06f693a0737a08ea96aceaf3fe0a7bc06d14e929cdc74b466785610a698128fa6e98c156f7a6e8c071fcf3b43cf104e67dd3ef0297355a5ed89100400cfbb1bfaac9d60ebafffa920da4a4b1c9a9a9e4850c3575c5ae6a4aecbbe19e36ed879c93ff57482c489b2c5e637450e5a15732ad68ca521e0c9363f7a171ced2b35c99380843db41011f41d9e2337be220104d1c23b5453276cf6858e1fe2dae596a0a714da1daef3193e06e09cb38bf779e80015e0de50d81dcc6d6b07eacf87122ab99d01043f27391860d373cda5b5b33c6455fe11fc6478fd6783abc06e458caeaf5ffe7c41332504d10d41f1788fbfbceb3ca51f5da8088343908e64bff030a7a38f40195c7869eabf10bacf236a0799bdc3da087e8421f4b7a3059ba21f3033b1f53a43e7a2e1cc12eaef5d2c1c1133aad26db2769a475057ac295b5862afd419c2e4b647d0dcf3d8a75f660ba7e2a4f35d51f059b7a7d61121fada9570c18617364c25f5dde39dce5ce4dd65073ba2997ad6d8beb69f68a2c09c180347a03450d92d6e2303f769ac64cdb9237c62e39d1d77d969df893900958592d5bec7ec7c6570e0ac99ad14f29a7f0e13c70d957364f7f6d3d17d358a6f89f99eb295843f72e26455ebd72ee26011996359b011ee05d4821ac18e2277b768a132ea24a135c5c07a94be46167900ad337f0dd1e80725531c1e8d1d8b2296931630ce5e7aade504d5e13ed23f079a0b6630a66115ea95766e55721fd41955916890dfc86f8c00defd1c7e97db03eb9e77d45900ef654342e01f108090f6b3f5e198b33b572eaee3fc218b026bf14ef5af3fc7591f204565e01a9129de3eb8e27d8b68603b17a2f7341de931a660347e4528879845a30e8fdba04d236c95b5c91967a7a2d4efa92a36d4e1b30ab1879ddcb07902f230671256b88e07fe138c2a09b1401998b769a03181d6d73ceba4219100bc5848aa33bd9426ed9f7382464e44c4214d75d6f02b6f2cb4553bdba40edd956819be750bd24448802526ff4cdd86d921f58d1d70d3cdb115f6703791fe0b2e66296fb176bc042e34ed812a60369e0a257474fca14c7154846a7005ebe50f6e41ee9cb49977a385b3522c2e4871712af8b71becee7f614ae71fd895217dda979f271acd016497c4aacd00c0ba47fece88ffda0ab1989e29c3629600ea643f1d5418fdc4ee3d2148c2b8da56903e7ec167fe42891d30920d6d958a7bc3414517edb4649f33cd87be08883955266c34ee02fba7aaa10134d113525113f10985fd6581f37baa61c671af9355a4fac172e32b5caf3c645d3df6189a1b3c0fc7d6d400cc8a9944364f479560cb6ecc1becd1d2a80d1ee5bb1a5f35f12bfb3de58d1b1ceae61ea7f9d676894dd3ad443f3f5ee1843f6a3f3c620f6bf22b1e9db3b4a0d13901ab730d48761a2c1f56cf31db0c1ff97c181be78bf5a8699960a9d3df216748e873f7edc3e3bf427b79672c11c62daa03e0e6a64edcc9f726833abef025a387d5819ca0a5ae4331362a62dfe9e051b7198583b3557741223516092d08dd66c13cc5c09d87e29ad35e9fab6986a90bb5cb1c47ec6d3bb22fb146dbddadf2bfd14181a077539b86d86b428b9a9ddc8c0726c9ee40d4f101a298299ec9a03c932fcc7e96032fa16c49cd7e8ee17ebd3042fef6728c7b33e58c7d551d61be826e4792f214d69d64cf732ee6a81647815747e2ab8bc81e8c09dcc490e8c8fa613d646e45af70f32bada17608d0527a4c60e530d6b5861f42ce7e3ba2d66d64e854059b7f7d6d541ff9c5ebd71231c8308b77bcc8d8785f87d4b9fd60caaba36e9963f68a0544fd55efde7ee1a5999ca9cd647b95a348bbebf1d6fc7fd5c3aba67d80deb6992e99ab0c5394ee7c466c48eef66cf9bd3d90c3ae30c4758a24ff158f573cdb440dc240c72c92ea47e6d54a32313225817d2cbeff2e4102e4768760c423066eb165ea3ca713926a711facbe9ab045b52820bfe77f827785c8333800bc191d25abefdbe89539ddd500fb271efeb5e53ce605ff5c7a85559611258a43292e2d1c696959dc15abffa2167798093fc375cca74e4aae8b4db71d8061a78e0273bce88d63e86d352cab46f7662163230fc762acb6079aa8e94e125e55ff85b268a1fb4e2bd1ff4f3b88f6999784644dd760ef554a38dc34b1503f69ae656fad9f051418d87d20eadf381174d68194e07ac8f20471d9b37eb3adc8f551a33ed86ca10389e2dd059840b0c13ce83d45cc94d2e8e23a4a9f9d2d1bf478e8e538209ddda9fc7ba62f7178b22821503eebc1960ff6bc8b51f9c4b1588ba34716932181e3466b1a2d84c5b162ffcce73c57dab2a1f98afc54f48194a147f29b4608dfe47fb3be2ab06676b073fe3cdab48b492e26f367617c5ed337f64476d0b454f59878886b4aaa84ad244c7688cdc14461a8f57156cfc9f50c069485ea5972c1868747b5ad51d0d2420ae362ee2fd4d6d20681d75cb454605929be3062e6305e7044228899a73eddb68078068cc91a0c9acbd0a16eabbfacefebcbdb81ce9ddaec01c3fa74b2a5e8f80468dadd312d3860dbb553952d0fc3032e99be2162df2cf8e682f8ec73c6c13bc73190414a71fcaeafe205ba889be1621aa7570a71fdd44ac70b1a7aa037149f68461e421df932fe570c545eb8b4d12ff9abdcfeb3260a5c58336d7bfc4f77dddd2afaf5ae01ad437356b7d9bb7f9ded11726d0e83501bcc055102e35f4a4dae292626a15b80044a9f582792a7d1ef857a4eb03945b49af866024d9cb6f346af8ea566ba8c8ba99cdc6e6e3aaafd003d9344e48167d2108a4d3066eef29f9d093585df01500d344964b4a4879acbe5bf144e046fe95a9e452272cdf280ff5ee8c5d62c5dd07c3531dc9172483c02deaf006e7d9ff948105b0e24ba94b1b11f3b3ae75e63c84169fd3c49663206602aad679c73759b3c1703c89ee77101e96e75eb5579f0bb82b37daae1a7fedfd22c8a80abc419b990d2b3eab2267a0b31e567df2e48d4214e54f8d1a72c9282fb577fbadafd2d4a71389fd292e19b4cc85c6cf1393c391f5125d518100ce42baf7fd1e49e99a0e979a944c54bdc33f1ef389d2a53096d3bb71b990ae3426407f02af44888fa6b1c630a3c354a889a2ad6945d7be68571bf39b10bd4990654a85c0f14f2c89f13e82282fd2ad88c9602a6da1c0687391946b507207b16e808a9ebc1a8418060fde15b050da6438cb1bd9c3aa3007e9240750d181e0ab523e869851dfee6ec19028722bb6e5fe49165768bf9643a79f30b8c2fe426837a3397b83753d531a3567d47df4c8fb794f54583309fb133692bbb999da2c87ea300af4a36e4455d2807fa226342413c1b47eef69747677f323621c7a7d3136aab1a32e32b31138c96a17f7047ff46fef2b0745e315b34d491950fd4c960fe1a9cf93febcf1fb5bfaef77644cc1aec831b596860fe5d690d8f5cd3c7e2587819be8785d678aa54346cfe0dc5fa365fd19c24878b9c2bbdf401eff216b63e1066560d67e7f6d4328559117864d68b438642d0d24071cf55c10fe5dee658387fbffddb979006fd9cc29e7ce75ba0755925fd1341483d6bb2c4889a42b414726b3396b3f8bbe4d1474ff25c54679b0653beeba290b5a5903fc728238235f0acc13361e24a2ed8e30bb131caba370987fee7efec2f3cdc5c54dd7508d9fb01f88ffb7d598051597d8579d6868d6d6125d61794e3a0444bc32660ba198fef6e7ee25621b711f8931af5ae87f2e04a922d9da8e76fd977f9d1cc2c4dcf61c46a961e77a3506c661d7c956c8cdd168f2e2470155fef85e1bbbe04981b9b2fcf6d56b6b2eade8cca2572c9a30de874c0d9b9b64d27fd11d090154ba48b03f9cd33ebbd59f46ccaee978b6e4a318d045e38a26e4f5ac14206fd9d5b389e8ebbd176d9828fb49163a36e99aafb709e2e441054bb94ac4ecc6bd60a185f325913bc4626cf2a6d90172b5a048443f34bfe1a0909a41cbb43a13bdb801842a33db03435886d22100d920fbca07d7cd55d7b5082fdd2f436b2c4c2c0ceca27a06128ff0068a83ca5b04e0acbaac906083e7031f048bc071c1a2e80c2eb9dc5436f37b3884c4115de725e9cb614fd23566764a748b9aab8907d95d9d264fc9507ad122798432d52e5cf79412e9e28ad1b1fc6cd1fd28cb13e3c05b9dd290fa3f583a4568b23569cd256c70f3da9aa13703b03c7ef73a5a5ca288ab5d7ef5e634a786be653d8444c2c66e8b61e942010f1ce9d72ed39ada0e5ef884814c8b5530a9e326977dab8fc9bc86d97c7fcb845e5841ac0ee1b0da5e864ebbe343dd4e575363909947aa4bc5c0f12d6272a636c0701de0a7c57560e871f77e4c621c4b644128b4ca9f9a758895693a146e12b54c128ee88a11c11e5081eac0e3dd613afd5897ef6ee9350e5c270f1052223c0ebfc43d4645fd20c0d08258a1aa8258c64de67dfee33fef9abaa11db741e1ca88754b055efcd9411dd8455ba7e77e7ba201e15fd29b60814221c5648adaabffe3d39f5c653b5ca29463e53a00c7e9778c0994d39909700658599adf3321b42c409cbfbfe3bb2ef937b9cc9ac0863a30d1568a0757990166b1cb435cfb47f43e9aa0701f7f12818ab390d1cef54f97586f17e05ea0ef54e31572ef1f91979bb660d60f186a5cb7bb3add96465725dca1a0301b9ab524a5e9cd484bbe15b3e696b9c9de770af75427c2b21bbe090da5e1fb0c86f7805acb01fc20efcb3c8cd9965e3894cb9df2eceb6b0bf519c3bacd812220e3d540fce077e4d9d67b42f69078492d11960a69cd2994e7726cd7c7057771acae1a9ee3b3ff08e1c40920a0855a3ed7b506b44ed3b6aa1b85414dd07652eb15a1a15ef164c2bf31aafb147c847adf02099171d1b36d53a0b6807606250baa170187000b4731ad53e0890c208b2323b0b44c9fc1622c83ca07917dccba848442958ee8142a2b0abc2bfd839dd5f69b91b016d8c148f1fecf584564ef4bb0a7cd40117f061d2c84faf1001fcded8166e0154e0b7909448ad2826c82068f5456dc46d8a9332d3e9eab2bc3b2217c6bd043a4f4e082b48f04184f7197d7835d0eb66f7289b11e604426e7ee49dae94348c620ad00b13b464c300400d5e8cda1e359eaffdd5087e9bb8e65904da9ae0c0911420ddba327f3392b7f860f9b6102e907b45a46cdf9b04135233497a5d578af1d5bfbfeab4dd442a17526c6d0a75a01477ee2704e6a4de40eb0f11074705d36f19dce3c73158c12a80c1d096bfd52e0dd61399ffdce5d29576534e2c129bbc31594313e57f2413897b3c2eced990d1b5c074306d2980fd53115df4810281becd3cb34f32d8948db493c54a88391a678c45d4cc65e96dd9781c4d81d9b568318d8b7cd5efddb607200a4f22195a28202a7cf8045288c240a4ca5e183cded4b55a91c30811b87d9fe69febeda0a8c147546e0bc4da4c0f897ba5a604b78bc6c0cb04ace4682802148bd55b349302c011a12a9bd635434e4f6ec3bc5472fbe252136e655642ced154fd661c62a8c2d234c99f8b1e93fcdaaf7c9d49fa0a2e97374857722e4bb916aa7d9190c325274b4428dd4bce1582d6f77452d929ee990c2e2cff485ef12a02421367161070f517ff4a85fdcceb2e26cd1870484b3d4fb31c8aa66809ec88248f297c6922ca1e82ac2071bba2276dc1d9b61bcf6433fe5c58f88c80caca36b60f1f92cb9710371101f87670a7d0f2dd2575f4ab7b313d38787ca140310c564ca926b9b52429fabc0891681c98dd593df2fb8b8a20ebd59c55278bb9199a537cb2e101283efdf072de6d9e116006dfaeb47cffa6d70e87fe57855df8492d19fbcac64dea0bf04491d2ac5fc08ea991b6e485fe483e56c3144c9df27872eec3f38f3cddaf49cb46cafcec3eda771e15f511081565e92fe4ea8b51722e10bb2225a616ae75ba7f976b9cbbfbcb96613e1e9e47408da11c94e292ff23bf2e5ed0efc0d0e0d5e346e2409b30d566dc165dbd16bbbe9542c19a81512627f1da672172b4466b7e3093eadfb60f24a9294b8824cad54b25846da063650071077f62894eb231a20c743d46b8d40dfcdd6ef16bae3c70aa536214ec082d976816e2b8cff1c93cbabcfd5cc11575c6532a110e786d59addbac1c88f103ac46b8b948125044c26e4332d197c7bc3322d013a23ed33096ca1d87f28a5e01d5e2c8e4ad7f88f799185e1a7e1c01a7e626fc0ac22403ef0ebd48b2e46ebd68538be6015196d7e63d78c28aa7aed6640989bd122754368c04f02e767fee913c030b0d6646f50e72ebd0b6d32531a5d4eff74</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>TRPG</category>
      </categories>
      <tags>
        <tag>TRPG</tag>
        <tag>Mods</tag>
      </tags>
  </entry>
  <entry>
    <title>时序知识图谱笔记与知识图谱推理的机遇挑战</title>
    <url>/Learning/Notes/Papers/TKG-Note/</url>
    <content><![CDATA[<h1 id="简介">简介</h1>
<p>主要来自： - Tittle: <strong>Reasoning over Different Types of
Knowledge Graphs: Static, Temporal and Multi-Modal</strong> - Author: Ke
Liang, Lingyuan Meng, Meng Liu, Yue Liu, Wenxuan Tu, Siwei Wang, Sihang
Zhou, Xinwang Liu , Senior Member, IEEE, Fuchun Sun, Fellow, IEEE -
Time: 24 Jan 2023 - Journal:</p>
<span id="more"></span>
<h1 id="定义">定义</h1>
<p>时序知识图谱推理（Temporal Knowledge Graph Reasoning）： Given a
temporal knowledge graph</p>
<p><span class="math display">\[
\mathcal{TKG=\{SKG_1, SKG_2, SKG_3, \ldots, SKG_t\}}
\]</span></p>
<p>where <span
class="math inline">\(\mathcal{SKG_t=\{E,R,F_t\}}\)</span> and timestamp
<span class="math inline">\(t \in \mathcal{T}\)</span>. With the queried
fact <span class="math inline">\((e^q_h, r^q, e^q_t, t^q)\)</span>,
reasoning can be classified into three types, including entity
reasoning, relation reasoning and timestamp reasoning.</p>
<figure>
<img data-src="/images/body/Papers/TKG-Note/Fig1.png" alt="Fig.1" />
<figcaption aria-hidden="true">Fig.1</figcaption>
</figure>
<p>根据queried fact的时间，推理又分为两类：interpolation reasoning 和
extrapolation reasoning（内推和外推）。详见Fig.1.</p>
<h1 id="模型">模型</h1>
<p>主要分为RNN-based Model和RNN-agnostic Model。</p>
<h2 id="rnn-based-model">RNN-based Model</h2>
<p>RNN很适合挖掘时间的变化，因此很多TKGR模型使用RNN来直接建模时序信息，称为RNN-based
Model。 根据使用的RNN的变种，可以分为三类：RNN、LSTM和GRU。</p>
<p>就先不细看了。</p>
<h2 id="rnn-agnostic-model">RNN-agnostic Model</h2>
<p>这些模型不适用RNN框架来采用时序信息，从而扩充原始的static
KGR模型。时间信息如何指导模型，可以将其大致分为两类：time-vector guided
models 和 time-operation guided models。</p>
<h3 id="time-vector-guided-model">Time-Vector Guided Model</h3>
<p>时间向量引导模型直接为时序信息生成附加时序嵌入t并将其作为附加信息与原始事实嵌入结合。虽然简单，但是模型效果主要依赖于时间编码器和嵌入融合模块是否合适。</p>
<h3 id="time-operation-guided-model">Time-Operation Guided Model</h3>
<p>时间操作引导模型利用一些特定的操作来组合时序信息到实体和关系嵌入中而不是直接生成时序嵌入t。比如将事实编码到设计的特定时间超平面中，并生成与时间相关的奖励。</p>
<p>RNN-agnostic Model比起RNN-based Model更为灵活。但是RNN-based
Model对时间信息建模的最好而且更容易使用在外推场景中。外推场景仍在早期阶段，有很大发展空间。</p>
<h1 id="数据集">数据集</h1>
<p>原文写的很多，可以直接看原文4.2节。</p>
<h1 id="机遇与挑战">机遇与挑战</h1>
<h2 id="分布外推理-out-of-distribution-reasoning">分布外推理
Out-of-distribution Reasoning</h2>
<p>使用增量对事实的推理叫做分布外推理，这对KGR模型的设计要求很高。最近一些尝试
为<strong>推断不可见实体</strong>提供了潜在方案，被称为
归纳推理模型。这些模型不考虑实体的具体含义，只挖掘图结构下的逻辑规则，取得了良好的性能。对于<strong>不可见关系推断</strong>，少镜头KGR模型倾向于提高模型的泛化能力，使训练后的模型能够很好地拓展到含有少量事实的不可见关系上。也就是说，少镜头KGR模型可以根据之前学习的相似知识快速学习新的任务。此外BERTRL试图根据语言模型计算出的文本语义来处理这种情况。而当语言模型没有得到很好的训练时，这些模型的性能会急剧下降。综上所述，分布外推理任务的KGR模型仍处于早期阶段，值得未来深入探索。</p>
<h2 id="大尺度推理-large-scale-reasoning">大尺度推理 Large-scale
Reasoning</h2>
<p>工业知识图谱都相当的大，需要更加有效率的KGR模型。因此当前有些工作尝试以渐进的方式优化传播过程。</p>
<h2 id="多关系推理-multi-relational-reasoning">多关系推理
Multi-relational Reasoning</h2>
<figure>
<img data-src="/images/body/Papers/TKG-Note/Fig2.png" alt="Fig.2" />
<figcaption aria-hidden="true">Fig.2</figcaption>
</figure>
<p>多关系在知识图谱中是很常见的，和uni-relational、bi-relational
facts相比有更多样的结构和更复杂的语义，因此现今的KGR模型主要关注uni-relational、bi-relational
facts，甚至常常将多关系简化视作uni-relational、bi-relational
facts。这样的KGR模型不能准确地模拟真实情况，丢失了大量有意义的语义信息，导致表达能力不足。未来有必要研究如何利用多关系事实来提高推理能力。</p>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Papers</tag>
      </tags>
  </entry>
  <entry>
    <title>基于知识图谱的推荐系统综述笔记</title>
    <url>/Learning/Notes/Papers/KG-in-RS-Survey/</url>
    <content><![CDATA[<h1 id="简介">简介</h1>
<ul>
<li>Tittle: <strong>A Survey on Knowledge Graph-Based Recommender
Systems</strong></li>
<li>Author: Qingyu Guo, Fuzhen Zhuang, Chuan Qin, Hengshu Zhu, Senior
Member, IEEE, Xing Xie, Senior Member, IEEE, Hui Xiong, Fellow, IEEE,
and Qing He</li>
<li>Time: 7 October 2020</li>
<li>Journal: IEEE Transactions on Knowledge and Data Engineering</li>
</ul>
<p>20年利用知识图谱的推荐系统综述。</p>
<span id="more"></span>
<h1 id="基于知识图谱的推荐系统综述">基于知识图谱的推荐系统综述</h1>
<h2 id="methods">Methods</h2>
<h3 id="embedding-based-method">Embedding-based Method</h3>
<p>基于嵌入的方法通过利用kg中的多样事实来丰富item或user的表示，主要分为两个基础模块：图嵌入模块（学习图谱中的实体和关系表示）和推荐模块（使用学习到的特征来估计user对item的倾向）。</p>
<p>分类：<em>the two-stage learning method</em>、<em>the joint learning
method</em> 、and <em>the multi-task learning method</em>。</p>
<p>挑战：如何通过正确的知识图谱嵌入方法来获得实体嵌入，如何在推荐模块中结合已学习的实体嵌入。</p>
<h4 id="two-stage-learning-method-两阶段学习方法">Two-stage Learning
Method 两阶段学习方法</h4>
<p>分别训练图嵌入模块和推荐模块，图嵌入模块使用KGE训练之后与user、item的特征一起输入推荐模块进行预测。</p>
<p>优点：容易实现、kge不需要useritem的互动数据，对于大尺度数据集不会增加计算复杂度</p>
<p>缺点：transductive的缺点，训练好之后难以更新，需要重新训练，两模块直接联系不够紧密，不太适合kg外任务（有个解决方法是使用gan或贝叶斯生成模型来初始化实体嵌入）。</p>
<h4 id="joint-learning-method-联合学习方法">Joint Learning Method
联合学习方法</h4>
<p>把两模块端到端结合起来一起训练，推荐模块可以指导图嵌入模块的特征学习。</p>
<p>优点：可以端到端地训练，可以利用kg结构来规范推荐系统。</p>
<p>缺点：对于结合不同目的的函数，需要微调（fine-turning）</p>
<h4 id="multi-task-learning-method-多任务学习方法">Multi-task Learning
Method 多任务学习方法</h4>
<p>多任务学习就像是几个网络共用前多少层，然后对于不同的任务选择不同的分支进行？
使用kg相关的任务来指导推荐任务的训练，动机是因为useritem二部图中的items与kg中关联的实体的结构相似，因此在他们之间传递low-level
特征（有点像是细粒度？比如卷积一次的图还是能看出来原来是什么，卷积多次之后就是high-level
feature）对促进推荐系统的提升有帮助。</p>
<p>优点：能帮助避免推荐系统过拟合，提升泛化能力。</p>
<p>缺点：与联合学习方法类似，在一个框架下需要联合不同的任务。</p>
<h3 id="connection-based-method">Connection-based Method</h3>
<p>基于连接的方法利用图中的连接模式来指导推荐系统。大部分工作利用useritem的kg来挖掘图中实体的关系。</p>
<p>分类：<em>Meta-structure Based Method</em>、and <em>Path-embedding
Based methods</em>。</p>
<p>挑战：如何为困难的任务设计合适的元路径，如何建模实体间的连接模式。</p>
<h4 id="meta-structure-based-method-基于元结构的方法">Meta-structure
Based Method 基于元结构的方法</h4>
<p>元结构包括 meta-path 和
meta-graph，利用元结构来计算实体间的相似性，可以作为user和item表示的约束，或者用来从互动历史中的相似user、相似item来预测用户的兴趣。其中一种实现是利用不同元路径的实体的连接相似性作为图规范化来约束user和item的表示，动机是有高度元路径相似度的实体在潜在空间中都比较接近。</p>
<p>优点：容易实现，且大部分都基于矩阵分解技术（MF），使得模型复杂度低。</p>
<p>缺点：元路径或元图的选择需要相应领域的知识，且这些元结构在不同的数据集中差距很大。在某些特殊场景，该方法并不合适，例如新闻推荐任务中，一个新闻的实体可能属于不同的领域，使得很难设计元路径。连接模式没有明确地建模，因此这个方法缺乏一定的表示能力（FMG通过用元图代替元路径，捕捉更丰富的语义来解决这个问题）。</p>
<h4 id="path-embedding-based-methods-基于路径嵌入的方法">Path-embedding
Based methods 基于路径嵌入的方法</h4>
<p>基于元结构的方法中有个问题就是连接模式没有明确地建模，这使得很难学到useritem对和连接模式之间的相互作用。基于路径嵌入的方法就是来明确学习连接模式的嵌入。一些工作学习useritem知识图谱中的useritem对的连接、或item知识图谱中的itemitem对的连接的路径的明确嵌入来直接对useritem关系或itemitem关系建模。</p>
<p>优点：能够考虑目标用户、候选item和连接模式之间的相互作用。大部分模型能不借助预定义的元结构的帮助，自动地通过计算合格的路径并选择主要的那些来挖掘连接模式。因此可以能捕捉有表达力的连接模式。</p>
<p>缺点：如果图中的关系十分复杂，可能的路径数会相当大。实际中几乎不可能利用大规模知识图谱中每个实体对的所有路径，不然会妨碍模型的性能。</p>
<h3 id="propagation-based-method">Propagation-based Method</h3>
<blockquote>
<p>High-order relations contain spatial relations (e.g., “behind”,
“below”, “left”) and semantic relations (e.g., “playing”, “wearing”,
“holding”). Then these relations are combined with visual features to
enrich the representations of images.</p>
</blockquote>
<p>基于嵌入的方法利用知识图谱中的语义关系来丰富用户与物品表示或规范化推荐，但很难捕捉实体间的高阶关系（high-order
relations）。
基于连接的方法将复杂的useritem连接模式分解为线性路径，不可避免地会丢失信息。
基于传播的方法结合实体关系表示和高阶连接模式来创造一个更加人性化的推荐系统。基于传播的方法是基于表征传播（embedding
propagation）的思想。这些方法（GNN）通过聚合多跳邻居节点完善了实体嵌入，然后再进行推荐。</p>
<p>基于传播的方法一般都很消耗计算资源，为了提升效率，提出了更快的图卷积操作，在每层中通常使用邻居采样。然而随机采样会不可避免地损失信息，无法完整地explore图中的知识。</p>
<p>分类：<em>Refinement of User Representation</em>、<em>Refinement of
Item Representation</em>、and <em>Refinement of both User and Item
Representation</em>。</p>
<p>挑战：如何给不同的邻居分配合适的权重，如何在不同关系的边上传播信息，如何提升模型的泛化能力。</p>
<h4 id="refinement-of-user-representation-丰富用户表示">Refinement of
User Representation 丰富用户表示</h4>
<p>基于用户的互动历史来丰富用户表示，这些工作构建多种关系连接互动items和候选items的item
KG。动机是用户可以通过他们互动过的items和其多跳邻居来聚合为一个整体。</p>
<p>优点：在这个方法中item
KG的边的权重是明确的，因此可以选择连接候选item与交互过的item的主要路径（salient
path）来作为推荐结果的解释。</p>
<p>缺点：尽管利用了实体嵌入和高阶连接信息，在传播过程中只有用户表示得到了更新。</p>
<h4 id="refinement-of-item-representation-丰富物品表示">Refinement of
Item Representation 丰富物品表示</h4>
<p>在item
KG中，通过聚合候选物品的多跳邻居来学习其高阶表示。在向内的传播过程中，采用图注意力机制，其中不同邻居的权重是根据用户与关系特定的。动机是用户对不同的关系会有不同的倾向，这会引导知识图谱中的信息流动。</p>
<p>优缺点与丰富用户表示类似。</p>
<h4
id="refinement-of-both-user-and-item-representation-丰富用户与物品表示">Refinement
of both User and Item Representation 丰富用户与物品表示</h4>
<p>在useritem
KG中的传播机制，user、item和他们相关联的实体都在一张图中连接起来，useritem对之间的交互可以看作关系的一种。用户与物品嵌入可以通过他们相关的邻居节点上的传播过程来进行增强。</p>
<blockquote>
<p>和我想的useritementity的知识图谱很像，使用这种方法来获得user和item的嵌入，然后进行推荐预测。但本质上还是基于嵌入的链接预测？没法处理新的item和新的user，不然要重新嵌入，而且也会遇到冷启动问题？</p>
</blockquote>
<p>优点：权重也是user-specific的，所以也有一定的可解释性。特别是user也作为node，所以解释更直觉，高阶连接模式被充分利用。</p>
<p>缺点（downside）：图中更多的关系会带来不相关的实体，这会误导聚合过程中的用户倾向（为了解决，AKGE在子图中学习useritem对的加强表示）。</p>
<h2 id="datasets">Datasets</h2>
<p>See Table.1 .</p>
<figure>
<img data-src="/images/body/Papers/KG-in-RS-Survey/Table01.png"
alt="Table.1" />
<figcaption aria-hidden="true">Table.1</figcaption>
</figure>
<h2 id="future-directions">Future Directions</h2>
<h3 id="动态推荐">动态推荐</h3>
<p>GNN或GCN架构的KG-based推荐系统效果很好但是很耗时，因此可以被视作静态推荐。但在某些场景中，用户的兴趣会被社会事件或是朋友快速影响，这种情况下静态推荐无法理解实时的兴趣。可以利用动态图网络，来捕捉动态倾向。</p>
<h3 id="多任务学习">多任务学习</h3>
<p>KG-based推荐系统可以自然地视为图中的链接预测，所以考虑知识图谱的特性可能可以提升基于知识图谱的推荐性能。比如，kg中可能存在缺失事实，导致缺失关系或缺失实体，然而用户的倾向可能会因为这些事实的缺失而被忽略，这可能是推荐结果的决定性因素。Papers
[54], [71]
显示训练知识图谱补全后的推荐系统会有更好的结果。其他工作利用多任务学习，通过用kge任务[53]和item关系规范任务[55]来训练推荐模块。充分利用其他kg任务如实体分类与分解来将知识转移从而提升推荐效果会很有趣。</p>
<h3 id="跨领域推荐">跨领域推荐</h3>
<p>跨领域的交互数据是不均衡的，比如亚马逊平台的书的集合是大于别的领域的。通过迁移学习技术，源领域的交互数据可以被目标领域所利用，从而更好地推荐。Zhang
et al. [110]提出了基于矩阵的方法来跨领域推荐，Zhao et al.
[111]提出了PPGN，将不同领域的user和products放在一种图中，然后利用useritem交互图来跨领域推荐。尽管PPGN效果很好，但useritem图只包含了交互信息，没有考虑其他的关系。合并不同类型的useritem数据来进行跨领域推荐的前景不错。</p>
<h3 id="知识增强的语言表示">知识增强的语言表示</h3>
<p>将额外的知识集成到语言表示模型中来提升各种nlp任务，这样可以人为增强知识表示和文本表示。在新闻推荐系统或是其他基于文本的推荐任务中采用知识增强的文本表示很有前景，能有更好的表示学习，促进更准确的推荐。</p>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Papers</tag>
      </tags>
  </entry>
  <entry>
    <title>Top 70 Common Flutter Widgets</title>
    <url>/Learning/Notes/CommonFlutterWidgets/</url>
    <content><![CDATA[<p>From <span class="exturl" data-url="aHR0cHM6Ly95b3V0dS5iZS9HMUxHT0g0MjRsbw==">Best Flutter Widgets
EVER!<i class="fa fa-external-link-alt"></i></span></p>
<span id="more"></span>
<h1 id="top-70-common-flutter-widgets">Top 70 Common Flutter
Widgets</h1>
<ol type="1">
<li>MaterialBanner 点击按钮 从上方弹出提示</li>
<li>PreferredSize 创建你自己的appbar</li>
<li>BottomSheet 点击按钮 从底部弹出新页面（占据一半）</li>
<li>LongPressedDraggable 长按拖拽</li>
<li>InteractiveViewer 可以缩放</li>
<li>RecorderableListView 可以给listview里的拖拽排序</li>
<li>CheckboxListTile 勾选框</li>
<li>CircleAvatar 一个圆</li>
<li>CupertinoContextMenu 一个按钮触发多个选项供选择（省略号常用）</li>
<li>Table 表格</li>
<li>AlertDialog 提示</li>
<li>AnimatorContainer 可以变换的container</li>
<li>Card 有阴影的container？</li>
<li>DataPicker 选择日期的widget</li>
<li>TimePicker 选择时间的widget</li>
<li>DateRangePicker 选择时间区间的widget</li>
<li>Dismissable 可以左滑删除item的widget</li>
<li>DraggableScrollableSheet 可以拖动的scrollable sheet</li>
<li>DragTarget 可以拖拽Draggable widget进去的widget</li>
<li>Draggable 可以拖拽的widget</li>
<li>AnimatedCrossFade fade效果的widgets切换</li>
<li>Drawer 侧边栏</li>
<li>DrawerHeader 侧边栏header</li>
<li>PopupMenuButtom 有点像9，但是给的是返回值？</li>
<li>AnimatedDefaultTextStyle 可变换的textstyle？</li>
<li>AspectRatio 填充固定比例</li>
<li>AutoComplete 文本自动补全（联想）</li>
<li>ErrorWidget 出现错误的widget</li>
<li>Expaned 根据比例分配高/宽</li>
<li>Flexible 和expanded差不多，但是会被height覆盖</li>
<li>FloatingActionButton 悬浮按钮</li>
<li>Form 规定输入格式</li>
<li>TextFromField</li>
<li>AnimatedIcon 可变换的icon（例如播放暂停）</li>
<li>ChoiceChip 可供选择的文本标签</li>
<li>FadeInImage 加载出来图片之前可以设置默认图片</li>
<li>FractionallySizedBox 设置的高宽是基于屏幕比例的</li>
<li>FutureBuilder 加载完才会显示</li>
<li>GestureDetector 增加手势识别</li>
<li>GridView 有各种元素的滚动条？</li>
<li>GridTile 图片有header和footer</li>
<li>GridTileBar 给GridTile加上各种图标功能</li>
<li>AnimatedRotation 旋转动画</li>
<li>Hero 从一个页面跳到另一个页面的动画</li>
<li>IgnorePointer 可以使得按钮无法使用</li>
<li>IndexStack 点击相应index切换</li>
<li>ListView</li>
<li>ListTile</li>
<li>NavigationBar 底部栏</li>
<li>AnimatedOpacity 改变透明度的动画？</li>
<li>Stack 类似图层？</li>
<li>Stepper 生成Step</li>
<li>SteamBuilder 一串数据获取</li>
<li>Switch 类似c的switch</li>
<li>TabPageSelector 一般app第一次使用时的page切换</li>
<li>TabBar 顶部栏</li>
<li>PageView 左右滑动的页面</li>
<li>Positioned 放置确定位置的组件</li>
<li>RadioListTile 单选组件</li>
<li>RefreshIndicator 刷新组件</li>
<li>RotatedBox 旋转组件（不是动画）</li>
<li>SelectableText 可以选中（复制）的文本组件</li>
<li>Slider 滑块</li>
<li>SnackBar 底部提示，会自动消失</li>
<li>Visibility 可以隐藏的组件</li>
<li>Wrap</li>
<li>SafeArea 只在没有手机遮挡部分的地方的框</li>
<li>LayoutBuilder 根据手机size选择显示内容</li>
<li>OrientationBuilder 可以做横竖屏切换</li>
<li>OverflowBar 如果横着放不下会自动竖着放</li>
<li>FittedBox 自适应box</li>
<li>ExpansionTile 折叠列表</li>
<li>CupertinoSlidingSegmentedControl 根据选择tag切换</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>多模态知识图谱综述笔记</title>
    <url>/Learning/Notes/Papers/MMKG-Survey/</url>
    <content><![CDATA[<h1 id="简介">简介</h1>
<ul>
<li>Tittle: <strong>Multi-Modal Knowledge Graph Construction and
Application: A Survey</strong></li>
<li>Author: Xiangru Zhu, Zhixu Li Member, IEEE, Xiaodan Wang, Xueyao
Jiang, Penglei Sun, Xuwu Wang, Yanghua Xiao Member, IEEE, Nicholas Jing
Yuan Member, IEEE</li>
<li>Time: 11 Feb 2022</li>
<li>Journal: IEEE Transactions on Knowledge and Data Engineering</li>
</ul>
<p>22年多模态知识图谱综述。</p>
<span id="more"></span>
<h1 id="主旨">主旨</h1>
<h2 id="背景">背景</h2>
<h3 id="rdf">RDF</h3>
<p>RDF(Resource Description
Framework)，即资源描述框架，其本质是一个数据模型（Data
Model）。它提供了一个统一的标准，用于描述实体/资源。可以类比知识图谱的三元组。</p>
<h3 id="traditional-kg">Traditional KG</h3>
<p>Traditional KG is defined as a directed graph <span
class="math inline">\(\mathcal{G}=\{\mathcal{E,R,A,V,T_R,T_A}\}\)</span>.</p>
<ul>
<li><span class="math inline">\(\mathcal{E}\)</span>: entities</li>
<li><span class="math inline">\(\mathcal{R}\)</span>: relations</li>
<li><span class="math inline">\(\mathcal{A}\)</span>: attributes</li>
<li><span class="math inline">\(\mathcal{V}\)</span>: literal attribute
values</li>
<li><span class="math inline">\(\mathcal{T_R=E\times R\times
E}\)</span>, <span class="math inline">\(\mathcal{T_A=E\times A\times
V}\)</span> are sets of relation triples and attribute triples
respectively.</li>
</ul>
<h3 id="two-ways-for-representing-mmkg">Two Ways for representing
MMKG</h3>
<p>MMKG (Multi-Modal Knowledge Graph，多模态知识图谱)</p>
<figure>
<img data-src="/images/body/Papers/MMKG-Survey/Fig1.png" alt="Fig.1" />
<figcaption aria-hidden="true">Fig.1</figcaption>
</figure>
<ul>
<li><p><strong>A-MMKG</strong>: Taking multi-model data as particular
attribute values of entities or concepts, as shown in Fig.1(a).<br>
Denote as <span
class="math inline">\(\mathcal{G}=\{\mathcal{E,R,A,V,T_R,T_A}\}\)</span>
where <span class="math inline">\(\mathcal{T_A=E\times A\times
(V_{KG}\cup V_{MM})}\)</span> is the set of attribute triples,<br> <span
class="math inline">\(\mathcal{V_{KG}}\)</span> is the set of the KG’s
attribute values and <span
class="math inline">\(\mathcal{V_{MM}}\)</span> is the set of
multi-modal data.<br></p>
<blockquote>
<p>就是将原来的 <span class="math inline">\(\mathcal{T_A}\)</span> 中的
<span class="math inline">\(V\)</span> 并上多模态的数据。</p>
</blockquote></li>
<li><p><strong>N-MMKG</strong>: Taking multi-model data as entities in
KGs as the example shown in Fig.1(b).<br> Denote as <span
class="math inline">\(\mathcal{G}=\{\mathcal{E,R,A,V,T_R,T_A}\}\)</span>
where<br> <span class="math inline">\(\mathcal{T_R=(E_{KG}\cup
E_{MM})\times R\times (E_{KG}\cup E_{MM})}\)</span> is the set of
relation triples,<br> <span
class="math inline">\(\mathcal{E_{KG}}\)</span> is the set of KG
entities and <span class="math inline">\(\mathcal{E_{MM}}\)</span> is
the set of multi-modal data.<br></p>
<blockquote>
<p>将多模态数据拓展到实体集，当作实体考虑。</p>
</blockquote>
<p>Two images can also be associated in one of the following
relations:</p>
<ul>
<li>contain: One image entity visually contains another image entity by
the relative position of images.</li>
<li>nearBy: One image entity is visually nearby another image entity in
an image.</li>
<li>sameAs: Two different image entities refer to the same entity.</li>
<li>similar: Two image entities are visually similar to each other.</li>
</ul>
<p><br> In addition, in N-MMKGs an image is usually abstracted into a
number of image descriptors, which are usually summarized into feature
vectors of the image entity at pixel level, such as GHD
(灰度直方图描述符, Gray Histogram Descriptor), HOG (定向梯度直方图,
Histogram of Oriented Gradients Descriptor), CLD (颜色布局描述符, Color
Layout Descriptor) and so on.<br></p>
<blockquote>
<p>简单来说，N-MMKG中的图像是经过某些方法处理过后的特征向量。</p>
</blockquote></li>
</ul>
<p>Examples of A-MMKG and N-MMKG illustrated in Table.1.</p>
<figure>
<img data-src="/images/body/Papers/MMKG-Survey/Table1.png" alt="Table.1" />
<figcaption aria-hidden="true">Table.1</figcaption>
</figure>
<h3 id="multi-modal-tasks">Multi-Modal Tasks</h3>
<ul>
<li><em>Image Captioning. 图像描述.</em> Image captioning aims at
generating the descriptive caption for a given image.</li>
<li><em>Visual Grounding. 视觉定位.</em> Visual grounding aims at
locating an object with designated description in a given image.</li>
<li><em>Visual Question Answering (VQA). 视觉问答.</em> VQA aims at
generating a textual answer for a textual question with the help of a
relevant image.</li>
<li><em>Cross-Modal Retrieval. 跨模态检索.</em> There are two classic
cross-modal retrieval tasks including searching for images through a
text, and searching for texts through an image.</li>
</ul>
<h3 id="fundamental-challenges-of-multi-modal-learning">Fundamental
challenges of Multi-Modal Learning</h3>
<ul>
<li><p><em>Multi-modal Representation.</em> The multi-modal
representation uses the potential complementary of multi-modality to
learn feature representation.<br>
主要是两种方法，拼接和融合。拼接是将每种模态投射到各自的向量空间，如<strong>linear
correlation</strong>，再通过一些别的方法来将各个模态进行交融。融合是将所有模态全部投射到一个统一的空间，如<strong>VGG</strong>、<strong>ResNet</strong>。<br></p>
<blockquote>
<p>potential complementary:
指模态的潜在互补，每种模态都有一些别的模态没有的信息，如文字“这有一个男孩”，在图片中可以看出男孩的肤色是黑色，那么实际上我们知道这是一个黑人男孩。</p>
</blockquote></li>
<li><p><em>Multi-Model Translation.</em> Multi-modal translation learns
to translate from a source instance in one modality to a target instance
in another. <br> The example-based translation models build bridges
between different modality through dictionary, <br> while the generative
translation models build a more flexible model which can transform one
modal to another.</p></li>
<li><p><em>Multi-Model Alignment.</em> Multi-modal alignment aims to
find the correspondences between different modalities. <br> It can
either be directly applied in some multi-modal tasks such as visual
grounding, or be taken as a pre-training task in multi-modal pretrained
language models.</p></li>
<li><p><em>Multi-modal Fusion.</em> Multi-modal fusion refers to the
process of joining information from different modalities to perform a
prediction, <br> where various attention mechanism such as <strong>gated
cross-modality attention</strong>, <strong>bottom up attention</strong>
etc. are applied to model the interaction between different kinds of
features in the cross-modal module.</p></li>
<li><p><em>Multi-modal Co-Learning.</em> Multi-modal co-learning aims to
alleviate the low-resource problems in a certain modality by leveraging
the resources of other modalities through the alignment between
them.<br>
多模态联合学习通过多模态对齐利用其他类型的模态来缓解某一low-resource的模块。</p></li>
</ul>
<h3 id="multi-modal-pretrained-language-model">Multi-Modal Pretrained
Language Model</h3>
<p>Based on a large-scale unsupervised multi-modal data set with
text-image pairs, 许多工作都在学习多模态预训练语言模型 with designed
预训练自监督任务, including <strong>masked language model</strong>,
<strong>sentence image alignment</strong>, <strong>masked region label
classification</strong>, <strong>masked region feature
regression</strong>, <strong>masked object prediction</strong>, etc.
多模态预训练语言模型在下游任务中确实有效。</p>
<p>Can be divided into 1. <strong>single-stream models</strong> and 2.
<strong>two-stream models</strong>, in terms of the
<em>Transformer-based</em> fusion process of different modality.</p>
<ul>
<li><p>单流模型 Single-stream models, such as <strong>VL-BERT</strong>,
<strong>ViLT</strong>, input <em>all</em> modal information into
<em>a</em> single Transformer encoder for fusion by self-attention
modules.</p></li>
<li><p>双流模型 Two-stream models, such as <strong>LXMERT</strong>,
input <em>different</em> modal information into their <em>own</em>
encoders and fuse these representation from <em>different</em> modal
encoder by an additional cross-attention module.<br> The final output
representation not only contains the cross-modal interaction, but also
preserves the interaction within each modality.<br>
不仅包含了每个模块之间的交互，还保留了每个模块内部的交互。</p></li>
</ul>
<h3 id="mmkg-benefit-downstream-tasks">MMKG benefit downstream
tasks</h3>
<ol type="1">
<li>MMKG为实体与概念的表达补充足够丰富的background
knowledge，特别是那些long-tail ones 长尾问题。<br> long-tail: a few
classes(a.k.a. head class) occupy most of the data, while most
classes(a.k.a. tail class) have rarely few samples.
少数类(头类)占用大部分数据，而大多数类(尾类)只有少量的数据。</li>
<li>MMKG可以提升模型对图像中隐藏的物体的理解能力。Unseen object pose
great challenge for statistic based models.
这主要是利用符号知识提供的在视觉上不可见物体的符号信息，或在可见物体和不可见物体之间建立语义关系。</li>
<li>MMKG支持多模态推理。Multi-modal reasoning.</li>
<li>MMKG在一些NLP任务中，可以提供多模态数据作为附加特征来帮助弥合信息鸿沟。Take
entity recognition for example, an image could provide sufficient
infomation to identify whether "Rocky" is the name of a dog or a
person.</li>
</ol>
<h2 id="mmkg-construction.-mmkg的构建">MMKG Construction.
MMKG的构建</h2>
<p>MMKG构建的实质是将KG中的符号知识（实体、概念、关系等）与他们对应的图像相关联。有两种相反的方式来完成：1.
From images to symbols: Labeling images; 2. From symbols to images:
Symbol grounding.</p>
<figure>
<img data-src="/images/body/Papers/MMKG-Survey/Table2.png" alt="Table.2" />
<figcaption aria-hidden="true">Table.2</figcaption>
</figure>
<h3 id="from-images-to-symbols-labeling-images">From Images to Symbols:
Labeling Images</h3>
<p>The CV community has developed many <em>image labeling
solutions</em>, which could be leveraged in labeling images with
knowledge symbols in KG. Most image labeling solutions learn the
<strong>mapping</strong> from image content to a wide varity of label
sets (including objects, sences, entities, attributes, relations, events
and other symbols).<br> The learning procedure is supervised by a human
annotated data set, seen Fig.2.</p>
<figure>
<img data-src="/images/body/Papers/MMKG-Survey/Fig2.png" alt="Fig.2" />
<figcaption aria-hidden="true">Fig.2</figcaption>
</figure>
<p>Table.2(a) lists some well-known image-based visual knowledge
extraction systems constructed. 这些系统可以通过图像标注来构建MMKG。
According to <em>the category of symbols to be linked</em>, the process
of linking images to symbols could be divided into several fractionized
tasks:</p>
<ol type="1">
<li><strong>visual entity/concept extraction</strong>: Aim to detect and
locate target visual objects in images, and then label these objects
with entity/concept symbols in KGs.
从图像中识别实体并用KG中的entity标记;</li>
<li><strong>visual relation extracion</strong>: Aim at identifying
semantic relations among detected visual entities/concepts in images,
and then labeling them with the relations in KGs.
识别已识别的实体之间的语义关系并用KG中的relation标记;</li>
<li><strong>visual event extraction</strong>: Aim at 1) predicting the
visual event types and 2) locating and exacting objects in source images
or videos as visual arguments.
预测视觉事件类型，定位并提取对象作为可视参数。
<ul>
<li>EVENT: dynamic interaction among arguments, including a trigger and
several arguments with their corresponding argument roles.</li>
<li>Trigger: a verb or a noun indicating the occurrence of an
event.</li>
<li>Argument role: the semantic relation between an event and an
argument such as <em>Time</em>, <em>Person</em>, <em>Place</em>.</li>
</ul>
<blockquote>
<p>如“我在十点半睡觉”是一个event，<em>睡觉</em>是trigger，argument是<em>十点半</em>，argument
role是Time，另外<em>我</em>也可以是argument，这时argument
role就是Person。</p>
</blockquote></li>
</ol>
<h4 id="visual-entityconcept-extraction-视觉实体概念提取">Visual
Entity/Concept Extraction 视觉实体/概念提取</h4>
<h5 id="challanges">Challanges</h5>
<p>The main challenge with this task lies on how to learn an effective
fine-grained extraction model without a large-scale, fine-grained,
well-annotated concept and entity image dataset. <br>
CV中虽然有丰富的标注良好的图像数据，但这些数据集几乎都是粗粒度coarse-grained的概念图像，无法满足MMKG构建对细粒度概念和实体图像标注数据的要求。</p>
<blockquote>
<p>CV图像分类中的细粒度/粗粒度(fine-grained/coarse-grained):
粗粒度指类别之间差异大，如人、汽车、树；细粒度指类别之间差异小，如200种鸟的分类、100种花的分类。<br>
由于细粒度类别属于同一个大类，所以各类别之间的差距很小，这些细微的差距容易被光照、颜色、背景、形状和位置等变化因素覆盖，导致细粒度图像分类相对困难。</p>
</blockquote>
<h5 id="progresses">Progresses</h5>
<p>Existing efforts could be roughly divided into two categories: <br>
1) object recognition methods, which label a visual entity/concept by
classifying the region of a detected object; and<br> 2) visual grounding
methods, which label a visual entity/concept by mapping a word or phrase
in a caption to the most relevant region.</p>
<p>对象识别方法对检测到对象的区域进行分类，来标记视觉实体/概念；视觉定位是将标题中的单词或短语映射到图像中最相关的区域。这两个的侧重点分别是<strong>从图像区域到实体</strong>，一个是<strong>从实体到图像区域</strong>。</p>
<h6 id="object-recognition-methods">Object Recognition methods</h6>
<p>早期工作中，提供的图片基本都只有一个物体，但现实生活中的图像往往十分复杂，以至于无法用仅仅一个label来表示。为了识别多个视觉实体，我们需要预训练的检测器和分类器来标注视觉实体（以及属性及场景）及其在图像中的位置。<br>
检测器的训练数据都是有监督数据，主要来自public image-text datasets(such
as <strong>MSCOCO</strong>, <strong>Flickr30k</strong>, <strong>Flick30k
Entities</strong> and <strong>OpenImages</strong>)或预标注的种子图像
pre-labeled seed images.</p>
<p>在检测过程中，检测器捕获一组可能对象的候选区域region
proposals，并挑出实际包含对象的候选。在检测到的区域中，预先训练的分类器识别具有entity-level(例如BMW
320)或concept-level(例如Car)标签的候选视觉对象。</p>
<p>被识别出来的实体一般不会直接被认为是visual
entities，这是因为一般会有大量重复的实例 at different view points,
positions, poses and appearances. 因此我们一般会选择最具有代表性的
visual object 作为 visual entitiy。<br>
最常用的方法是对选出来的图像区域进行聚类，每个聚类的中心就被认为是一个新的
visual entity。</p>
<p>缺点：当该方案需要生成大量labels时，需要很多的预处理工作，比如预训练的规则、预确定的实体列表、预训练的细粒度检测器和分类器等，这会导致该方案的鲁棒性scalability下降。</p>
<h6 id="visual-grounding-method">Visual Grounding Method</h6>
<p>视觉实体提取问题简化为开域视觉定位问题，即定位标题中的每个短语对应的图像区域，从而获得图像中的视觉对象及其标签。</p>
<blockquote>
<p>一般在visual entity extraction中，训练用的 labeled data 需要 with
bounding boxes and pre-defined schema with a fixed set of concept, which
is difficult to be used for large-scale visual knowledge
acquisition.<br> 幸运的是，Web上有很多image-captions pairs，来为visual
knowledge extraction提供<strong>弱监督weakly supervise</strong> without
relying on the labeled bounding boxes.</p>
</blockquote>
<blockquote>
<p>As illustrated in Fig.3 below, weakly supervised learning mainly
includs three classical categories:<br> 1) 不完全监督 Incomplete
supervision:
训练数据中只有一部分数据被给了标签，有一些数据是没有标签的。<br> 2)
不确切监督 Inexact supervision: 训练数据只给出了粗粒度标签。<br> 3)
不精确监督 Inaccurate supervision: 给出的标签不总是正确的。<br> <img
src="/images/body/Papers/MMKG-Survey/Fig3.png" alt="Fig.3" />
在实际操作中，这三类经常同时发生。</p>
</blockquote>
<blockquote>
<p>关于弱监督学习可以参考周志华 《A Brief Introduction to Weakly
Supervised Learning》（2018.1）</p>
</blockquote>
<p>当从弱监督的图像标题对重提取信息时，通常根据<strong>空间热力图</strong>(shown
as Fig.4)直接选择给定单词的活动像素作为视觉对象的区域。</p>
<figure>
<img data-src="/images/body/Papers/MMKG-Survey/Fig4.png" alt="Fig.4" />
<figcaption aria-hidden="true">Fig.4</figcaption>
</figure>
<p>在同一语义空间中的文本、图像表示，每个短语的热图可以通过<strong>基于注意力的方法</strong>和<strong>基于显著性的方法</strong>作为跨模态权重来学习，shown
as Fig.5。</p>
<figure>
<img data-src="/images/body/Papers/MMKG-Survey/Fig5.png" alt="Fig.5" />
<figcaption aria-hidden="true">Fig.5</figcaption>
</figure>
<ol type="1">
<li>在训练时，基于显著性的方法通过梯度计算，直接将像素对给定短语的敏感度视为热力图的值。</li>
<li>基于注意力的方法将跨模态相关性视为热力图的值，与基于显著性的方法相比，其更受欢迎。</li>
</ol>
<blockquote>
<p>有的热图是根据标题中提到的每个实体的图像区域之间的相似性生成的，
而有的热图是根据图像区域与可能的事件参数角色类型之间的相似性生成的。</p>
</blockquote>
<blockquote>
<p>在测试时，对热图进行阈值设置，以获得可视对象的合适包围框。如果kg中已有视觉实体/概念的边界框与新的边界框没有重叠，则将该边界框创建为新的视觉实体或概念。</p>
</blockquote>
<p>尽管视觉定位方法不依赖于带有边界框的标记数据，但实际上仍需要人工验证。
一些工作试图在训练阶段增加对常识、关系和事件参数的约束，以增加监督信息。
在与MMKG的构建相关的工作中，视觉定位的精确度低于 70%。</p>
<p>通过视觉定位的视觉对象可以是实体（例如 Barack Hussein
Obama）、概念（例如地点、汽车、石头）、属性（例如红色、短）。然而，图像和文本的语义尺度不一致可能导致不正确的匹配。例如，<strong>troops</strong>可能会映射到<strong>several
individuals wearing military uniforms</strong>，而<strong>Ukraine
(country)</strong>可能会映射到<strong>Ukrainian
flag</strong>，这两者都是相关的但并不等同。</p>
<h5 id="opportunities">Opportunities</h5>
<p>随着多模态预训练语言模型的出现，多模态预训练语言模型强大的表示能力增强了提取实体和概念的能力。
图像块和单词的映射可以直接在模型的自注意力图中可视化，而无需额外的训练。
ViLT 的预测示例如图 6 所示。多模态预训练语言模型如
CLIP，在数亿网络规模的图像-文本数据上进行了预训练，在著名人物和地标建筑上具有很高的准确性，这将在构建一个MMKG人物或建筑时减少大量的数据收集和模型训练工作量。一些预训练的视觉转换器模型已经具有很强的视觉对象分割能力，即使在高度模糊的情况下也能聚焦于前景对象，例如
DINO ，这将提高定位视觉对象和对齐跨模态知识的性能。</p>
<figure>
<img data-src="/images/body/Papers/MMKG-Survey/Fig6.png" alt="Fig.6" />
<figcaption aria-hidden="true">Fig.6</figcaption>
</figure>
<h4 id="visual-relation-extraction-视觉关系提取">Visual Relation
Extraction 视觉关系提取</h4>
<h5 id="challanges-1">Challanges</h5>
<p>虽然视觉关系检测在CV社区已经得到了广泛的研究，但大多数检测到的关系都是视觉对象之间的表面视觉关系，如(person,
standing on,
beach)。不同的是，为了构建MMKG，视觉关系提取任务旨在识别在kg中定义的更一般的语义关系类型，如(Jack,
spouse, Rose)。</p>
<h5 id="progresses-1">Progresses</h5>
<p>现有的工作大致可分为<strong>基于规则的关系抽取</strong>和<strong>基于统计的关系抽取</strong>，其余的一些工作主要集中在长尾关系和细粒度关系上。</p>
<h6 id="rule-based-relation-extration">Rule-based Relation
Extration</h6>
<p>传统的基于规则的方法主要关注一些特定类型的关系，如空间关系和动作关系。这些规则通常由专家预先定义，判别特征通过启发式方法进行评分和选择。</p>
<p>在基于规则的方法中，要检测的关系是根据标签的类型和区域的相对位置来定义的。例如，如果一个对象的边界框总是在另一个对象的边界框内，则它们之间可能存在
PartOf 关系。表 3
列出了在NEIL中检测到的几种视觉关系。提取过程中，检测到的一对对象之间的关系反过来又会对新实例标记的附加约束。例如，“Wheel
is a part of Car”表示 Wheel 更有可能出现在 Car
的边界框中。基于规则的方法提供高度准确的视觉关系，但它们依赖于大量的手动工作。所以在大规模MMKG建设中是不实用的。</p>
<figure>
<img data-src="/images/body/Papers/MMKG-Survey/Table3.png" alt="Table.3" />
<figcaption aria-hidden="true">Table.3</figcaption>
</figure>
<h6 id="statistic-based-general-relation-extration">Statistic-based
General Relation Extration</h6>
<p>基于统计的方法将检测到的对象的视觉特征、空间特征和统计等特征编码为分布式向量，并通过分类模型预测给定对象之间的关系。与基于规则的方法相比，基于统计的方法能够检测到训练集中出现的所有关系。</p>
<p>一些工作证明谓词在很大程度上依赖于主客体的类别，但主客体不依赖于谓词，主客体之间也没有依赖关系。
例如，在三元组（人、骑、大象）中，人和大象表示关系可能是骑而不是穿。因此，为了利用依赖关系，一些工作通过对象的标签将语言模型的语言先验添加到统计模型中，设置了一个更严格的约束，即三元组的隐藏层表示应满足主语
+ 谓词 <span class="math inline">\(\approx\)</span>
宾语。令人尴尬的是，语言模型带来很大的改进，但视觉信息的贡献却很小。</p>
<p>图像中检测到的对象和关系可以表示为图。图结构使边能够从其他节点和边中获得更多消息，从而以更高的精度对关系进行分类。例如，对象和关系可以表示为两个互补的子图，其中节点根据周围边的值迭代更新，反之亦然。
一些工作使用注意力图卷积神经网络来学习上下文对象和边。</p>
<h6 id="long-tail-and-fine-grained-relation-extraction">Long-tail and
Fine-grained Relation Extraction</h6>
<p>尽管基于统计的方法能够检测一般关系，但很难检测长尾关系。原因是具有大量样本的有偏差的数据集使得预测关系更加困难。为了消除训练集中不平衡样本的影响，为了消除训练集中不平衡样本的影响，学者提出了一种新的无偏度量(Mean
Recall@K)来平均所有类型关系的召回率，而不是所有样本的召回率，避免忽略只有少量样本的关系。还有很多其他的工作，主要是通过迁移学习、少镜头学习和对比学习来检测少量样本的关系，但仍然局限于隐层的特征融合。</p>
<p>细粒度关系是一种长尾关系。现有的从特征融合角度对长尾关系问题的研究未能很好地区分细粒度的关系。例如，例如，模型倾向于预测“on”而不是细粒度的关系“sit
on”/"walk on"/"lay on"。</p>
<p>检测更复杂和细粒度的关系更困难，例如人与对象交互和动作检测。因为一个人的姿势是由身体的许多组成部分决定的。例如，(person,
play, violin) 和 (person, hold, violin)
的图像之间存在细微差别。在早期研究中，动作被定义为身体不同部位的一系列姿态，并通过启发式方法挖掘识别特征。在目前基于统计量的检测中，判别特征采用更严格的对比损失函数滤波，但显然仍过于粗糙。</p>
<h5 id="opportunitiies">Opportunitiies</h5>
<p>尽管现有的工作很多，但仍有许多具有挑战性的问题没有解决。例如：</p>
<ol type="1">
<li><p><strong>视觉知识关​​系判断</strong>
许多从图像中提取的视觉三元组只描述了图像的场景，由于它们不是被广泛接受的事实，因此不能被视为视觉知识。难点在于我们如何从场景信息的三元组中识别视觉知识的三元组。</p></li>
<li><p><strong>基于推理的关系检测</strong>
现有的关系检测方法通过融合视觉特征和语言先验的隐藏统一表示来预测关系。例如，如果一个图像中有一个人和一个足球，并且(head,
look at, sth) (arm, swing, -) (foot, kick, sth)
同时满足，则该动作将被判断为(person, kick,
football)。不幸的是，这个数据集是手动构建的。我们需要自动总结关系检测的推理链。</p></li>
</ol>
<h4 id="visual-event-extraction-视觉事件提取">Visual Event Extraction
视觉事件提取</h4>
<p>视觉事件提取可以分为两个子任务:</p>
<ol type="1">
<li>预测视觉事件类型;以及</li>
<li>定位和提取源图像或视频中的对象作为可视参数</li>
</ol>
<h5 id="challenges">Challenges</h5>
<p>该任务面临以下几个挑战:</p>
<ol type="1">
<li>视觉事件提取需要对不同的事件类型预先定义模式，但大量的视觉事件还没有被专家定义。如何将视觉模式自动挖掘为事件模式?</li>
<li>如何从图像或视频中提取视觉事件的视觉论据?</li>
</ol>
<h5 id="progresses-2">Progresses</h5>
<p>当前工作主要focuses on两个方面: 1)
视觉事件模式挖掘，将最相关的视觉实体（或概念）检测并标记为新模式； 2)
视觉事件参数提取，根据事件模式从视觉数据中提取参数角色区域。</p>
<h6 id="visual-event-schema-mining">Visual Event Schema Mining</h6>
<p>例如，事件 Clipping 具有诸如 Agent、Source、Tool、Item、Place
等参数角色，并且在剪羊毛的图像中它们分别是
Man、Sheep、Shears、Wool、Field。该任务主要旨在识别视觉事件，而不是定位和提取其视觉参数。</p>
<p>然而，在大规模的可视化事件提取中（如新闻），许多事件的视觉图式还没有被手动定义，这需要大量专家的工作。</p>
<p>来自Internet的大量图像标题对使得挖掘和标记事件模式的视觉模式成为可能。因此，此任务简化为从给定事件的图像中查找指示正确事件类型的视觉模式的频繁项集。可以从带有事件触发器的图像标题对中检索事件的图像集合作为查询。通过视觉定位的方法，将候选图像补丁用文字或短语标注在字幕中。可以利用启发式方法(如Apriori算法)挖掘频繁的视觉图像补丁，找到关联规则，通过视觉模式预测事件类型。</p>
<h6 id="visual-event-arguments-extraction">Visual Event Arguments
Extraction</h6>
<p>视觉事件参数提取实际上是提取一组具有关系约束的视觉对象的任务。视觉参数可以通过完全监督方法(如对象识别)或弱监督方法(如视觉基础)进行标记。根据视觉事件提取的两个子任务，根据事件图像的全局特征对事件类型进行分类，并将事件参数提取为对事件类型最敏感的局部区域。</p>
<p>但是，在弱监督方法中，我们不能确定所提取的视觉对象之间的关系是否与文本中的关系一致。因此，视觉参数和文本参数的关系也应该分别对齐。有的工作将从一个事件的图像中提取的情景图与抽象意义表示图(AMR图)对齐，AMR图根据跨模态参数的语义和类别表示该事件标题的语义结构。联合提取中还增加了语义、事件类型、事件参数角色、视觉信息和文本信息一致性等诸多约束条件。</p>
<p>与图像相比，视频更适合于事件提取，因为一个事件的时间包围框可能跨越整个视频，所有的参数可能不会在一帧中显示。为了简化任务，可以从只包含一个事件的短视频片段中提取了三个关键帧的参数，这些关键帧是与视频标题最匹配的帧。</p>
<h5 id="opportunities-1">Opportunities</h5>
<p>这一课题的研究还处于早期阶段，还有很多问题值得探索。例如:</p>
<ol type="1">
<li>从包含多个事件的长视频中提取连续事件的问题还没有解决。</li>
<li>多子事件视频事件提取。例如，将“煮咖啡”事件分为清洁咖啡机→倒入咖啡豆→打开咖啡机等一系列步骤，每一步也可以视为一个事件。顺序步骤需要按照步骤的时间轴进行提取和列出，这是目前方法难以解决的问题。</li>
</ol>
<h3 id="from-symbols-to-images-symbol-grounding">From Symbols to Images:
Symbol Grounding</h3>
<p>符号定位是指寻找合适的多模态数据项(如图像)来表示传统KG中存在符号知识的过程。与图像标注方式相比，符号接地方式在MMKG施工中应用更为广泛。大多数现有的MMKG都是这样构造的。</p>
<p>We cover the process of grounding symbols to images in several
fractionized tasks: <strong>Entity Grounding</strong>, <strong>Concept
Grounding</strong>, <strong>Relation Grounding</strong>.</p>
<h4 id="entity-grounding">Entity Grounding</h4>
<p>实体定位旨在将知识图谱中的文本实体定位到其相应的多模态数据，例如图像、视频和音频。</p>
<h5 id="challenges-1">Challenges</h5>
<ol type="1">
<li>如何以低成本为实体找到足够多的高质量图像？</li>
<li>如何从大量噪声中选择最匹配实体的图像？</li>
</ol>
<h5 id="progresses-3">Progresses</h5>
<h6 id="from-online-encyclopedia-such-as-wikipedia">From Online
Encyclopedia (such as Wikipedia)</h6>
<p>在维基百科中，一篇文章通常用图像和其他多模态数据来描述一个实体。
Wikipedia 和 DBpedia 提供了许多工具（例如 Wikimedia Commons ）来帮助在
DBpedia 中的实体与 Wikipedia
中的相应图像或其他模态数据之间建立连接。研究人员很容易使用像维基百科这样的在线百科全书来构建大规模
MMKG 的第一个版本。</p>
<p>然而，基于百科全书的方法有三个主要缺点：</p>
<ol type="1">
<li>首先，每个实体的图像数量是有限的。维基百科中每个实体的平均图像数量为
1.16。</li>
<li>其次，维基百科中的许多实体图像仅与其对应的实体相关，而不是与实体完全相关。例如，维基百科中北京动物园的图片中存在动物、建筑、牌匾、雕刻等多张图片，很容易导致语义漂移。</li>
<li>最后，基于维基百科构建的MMKG的覆盖范围仍有待提高。英文维基百科有600万个实体（文章），这是从英文维基百科收获的MMKG容量的上限。根据我们的调查，近
80%的英文维基百科文章没有对应的图像，其中只有 8.6 %有超过 2
个图像。</li>
</ol>
<h6 id="from-the-internet-through-web-search-engines">From The Internet
Through Web Search Engines</h6>
<p>为了提高 MMKG
的覆盖率，提出了基于搜索引擎的解决方案。通过查询实体名称从搜索引擎的搜索结果中找到图像。一般来说，排名靠前的结果图像很有可能是要搜索的实体的正确图像。然而，基于搜索引擎的方法很容易将错误的事实引入
MMKG。众所周知，搜索引擎结果可能是嘈杂的。另一个原因是指定搜索关键字并非易事。例如，搜索查询“Bank”不足以找到
Commercial Bank 的图像，因为它也产生了 River Bank
的图像。因此，已经有很多清理候选图像的工作。通常通过添加父同义词集或实体类型来扩展查询词以消除歧义。在为实体选择最佳图像时，多样性也是不可忽视的问题。训练图像多样性检索模型以去除冗余的相似图像，使图像尽可能多样化。</p>
<p>由于在构建过程中实体及其视觉特征的解耦，基于实体接地的MMKG具有区分视觉相似实体的能力，如图7所示。实体定位方法使得构建面向领域的细粒度MMKG成为可能。</p>
<figure>
<img data-src="/images/body/Papers/MMKG-Survey/Fig7.png" alt="Fig.7" />
<figcaption aria-hidden="true">Fig.7</figcaption>
</figure>
<p>与基于百科全书的方法相比，基于搜索引擎的方法覆盖面更好，但质量更差，因此这两种方法经常一起使用。例如，可以通过从搜索引擎为每个实体收集更多图像或将每个图像映射到它包含的所有实体以扩大实体图像的数量来提高从维基百科获取的
MMKG 的覆盖范围。</p>
<h5 id="opportunities-2">Opportunities</h5>
<p>这个方向还有很多未解决的问题。 1)
实体被定位成几个图像，每个图像只是实体的一个方面。例如，一个人的图像集合可以是不同年龄的图像、生活照片、事件照片、单人照片和家庭照片。如何确定最典型的图像？图8以特朗普为例。</p>
<figure>
<img data-src="/images/body/Papers/MMKG-Survey/Fig8.png" alt="Fig.8" />
<figcaption aria-hidden="true">Fig.8</figcaption>
</figure>
<ol start="2" type="1">
<li>现实世界的实体是多角度的，在不同的上下文中将一个实体与多个图像相关联是合理的。这促使我们提出一项新的多定位任务，该任务从给定特定上下文的实体中选择最相关的图像。例如，美国第
45 任和现任总统唐纳德·特朗普 (Donald Trump)
拥有许多可以从网络上收集的不同图像。但如图 8
所示，任何单个图像都不适用于所有不同的上下文。然而，将实体的不同方面映射到不同上下文中最相关的图像并非易事。首先，实体的图像池很难建立，因为图像池的完整性无法保证，在某些上下文中很容易漏掉一些相关的图像。其次，为特定上下文的实体消歧图像具有挑战性，因为上下文通常是嘈杂的并且包含稀疏信息，并且需要更多的背景信息来指导语义信息的获取。最后，作为一项新任务，标记数据的缺乏是一个大问题。</li>
</ol>
<h3 id="concept-grounding">Concept Grounding</h3>
<p>概念定位旨在为视觉概念找到具有代表性的、有区别的和多样化的图像。</p>
<h4 id="challenges-2">Challenges</h4>
<p>虽然一些视觉上统一的概念（如男人、女人、卡车和狗）也可以使用实体定位方法连接到图像。然而</p>
<p>1）并非所有的概念都可以正确可视化。例如，irreligionist（非宗教主义者）不能指定某种具体醒醒。因此，如何区分可视化概念和非可视化概念成为一个难点</p>
<p>2）如何从一组相关图像中找到一个可视化概念的代表性图像？请注意，可视化概念的图像可能非常多样化。例如，一提到公主，人们往往会想到几种不同的形象，迪士尼公主、历史电影中的古代公主或新闻中的现代公主。因此，我们必须考虑图像的多样性。</p>
<h4 id="progresses-4">Progresses</h4>
<p>针对上述挑战，相关研究分为三个任务：<strong>可视化概念判断</strong>、<strong>代表性图像选择</strong>和<strong>图像多样化</strong>。</p>
<h5 id="可视化概念判断">可视化概念判断</h5>
<p>该任务旨在判断概念是否可视化，研究人员发现只有 12.8 %的 Person
子树的同义词集具有公认的可视化性。并且许多其余同义词集没有相应的视觉描述。例如，摇滚明星是可视化的，而求职者是不可视化的。手动注释在构建大规模
MMKG 时明显不实用。</p>
<p>为了自动判断视觉概念，研究人员构建了以下方法，比如：认为抽象名词概念是非可视化的，只收集非抽象名词概念的图像。但是，这些方法都不是很准确。例如，愤怒或快乐可以指定为一个人感到愤怒或快乐的形象。由于图像来自互联网，因此可以使用搜索引擎点击来识别视觉概念。例如，如果谷歌图片点击的数量大于谷歌网络点击的数量，可以表明一个实体可能是可视化的。</p>
<p>此外，可视化的高质量图像的一些特征可以用来识别视觉概念，例如代表性和辨别性。
一些研究人员认为具有代表性图像的前景是相似的，前景易于与背景分离，并且具有较小的类间方差。因此，因此考虑反过来训练分类器来选择其图像集合具有这些特征的概念。</p>
<h5 id="代表性图像选择">代表性图像选择</h5>
<p>该任务本质上旨在根据图像的代表性重新排列图像。图像的代表性是根据基于聚类的方法的结果来评分的，例如
K-means、谱聚类等。聚类内的方差越小，聚类中图像的得分越高。在对图像的代表性得分重新排序后，排在前面的可能是代表性图像。此外，图像也受到规则的约束，以区分不同的簇。例如，一些工作添加了一个新的度量标准来对图像和聚类内的相似度进行排序，即类间距离和类内距离的比率，比率越大，图像的判别力越强。</p>
<p>来自搜索引擎的图像的标题和标签也可以用来评估图像在语义层面的代表性和区分性。标题和标签提供图像没有的语义信息。例如，一张冰岛风景的照片和一张英国风景的照片可能看起来很相似，但文本标签可以帮助我们区分它们的概念差异。一些工作中，标签基于语义特征进行聚类，图像根据标签的语义聚类重新分配到每个聚类中。</p>
<h5 id="多样化图像选择">多样化图像选择</h5>
<p>该任务要求以概念为基础的图像应平衡多样性和相关性。图像也应该在聚类后重新排序，但与代表性图像选择的区别在于，我们想展示尽可能多的集群的结果。
具体来说，在每次选择中，尽量从聚类中选择没有被选择的图像。</p>
<p>这些研究集中在文本图像检索领域，很少有与多模态知识图谱相关的研究。来自互联网的关于性别、种族、肤色和年龄的概念图像的多样性仍然存在许多未解决的偏见，现在这个问题在很大程度上依赖于众包。</p>
<h4 id="opportunities-3">Opportunities</h4>
<h5 id="抽象概念定位">抽象概念定位。</h5>
<p>以前关于概念可视化判断的工作很少考虑抽象概念。但抽象的概念也可以以图像为基础。例如，快乐通常与微笑联系在一起，而愤怒通常与愤怒的脸联系在一起。一些抽象名词具有多样而固定的视觉联想，如自然、人、行为等。例如，“美”的图像与以下词群相关:女人/女孩、水/海滩/海洋、花/玫瑰、天空/云/日落。同样，爱的形象与以下词群相关:婴儿/可爱/新生儿，狗/宠物，心/红/情人节，海滩/海/情侣，天空/云/日落，花/玫瑰。可以看出，一些抽象名词在情感上往往具有一般的、固定的意象，在语义上往往具有辨别性的意象。</p>
<h5 id="动名词概念基础">动名词概念基础。</h5>
<p>动名词是一类特殊的名词，可以转化为动词，如singing→sing。通过众包将许多动名词与图片联系起来，例如争吵、摔跤和跳舞。这些涉及人际交往的动词对人的身体角度、注视角度、关节位置和表情等特征较为敏感。</p>
<h5
id="通过实体定位的非可视化概念定位">通过实体定位的非可视化概念定位。</h5>
<p>如果一个概念是非可视化的，但这个概念的实体是可以可视化的，那么这个概念也可以通过它的实体来建立基础。例如，合理选择这样一个概念的接地图像是使用该概念最典型实体的图像。如使用一张爱因斯坦的照片作为物理学家这个概念的基础。这是合理的，因为当我们提到物理学家时，我们大多数人都会想到爱因斯坦。但是，目前还存在许多未解决的问题:(a)一般来说，不同的人对一个概念的思考具有不同的典型实体，因此在概念的基础上要解决这种主观性。一个实体在其概念的约束下是否是一个典型的实体?(b)我们应该选择几个典型实体的图像来表达这个概念。如何总结和选择典型实体来表示概念?(c)我们是否应该从多个实体图像中提取共同的视觉特征?</p>
<h3 id="relation-grounding">Relation Grounding</h3>
<p>关系定位是从图像数据语料库或互联网中找到可以表示特定关系的图像。输入可以是这个关系的一个或多个三元组，输出应该是这个关系中最具代表性的图像。</p>
<h4 id="challenges-3">Challenges</h4>
<p>当我们将三元组作为查询来检索关系的图像时，排名靠前的图像通常与三元组的主题和对象更相关，但与关系本身无关。如何找到能够反映输入三元组语义关系的图像？</p>
<h4 id="progresses-5">Progresses</h4>
<p>现有的关系指定研究侧重于空间或动作关系，例如left of、on、ride
和eat。</p>
<p>虽然文本问询可以通过抽象语义表示图（主题、关系、对象）的格式表示为结构化数据，但候选图像也可以结构化为场景图。然后，通过文本-图像匹配或图形匹配，可以将结构化文本和结构化图像进行细粒度匹配，下面将具体展开。</p>
<h5 id="文本图像匹配">文本图像匹配</h5>
<p>在文本-图像匹配任务中，文本和图像通常表示为统一语义嵌入空间中的向量。通过跨模态表示的相似度得分找到与查询最匹配的图像。跨模态表示通常由注意力机制融合，因此全局表示的缺点是缺乏显式细粒度关系的语义。除了基于表示的检索之外，一种更方便的方法是基于标题的检索，如互联网上的搜索引擎。基于标题的检索的缺点是没有使用视觉特征进行匹配。</p>
<p>为了表示对象之间的明确关系，许多研究集中在考虑图像局部结构的图像编码器上。最终的图像表示是全局视觉特征、局部结构特征和文本对齐嵌入的融合。一些工作将所有一阶（实体或概念）、二阶（属性或动作）、三阶（三元组）事实均统一遵循
建模，分别由多层图像编码器的不同分支的输出来表示。
一些研究使用场景图来表示图像中的所有三元组
，并使用图卷积神经网络来学习视觉关系。最后，每张图像学习到的​​所有具有关系特征的视觉表示都必须接近。因此，可以通过使用三元组作为查询而不是句子来直接检索匹配的图像。</p>
<p>多模态预训练语言模型是考虑对象（实体或概念）和三元组的图像编码器的新替代方案。对于每个图像-标题对，使用场景图解析器从图像的标题中生成包含对象、属性和关系的场景图，然后将场景图的对象、属性和关系节点随机替换为与对应的词汇表不同的对象、属性或关系来生成大量的硬负样本。
ERNIEViL通过增加三个预训练任务，对象预测、属性预测和关系预测来增强视觉和语言模型的能力。</p>
<h5 id="图匹配">图匹配</h5>
<p>我们期望通过对象和关系的显式匹配而不是统一的跨模态嵌入的隐式匹配来建立关系基础。一种更方便的方法是基于标题的检索，如
Internet 上的搜索引擎，匹配实体的标记与
问询与标题之间的关系。基于标题的检索的缺点是没有使用视觉特征进行匹配。例如，Richpedida
提出了一个非常强的假设，即如果 Wikipedia
描述中的两个实体之间存在预定义的关系（例如 nearBy 和
contains），则两个实体对应的视觉实体之间也存在相同的关系。但实际上，这两个对象更有可能不会同时出现在一张图像中。如果我们将文本查询和候选图像表示为图形，则关系指定任务变成了图形匹配任务，如图
9
所示。可以将图像结构化为图形，其中节点是对象，边是关系。文本问询中的依赖关系可以建模为依赖分析树，它也是一个图。一个简单的解决方案是只匹配两个图中的对象和共现关系而不预测关系类型，即假设如果两个实体之间存在关系，则该关系被认为是匹配的，这也是一个强假设。显然，关系预测模块是必不可少的。
一些研究用GCN分别表示两个场景图，其中对象自己进行更新，关系节点从其邻居的聚合更新。预测时，分别测量两个不同形式的图的相似度：对象节点匹配和关系节点匹配。</p>
<figure>
<img data-src="/images/body/Papers/MMKG-Survey/Fig9.png" alt="Fig.9" />
<figcaption aria-hidden="true">Fig.9</figcaption>
</figure>
<h4 id="opportunities-4">Opportunities</h4>
<p>现有研究主要集中在空间关系和动作关系的基础上，这些关系可以在图像中直观地观察到。但是，大多数其他关系例如isA,
Occupation, Team and
Spouse在图像中可能并不明显。这些关系通常缺乏训练数据，因此很难用上述两种解决方案训练模型来检索图像。</p>
<h1 id="总结分析">总结/分析</h1>
<h2
id="多模态知识图谱综述链接预测部分参考文献">多模态知识图谱综述链接预测部分参考文献：</h2>
<ul>
<li>134 Translating embeddings for modeling multi-relational data
<strong>2013</strong> 就是TransE。</li>
<li>136 Learning entity and relation embeddings for knowledge graph
completion <strong>2015</strong> 是TransR。</li>
<li>141 Representation learning of knowledge graphs with entity
descriptions <strong>2016</strong> 具有实体描述的知识图谱表示学习。</li>
<li>142 Modeling relation paths for representation learning of knowledge
bases <strong>2015</strong> PTransE 对多跳关系的建模。</li>
<li>143 Reasoning with neural tensor networks for knowledge base
completion <strong>2013</strong>
如果两实体名字中有相同的字符串，比如apple pie和apple
cake，以往的工作中他们的嵌入是没有什么关系的，这篇以全新的方式（词向量的平均值）来嵌入实体，并且提出了新的神经网络结构ntn。</li>
</ul>
<p>以上都是单一模态知识图谱的工作，下面的才是多模态的：</p>
<ul>
<li><p>138 A multimodal translation-based approach for knowledge graph
representation learning <strong>2018</strong>
有点像是多模态的transE，主要将多模态信息与图谱结构相结合，三种融合方式，将文本信息与多模态信息拼接，将文本信息映射到多模态信息空间中，将多模态信息映射到文本信息空间中。设计了一个打分（能量）函数。别的没有什么特殊的地方。</p></li>
<li><p>144 Image-embodied knowledge representation learning
<strong>2016</strong>
IKRL是第一个将图像中的视觉信息显式编码为知识表示的尝试。</p></li>
<li><p>140 Embedding multimodal relational data for knowledge base
completion <strong>2018</strong>
提出了多模态知识库嵌入（MKBE），它对这些观察数据使用不同的神经编码器，并将它们与现有的关系模型相结合，以学习实体和多模态数据的嵌入。使用这些学习的嵌入和不同的神经解码器，引入了一种新的多模态插补模型，以从知识库中的信息生成缺失的多模态值，如文本和图像。</p></li>
<li><p>23 Answering visual-relational queries in web-extracted knowledge
graphs <strong>2017</strong>
基于FB15k构建了一个ImageGraph，使用卷积提取视觉特征然后和知识图谱嵌入相结合。<strong>给定一个不属于已知kg的图像，该模型可以给出其与另一个给定图像的关系，但我们并不知道他们对应的实体是什么</strong></p>
<ol type="1">
<li>给定一对不可见的图像，我们不知道它们的KG实体，确定潜在实体之间的未知关系。</li>
<li>给定一个不可见的图像(我们不知道其底层KG实体)和一个关系类型，确定完成查询的可见图像</li>
<li>给定一个不属于KG的全新实体的不可见图像，以及一个我们不知道底层KG实体的不可见图像，确定两个底层实体之间未知的关系。</li>
<li>给定一个不属于KG的全新实体的不可见图像和一个已知的KG实体，确定两个实体之间未知的关系。
对于这些查询类型中的每一个，在训练期间都没有观察到底层实体之间的关系。
查询类型(3)和(4)是zero-shot学习的一种形式。因为在训练过程中，新实体与其他实体的关系以及它的图像都没有被观察到。这些考虑说明了可视化查询类型的新颖特性。机器学习模型必须能够学习KG的关系语义，而不是简单地将图像分配给实体的分类器。</li>
</ol></li>
<li><p>24 Mmkg: Multi-modal knowledge graphs <strong>2019</strong>
MMKG数据集将三个知识图谱数据集Freebase15k、DBpedia15k和YAGO15k使用sameAs关系连接起来，该文章只学习了sameAs关系，证明了不同模态对同一链接预测任务是互补的。</p></li>
</ul>
<h2 id="多模态知识图谱数据集">多模态知识图谱数据集：</h2>
<p>DBpedia</p>
<p>DBpedia作为近十年来语义网研究的中心领域，其丰富的语义信息也将会成为今后多模态知识图谱的链接端点，其完整的本体结构对于构建多模态知识图谱提供了很大的便利。DBpedia项目是一个社区项目，旨在从维基百科中提取结构化信息，并使其可在网络上访问。DBpedia知识库目前描述了超过260万个实体。对于每个实体，DBpedia定义了一个唯一的全局标识符，可以将其解引用为网络上一个RDF描述的实体。DBpedia提供了30种人类可读的语言版本，与其他资源形成关系。在过去的几年里，越来越多的数据发布者开始建立数据集链接到DBpedia资源，使DBpedia成为一个新的数据web互联中心。目前，围绕DBpedia的互联网数据源网络提供了约47亿条信息，涵盖地理信息、人、公司、电影、音乐、基因、药物、图书、科技出版社等领域。</p>
<p>Wikidata</p>
<p>Wikidata中也存在大量的多模态资源，Wikidata是维基媒体基金会(WMF)联合策划的一个知识图谱，是维基媒体数据管理策略的核心项目。充分利用Wikidata的资源，主要挑战之一是提供可靠并且强大的数据共享查询服务，维基媒体基金会选择使用语义技术。活动的SPARQL端点、常规的RDF转储和链接的数据api是目前Wikidata的核心技术，Wikidata的目标是通过创造维基百科全球管理数据的新方法来克服数据不一致性。Wikidata的主要成就包括:Wikidata提供了一个可由所有人共享的免费协作知识库;Wikidata已经成为维基媒体最活跃的项目之一;越来越多的网站在浏览页面时都从Wikidata获取内容，以增加大数据的可见性和实用性。</p>
<p>IMGpedia</p>
<p>IMGpedia是一个大型的链接数据集，它从Wikimedia
Commons数据集中的图像中收集大量的可视化信息。它构建并生成了1500万个视觉内容描述符，图像之间有4.5亿个视觉相似关系，此外，在IMGpedia中单个图像与DBpedia之间还有链接。IMGpedia旨在从维基百科发布的图片中提取相关的视觉信息，从Wikimedia中收集所有术语和所有多模态数据(包括作者、日期、大小等)的图像，并为每张图像生成相应的图像描述符。链接数据很少考虑多模态数据，但多模态数据也是语义网络的重要组成部分。为了探索链接数据和多模态数据的结合，构建了IMGpedia，计算Wikipedia条目中使用的图像描述符，然后将这些图像及其描述与百科知识图谱链接起来。</p>
<p>IMGpedia是一个多模态知识图谱的先例。将语义知识图谱与多模态数据相结合，面对多种任务下的挑战和机遇。IMGpedia使用四种图像描述符进行基准测试，这些描述符的引用和实现是公开的。IMGpedia提供了Wikidata的链接。由于DBpedia中的分类对一些可视化语义查询不方便，所以IMGpedia旨在提供一个更好的语义查询平台。IMGpedia在多模态方向上是一个很好的先例，但也存在一些问题，比如关系类型稀疏，关系数量少，图像分类不清晰等，也是之后需要集中解决的问题。</p>
<p>MMKG</p>
<p>MMKG主要用于联合不同知识图谱中的不同实体和图像执行关系推理，MMKG是一个包含所有实体的数字特征和(链接到)图像的三个知识图谱的集合，以及对知识图谱之间的实体对齐。因此，多关系链接预测和实体匹配社区可以从该资源中受益。MMKG有潜力促进知识图谱的新型多模态学习方法的发展，作者通过大量的实验验证了MMKG在同一链路预测任务中的有效性。</p>
<p>MMKG选择在知识图谱补全文献中广泛使用的数据集FREEBASE-15K
(FB15K)作为创建多模态知识图谱的起点。知识图谱三元组是基于N-Triples格式的，这是一种用于编码RDF图的基于行的纯文本格式。MMKG同时也创建了基于DBpedia和YAGO的版本，称为DBpedia-15K(DB15K)和YAGO15K，通过将FB15K中的实体与其他知识图谱中的实体对齐。其中对于基于DBpedia的版本，主要构建了sameAs关系，为了创建DB15K，提取了FB15K和DBpedia实体之间的对齐，通过sameAs关系链接FB15K和DBpedia中的对齐实体；构建关系图谱，来自FB15K的很大比例的实体可以与DBpedia中的实体对齐。但是，为了使这两个知识图谱拥有大致相同数量的实体，并且拥有不能跨知识图谱对齐的实体，在DB15K中包括了额外的实体；构建图像关系，MMKG从三大搜索引擎中获取相应文本实体的图像实体，生成对应的文本-图像关系。但是，它是专门为文本知识图谱的完成而构建的，主要针对小数据集(FB15K,
DBPEDIA15K,
YAGO15K)。MMKG在将图像分发给相关文本实体时也没有考虑图像的多样性。</p>
<p>还有之前提到的ImageGraph应该也算。</p>
<h2 id="推荐系统">推荐系统</h2>
<p>将时序信息引入知识图谱可能效果会更好，因为每个人的兴趣很有可能因为时间而改变，用户链接任务也可以通过引入时序的知识图谱完成？</p>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>Papers</tag>
      </tags>
  </entry>
  <entry>
    <title>Suda-charging-monitor</title>
    <url>/Life/Suda-charging-monitor/</url>
    <content><![CDATA[<p>苏州大学充电桩监控（已弃用！）</p>
<span id="more"></span>
<h1 id="suda-charging-piles-monitor">SUDA Charging Piles Monitor</h1>
<p>苏州大学充电桩监控</p>
<p>项目因某些原因已废弃！</p>
<p>代码已开源至<a
href="https://github.com/willkyu/SUDA_Charging_Piles_Monitor">我的GitHub仓库</a>。</p>
<h2 id="使用说明">使用说明</h2>
<ul>
<li><p>打开网站 &lt;yayan.xyz&gt;，填写相关信息。</p></li>
<li><p>关注邮箱，等待回信。</p>
<blockquote>
<p>如果选择“监控”，则可能需要等待5秒左右的时间收到Email，提示你开始监控。</p>
</blockquote>
<blockquote>
<p>如果选择“查询”，则会在1秒内发送Email给你。</p>
</blockquote></li>
<li><p>如果你监控的充电桩中途不进行充电了（被人拔了或其他原因无法充电），会在15秒内给你回Email通知你。</p></li>
<li><p>如果你监控的充电桩已充电6小时，则会自动取消监控并给你发送回执邮件。</p></li>
</ul>
<h2 id="注意事项">注意事项</h2>
<ul>
<li><p><strong><em>请输入正确的邮箱</em></strong></p></li>
<li><p><strong><em>不要重复提交（可以再次提交以更换监控的充电桩）</em></strong></p></li>
<li><p><strong><em>如果你碰上拔你充电器的人，请与他好好交流，避免肢体冲突</em></strong></p></li>
</ul>
<h2 id="其他的话">其他的话</h2>
<p>邮件全部采用英文是因为采用不同邮箱接收可能会导致中文的乱码问题。</p>
<p>如果你要自己搭建属于自己的监控，请将<strong>util.py</strong>中的一些邮件相关配置替换为自己的发件箱，运行<strong>flaskapp.py</strong>与<strong>chargingmonitor.py</strong>。</p>
<h2 id="致谢">致谢</h2>
<p>感谢苏大的<a
href="http://sudacharge.haoxiaoren.com/">充电助手网站</a>，该项目就是基于这个网页写的。</p>
<p>感谢室友<a
href="https://github.com/Gladduck">gladdduck</a>写的前端与一些改进，服务器、域名也由他提供！</p>
<p>感谢别的室友为我们测试并发现一些bug！</p>
<p>如果你有任何建议或反馈，可以通过GitHub账号内的联系方式联系我们！</p>
]]></content>
  </entry>
  <entry>
    <title>基础知识01</title>
    <url>/Learning/Notes/2022Summer/the-Basics01/</url>
    <content><![CDATA[<ul>
<li>张量</li>
<li>参数初始化策略</li>
<li>参数范数与正则化</li>
<li>梯度下降法</li>
<li>梯度爆炸与梯度消失</li>
<li>自适应学习率算法</li>
<li>评估指标</li>
<li>归一化</li>
<li>Dropout</li>
<li>激活函数</li>
<li>损失函数</li>
<li>反向传播算法（公式推导）</li>
<li>过拟合与欠拟合</li>
</ul>
<span id="more"></span>
<h1 id="张量">张量</h1>
<p>张量（tensor）是一个<strong>多维数组</strong>，张量的<strong>阶数（order）</strong>也称为维度（dimensions）。</p>
<p>一阶张量是一个<strong>矢量</strong>，二阶张量是一个<strong>矩阵</strong>，三阶或更高阶的张量叫做<strong>高阶张量</strong>。</p>
<!--
![三阶张量](/images/body/the-Basics01/third-order-tensor.png "A third-order tensor")
-->
<figure>
<img data-src="pics01/third-order-tensor.png" title="A third-order tensor"
alt="三阶张量" />
<figcaption aria-hidden="true">三阶张量</figcaption>
</figure>
<h2 id="张量的范数">张量的范数</h2>
<p>张量 <span class="math inline">\(\mathscr{X} \in \mathbb{R}^{I_1
\times I_2 \times \cdots \times I_N}\)</span>
的范数（norm）是其<strong>所有元素平方和的平方根</strong>，即</p>
<p><span class="math display">\[
\Vert \mathscr{X} \Vert =
\sqrt{\sum_{i_1=1}^{I_1}{\sum_{i_2=1}^{I_2}{\cdots
\sum_{i_N=1}^{I_N}{x_{i_1i_2 \cdots i_N}^2}}}}
\]</span></p>
<h2 id="张量的内积">张量的内积</h2>
<p>两个相同大小的张量 <span class="math inline">\(\mathscr{X} ,
\mathscr{Y} \in \mathbb{R}^{I_1 \times I_2 \times \cdots \times
I_N}\)</span> 的内积（inner product）为</p>
<p><span class="math display">\[
\langle \mathscr{X} , \mathscr{Y} \rangle =
\sum_{i_1=1}^{I_1}{\sum_{i_2=1}^{I_2} {\cdots
\sum_{i_N=1}^{I_N}{x_{i_1i_2 \cdots i_N} y_{i_1i_2 \cdots i_N}}}}
\]</span></p>
<p>且有 <span class="math inline">\(\langle \mathscr{X} , \mathscr{X}
\rangle = \Vert \mathscr{X} \Vert^2\)</span></p>
<h2 id="一些代码实现">一些代码实现</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 生成一个随机的(n,m)的矩阵，其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态</span><br><span class="line">x=torch.randn(3, 4)</span><br><span class="line"></span><br><span class="line"># 使用 arange 创建一个行向量 x。这个行向量包含以0开始的前n个整数，它们默认创建为整数</span><br><span class="line">x = torch.arange(12)</span><br><span class="line"></span><br><span class="line"># 查看x的形状</span><br><span class="line">x.shape</span><br><span class="line"></span><br><span class="line"># 改变x的形状 元素的个数总和不能改变</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">view和reshape都是用来重塑tensor的shape的。</span><br><span class="line">view只适合对满足连续性条件（contiguous）的tensor进行操作，</span><br><span class="line">而reshape同时还可以对不满足连续性条件的tensor进行操作，具有更好的鲁棒性。</span><br><span class="line">view能干的reshape都能干，如果view不能干就可以用reshape来处理</span><br><span class="line">参考连接：https://blog.csdn.net/Flag_ing/article/details/109129752</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">x.reshape(3,4)</span><br><span class="line"></span><br><span class="line"># 查看设备是否能使用cuda</span><br><span class="line">torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line"># 把张量移动到GPU上</span><br><span class="line"># DEVICE=&#x27;cuda:0&#x27;</span><br><span class="line">DEVICE=&#x27;cpu&#x27;</span><br><span class="line">x.to(DEVICE)</span><br><span class="line"># 或者</span><br><span class="line"># x.cuda()</span><br><span class="line"></span><br><span class="line"># 查看张量所在的设备</span><br><span class="line">x.device</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 基本的加减乘除</span><br><span class="line">x = torch.tensor([1.0, 2, 4, 8])</span><br><span class="line">y = torch.tensor([2, 2, 2, 2])</span><br><span class="line">x + y, x - y, x * y, x / y, x ** y</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 两个向量在同一维度上的拼接</span><br><span class="line">X = torch.arange(12, dtype=torch.float32).reshape((3,4))</span><br><span class="line">Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])</span><br><span class="line">torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 两个向量在新维度上的堆叠</span><br><span class="line">X = torch.arange(12, dtype=torch.float32).reshape((3,4))</span><br><span class="line">Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])</span><br><span class="line">torch.stack((X, Y), dim=0)</span><br></pre></td></tr></table></figure>
<p>索引切片和广播机制
就像在任何其他Python数组中一样，张量中的元素可以通过索引和切片访问。
张量的广播机制和numpy的广播机制一样 切片和python内置的数组一样
两个张量形状不一样时进行运算，有两种情况能够进行广播</p>
<ol type="1">
<li><p>A.ndim &gt; B.ndim, 并且A.shape最后几个元素包含B.shape,
A.shape=(2,3,4,5), B.shape=(3,4,5) A.shape=(2,3,4,5), B.shape=(4,5)
A.shape=(2,3,4,5), B.shape=(5)</p></li>
<li><p>A.ndim == B.ndim,
并且A.shape和B.shape对应位置的元素要么相同要么其中一个是1,
A.shape=(1,9,4), B.shape=(15,1,4) A.shape=(1,9,4),
B.shape=(15,1,1)</p></li>
</ol>
<h1 id="参数初始化策略">参数初始化策略</h1>
<p>参数初始化指的是网络模型在进行训练之前，对各个节点的权重和偏置进行初始化赋值的过程。</p>
<p>深度学习中，神经网络的参数初始化策略对模型的收敛速度及性能有至关重要的影响。在神经网络中，随着层数的增多，在梯度下降的过程中极易出现<a
href="#梯度爆炸与梯度消失">梯度消失或梯度爆炸</a>的问题，一个好的参数初始化对于处理这两个问题有着很大帮助。</p>
<h2 id="初始化为常数过大或过小">初始化为常数、过大或过小</h2>
<p>这些初始化策略都是不可取的，常数初始化会使得每层所有神经元相等，效果等效于一个神经元，极大限制了神经网络的学习能力。而参数过大过小会导致模型出现梯度爆炸或梯度消失的问题。</p>
<p>具体推导过程可见：<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMzgwNjQxODg=">https://zhuanlan.zhihu.com/p/138064188<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="什么样的初始化是好的">什么样的初始化是好的？</h2>
<ul>
<li>因为对参数 <span class="math inline">\(w\)</span>
的大小和正负缺乏先验知识，<span class="math inline">\(w\)</span>
应为随机数，且期望 <span class="math inline">\(E(w) = 0\)</span> 。</li>
<li>为了防止梯度爆炸和梯度消失，权重不宜过大或过小，要对权重的方差 <span
class="math inline">\(Var(w)\)</span> 有所控制。</li>
<li>由于 <span class="math inline">\(dW_{l} = \frac{1}{m}dZ_{l}\cdot
A_{l-1}^T\)</span>，<span class="math inline">\(dW_{l}\)</span> 还与
<span class="math inline">\(A_{l-1}^T\)</span>
有关，所以我们希望不同激活层输出的方差相同，即 <span
class="math inline">\(Var(a_l) = Var(a_{l-1})\)</span>
，也就意味着不同激活层输入的方差相同，即 <span
class="math inline">\(Var(z_l) = Var(z_{l-1})\)</span> 。</li>
<li>权重的数值范围应考虑到前向与后向两个过程，不能过大或过小。</li>
</ul>
<h2 id="xavier初始化策略">Xavier初始化策略</h2>
<p>论文地址：<a
href="https://link.zhihu.com/?target=http%3A//jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf">Understanding
the difficulty of training deep feedforward neural networks</a></p>
<p><strong>核心思想：正向传播时，激活值的方差保持不变；反向传播时，关于状态值的梯度的方差保持不变</strong></p>
<p>Xavier初始化将每层权重设置在有界的随即均匀分布中选择的值</p>
<p><span class="math display">\[
\pm \frac{\sqrt{6}}{\sqrt{n_i+n_{i+1}}}
\]</span></p>
<p>其正态分布形式为</p>
<p><span class="math display">\[
(u, \sigma^2) = (0, \frac{2}{n_{i-1}+n_{i}})
\]</span></p>
<p>Xavier初始化策略对<strong>使用关于零对称且在[-1,
1]内有输出的激活函数（如softsign和tanh）</strong>效果较好，而如果使用ReLU激活函数则会产生梯度消失。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def Xavier(m, h):</span><br><span class="line">    return torch.Tensor(m, h).uniform_(-1, 1) * math.sqrt(6. / (m + h))</span><br><span class="line"></span><br><span class="line">x = torch.randn(512)</span><br><span class="line">for i in range(100):</span><br><span class="line">    a = Xavier(512, 512)</span><br><span class="line">    x = torch.tanh(a @ x)</span><br><span class="line">print(x.mean(), x.std())</span><br><span class="line"></span><br><span class="line">x = torch.randn(512)</span><br><span class="line">for i in range(100):</span><br><span class="line">    a = Xavier(512, 512)</span><br><span class="line">    x = torch.relu(a @ x)</span><br><span class="line">print(x.mean(), x.std())</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensor(0.0072) tensor(0.0723)</span><br><span class="line">tensor(5.5722e-16) tensor(8.1033e-16)</span><br></pre></td></tr></table></figure>
<h2 id="kaiming初始化策略">Kaiming初始化策略</h2>
<p>论文地址：<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE1MDIuMDE4NTI=">Delving Deep
into Rectifiers: Surpassing Human-Level Performance on ImageNet
Classification<i class="fa fa-external-link-alt"></i></span></p>
<p><strong>核心思想：正向传播时，状态值的方差保持不变；反向传播时，关于激活值的梯度的方差保持不变</strong></p>
<p>Kaiming初始化（也称he初始化）是针对Relu激活函数的初始化方法，作者证明了如果采用一下输入权重初始化策略，深层网络会更早收敛：</p>
<ul>
<li>使用适合给定图层的权重矩阵创建张量，并使用从标准正态分布中随机选择的数字填充它。</li>
<li>将每个随机选择的数字乘以<span
class="math inline">\(\frac{\sqrt{2}}{\sqrt{n}}\)</span>，其中n是从前一层输出到指定层的连接数（fan-in）</li>
<li>偏差张量初始化为零。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def Kaiming(m, h):</span><br><span class="line">    return torch.randn(m, h) * math.sqrt(2. / m)</span><br><span class="line"></span><br><span class="line">x = torch.randn(512)</span><br><span class="line">for i in range(100):</span><br><span class="line">    a = Kaiming(512, 512)</span><br><span class="line">    x = torch.relu(a @ x)</span><br><span class="line">print(x.mean(), x.std())</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensor(0.7144) tensor(1.0703)</span><br></pre></td></tr></table></figure>
<h1 id="参数范数与正则化">参数范数与正则化</h1>
<p>正则化（regularization）技术广泛应用在机器学习和深度学习算法中，其<strong>本质作用是防止过拟合、提高模型泛化能力</strong>。在早期的机器学习领域一般只是将范数惩罚叫做正则化技术，而在深度学习领域认为：能够显著减少方差，而不过度增加偏差的策略都可以认为是正则化技术，故推广的正则化技术还有：扩增样本集、早停止、Dropout、集成学习、多任务学习、对抗训练、参数共享等</p>
<h2 id="范数">范数</h2>
<ol type="1">
<li>P范数：</li>
</ol>
<p><span class="math display">\[
L_p = (\sum_{i = 1}^n\vert x_i\vert^p)^{\frac{1}{p}}
\]</span></p>
<ol start="2" type="1">
<li>L0范数：表示向量中非零元素的个数</li>
<li>L1范数：为向量元素绝对值之和</li>
</ol>
<p><span class="math display">\[
\Vert x\Vert _1 = \sum_{i = 1}^n\vert x_i\vert
\]</span></p>
<ol start="4" type="1">
<li>L2范数：向量元素的平方和再开方，也称欧几里得距离</li>
</ol>
<p><span class="math display">\[
\Vert x\Vert _2 = \sqrt{\sum_{i = 1}^nx_i^2}
\]</span></p>
<ol start="5" type="1">
<li><span class="math inline">\(\infty\)</span>
范数：即所有向量元素绝对值中的最大值</li>
</ol>
<p><span class="math display">\[
\Vert x\Vert _\infty = \max_i\vert x_i\vert
\]</span></p>
<ol start="6" type="1">
<li><span class="math inline">\(-\infty\)</span>
范数：即所有向量元素绝对值中的最小值</li>
</ol>
<p><span class="math display">\[
\Vert x\Vert _{-\infty} = \min_i\vert x_i\vert
\]</span></p>
<h2 id="简单数值假设分析">简单数值假设分析</h2>
<!--
![不同参数下的曲线拟合结果(左欠拟合，右过拟合)](/images/body/the-Basics01/three-fitting-curve.jpg "Three fitting curve")
-->
<figure>
<img data-src="pics01/three-fitting-curve.jpg" title="Three fitting curve"
alt="不同参数下的曲线拟合结果(左欠拟合，右过拟合)" />
<figcaption
aria-hidden="true">不同参数下的曲线拟合结果(左欠拟合，右过拟合)</figcaption>
</figure>
<p>对于右边的拟合曲线，有</p>
<p><span class="math display">\[
h_\theta(x) = \theta _0 + \theta _1x_1 + \theta _2x_2^2 + \theta _3x_3^3
+ \theta _4x_4^4
\]</span></p>
<p>由于 <span class="math inline">\(\theta _3\)</span> 和 <span
class="math inline">\(\theta _4\)</span>
对应了高阶，导致拟合曲线是4阶曲线，出现了过拟合。正则化的目的为适当缩减
<span class="math inline">\(\theta _3\)</span> 和 <span
class="math inline">\(\theta _4\)</span>
的值，例如都为0.0001，则上述曲线本质上等价于</p>
<p><span class="math display">\[
h_\theta(x) = \theta _0 + \theta _1x_1 + \theta _2x_2^2
\]</span></p>
<p>也就是变成了中间的刚好合适的拟合曲线。对 <span
class="math inline">\(\theta _3\)</span> 和 <span
class="math inline">\(\theta _4\)</span>
增加L2正则项后的代价函数表达式为</p>
<p><span class="math display">\[
J(\theta) = \min_\theta \frac{1}{n} \sum_{i = 1}^n{((h_\theta(x^i) -
y^i)^2 + 1000\theta_3^2 + 1000\theta_4^2)}
\]</span></p>
<p>从上式可以看出， <span class="math inline">\(\theta _3\)</span> 和
<span class="math inline">\(\theta _4\)</span>
均大于0，其乘上了1000，要是 <span
class="math inline">\(J(\theta)\)</span> 最小，则会迫使模型学习到的
<span class="math inline">\(\theta _3\)</span> 和 <span
class="math inline">\(\theta _4\)</span> 会非常小，因为只有在 <span
class="math inline">\(\theta _3\)</span> 和 <span
class="math inline">\(\theta _4\)</span>
非常小的情况下整个代价函数值才会取的较小值。在实际开发中，是对所有参数进行正则化，为了使代价函数尽可能的小，所有的参数
<span class="math inline">\(\theta\)</span> 的值（不包括 <span
class="math inline">\(\theta_0\)</span>
）都会在一定程度上减小，但是减少程度会不一样，从而实现了权重衰减、简化模型复杂度的作用。</p>
<h2 id="参数范数与正则化的联系">参数范数与正则化的联系</h2>
<p>如果有一批数据输入指数为50的函数分布，我们至少需要输入50组数据来记录所有的函数对应的参
数。但对于深度学习这种拥有百万级参数规模的学习模型来说，那简直是不可想象的。</p>
<ol type="1">
<li>因此我们放松限制，仅仅控制参数的数目，而不是从高到低的顺序限制参数。我们将不为0的参数数
量限制再 c 以内来达到限制模型的目的(L0范数惩罚)。</li>
<li>虽然我们已经放松了限制，但是以上表达式并不完美，对于实际应用并不是太友好，那么我们不妨再
放松一下限制，不要求非零的参数个数控制再 c
以内，但要求参数绝对值数值的和控制再 c 以内。这种
参数数值总和的限制被称之为L1范数惩罚，也被成为参数稀疏性惩罚</li>
<li>虽然我们已经更加放松了限制，但是这还是不完美，因为带有绝对值，我们都知道，绝对值函数再求
梯度时不可导，因此我们再次放宽限制，将求绝对值和变为求平方和，如下式所示，这就是L2范数惩
罚，也就是我们熟悉的权重衰减惩罚。我们可以通过控制 c
值的大小来限制模型的学习能力，c 越大， 模型能力就越强（过拟合），c
越小，模型能力就越弱（欠拟合）。该条件极值可以通过拉格朗日乘子
法来进行求解。</li>
</ol>
<h1 id="梯度下降法">梯度下降法</h1>
<p>优化算法的功能是通过改善训练方法，来最小化（或最大化）损失函数 <span
class="math inline">\(J(\theta)\)</span>。</p>
<p>梯度下降背后的思想是：开始时我们随机选择一个参数的组合 <span
class="math inline">\((\theta _0, \theta _1, \theta _2, \dots, \theta
_n)\)</span>
，计算损失函数，然后我们寻找下一个能让损失函数值下降最多的参数组合。我们持续这么做直到到一个局部最小值（local
minimum），因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（global
minimum），选择不同的初始参数组合，可能会找到不同的局部最小值。</p>
<!--
![不同初始参数组合找到不同的极小值](/images/body/the-Basics01/different-local-minimum.png "Different local minimum")
-->
<figure>
<img data-src="pics01/different-local-minimum.png"
title="Different local minimum"
alt="不同初始参数组合找到不同的极小值" />
<figcaption
aria-hidden="true">不同初始参数组合找到不同的极小值</figcaption>
</figure>
<p>梯度下降算法如下：</p>
<p><span class="math display">\[
\theta _j := \theta _j - \alpha\frac{\partial}{\partial\theta
_j}J(\theta)
\]</span></p>
<p>其中 <span class="math inline">\(\alpha\)</span> 是学习率（learning
rate），它决定了我们沿着该方向迈出的步子有多大。<span
class="math inline">\(\alpha\)</span>
太大或太小都不好，太小会导致收敛速度很慢，而太大可能会越过最低点，甚至无法收敛。</p>
<!--
![梯度下降法](/images/body/the-Basics01/different-local-minimum.png "Gradient descent")
-->
<figure>
<img data-src="pics01/gradient-descent.png" title="Gradient descent"
alt="梯度下降法" />
<figcaption aria-hidden="true">梯度下降法</figcaption>
</figure>
<p>传统的批量梯度下降法计算整个数据集梯度，但只进行一次更新，这在处理大型数据集时速度很慢且难以控制，甚至导致内存溢出。</p>
<p>权重的更新速度由学习率 <span class="math inline">\(\alpha\)</span>
决定，并且可以在凸面误差曲线中收敛到全局最优值，在非凸曲面中可能趋于局部最优值。</p>
<p>此外，标准形式的批量梯度下降法在训练大型数据集时存在冗杂的权重更新。</p>
<h1 id="梯度爆炸与梯度消失">梯度爆炸与梯度消失</h1>
<h2 id="梯度爆炸">梯度爆炸</h2>
<p>误差梯度是神经网络训练过程中计算的方向和数量，用于以正确的方向和合适的量更新网络权重。
在深层网络或循环神经网络中，误差梯度可在更新中累积，变成非常大的梯度，然后导致网络权重的大幅更新，并因此使网络变得不稳定。在极端情况下，权重的值变得非常大，以至于溢出，导致
NaN 值。 网络层之间的梯度（值大于
1.0）重复相乘导致的指数级增长会产生梯度爆炸。在深度多层感知机网络中，梯度爆炸会引起网络不稳定，最好的结果是无法从训练数据中学习，而最坏的结果是出现无法再更新的NaN权重值。</p>
<h2 id="梯度消失">梯度消失</h2>
<p>在某些情况下，梯度会变得非常小，有效地阻止了权重值的变化。在最坏的情况下，这可能会完全停止神经网络的进一步训练。例如，传统的激活函数(如双曲正切函数)具有范围(0,1)内的梯度，反向传播通过链式法则计算梯度。这样做的效果是，用这些小数字的n乘以n来计算n层网络中“前端”层的梯度，这意味着梯度(误差信号)随n呈指数递减，而前端层的训练非常缓慢。</p>
<h2 id="产生原因">产生原因</h2>
<p>主要是采用了不合适的损失函数,
如果我们使用标准化初始w，那么各个层次的相乘都是0-1之间的小数，而激活函数f的导数也是0-1之间的数，其连乘后，结果会变的很小，导致梯度消失。若我们初始化的w是很大的数，w大到乘以激活函数的导数都大于1，那么连乘后，可能会导致求导的结果很大，形成梯度爆炸。</p>
<h2 id="解决方法">解决方法</h2>
<h3 id="预训练并微调">预训练并微调</h3>
<p>基本思想是每次训练一层隐节点，训练时将上一层隐节点的输出作为输入，而本层隐节点的输出作为下一层隐节点的输入，此过程就是逐层“预训练”（pre-training）；在预训练完成后，再对整个网络进行“微调”（fine-tunning）。</p>
<h3 id="梯度剪切与正则化">梯度剪切与正则化</h3>
<p>梯度剪切这个方案主要是针对梯度爆炸提出的，其思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。这可以防止梯度爆炸。</p>
<p>另外一种解决梯度爆炸的手段是采用权重正则化（weithts
regularization）比较常见的是L1正则化，和L2正则化，在各个深度框架中都有相应的API可以使用正则化。</p>
<h3
id="使用reluleakreluelu等激活函数">使用relu、leakrelu、elu等激活函数</h3>
<p>Relu:思想也很简单，如果激活函数的导数为1，那么就不存在梯度消失爆炸的问题了，每层的网络都可以得到相同的更新速度，relu就这样应运而生。详见<a
href="#激活函数">激活函数</a>。</p>
<h3 id="批规范化">批规范化</h3>
<p>Batchnorm是深度学习发展以来提出的最重要的成果之一，目前已经被广泛的应用到了各大网络中，具有加速网络收敛速度，提升训练稳定性的效果，Batchnorm本质上是解决反向传播过程中的梯度问题。batchnorm全名是batch
normalization，简称BN，即批规范化，通过规范化操作将输出信号x规范化到均值为0，方差为1保证网络的稳定性。</p>
<h3 id="使用残差结构">使用残差结构</h3>
<p>自从残差提出后，几乎所有的深度网络都离不开残差的身影，相比较之前的几层，几十层的深度网络，在残差网络面前都不值一提，残差可以很轻松的构建几百层，一千多层的网络而不用担心梯度消失过快的问题，原因就在于残差的捷径（shortcut）部分。</p>
<h3 id="lstm长短期记忆网络">LSTM（长短期记忆网络）</h3>
<p>在RNN网络结构中，由于使用Logistic或者Tanh函数，所以很容易导致梯度消失的问题，即在相隔很远的时刻时，前者对后者的影响几乎不存在了，LSTM的机制正是为了解决这种长期依赖问题。</p>
<h1 id="自适应学习率算法">自适应学习率算法</h1>
<p>学习率对模型的性能有显著的影响，是难以设置的超参数之一。损失通常高度敏感于参数空间中的某些方向，而不敏感于其他。动量算法可以在一定程度缓解这些问题，但这样做的代价是引入了另一个超参数。</p>
<p>Delta-bar-delta 算法 (Jacobs, 1988)
是一个早期的在训练时适应模型参数各自学习率的启发式方法。该方法基于一个很简单的想法，如果损失对于某个给定模型参数的偏导保持相同的符号，那么学习率应该增加。如果对于该参数的偏导变化了符号，那么学习率应减小。当然，这种方法只能应用于全批量优化中。最近，提出了一些增量（或者基于小批量）的算法来自适应模型参数的学习率。</p>
<h2 id="adagrad">AdaGrad</h2>
<p>Adagrad方法是在每个时间步中，根据过往已计算的参数梯度，来为每个参数修改对应的学习率。能独立地适应所有模型参数的学习率，当参数损失偏导值比较大时，有一个较大的学习率；当参数的损失偏导值较小时，有一个较小的学习率。</p>
<p>Adagrad方法的主要好处是，不需要手工来调整学习率。大多数参数使用了默认值0.01，且保持不变。</p>
<p>Adagrad方法的主要缺点是，学习率总是在降低和衰减。</p>
<p>因为每个附加项都是正的，在分母中累积了多个平方梯度值，故累积的总和在训练期间保持增长。这反过来又导致学习率下降，变为很小数量级的数字，该模型完全停止学习，停止获取新的额外知识。</p>
<p>因为随着学习速度的越来越小，模型的学习能力迅速降低，而且收敛速度非常慢，需要很长的训练和学习，即学习速度降低。</p>
<!--
![Adagrad算法](/images/body/the-Basics01/Adagrad.png "Adagrad")
-->
<figure>
<img data-src="pics01/Adagrad.png" title="Adagrad" alt="Adagrad算法" />
<figcaption aria-hidden="true">Adagrad算法</figcaption>
</figure>
<h2 id="rmsprop">RMSProp</h2>
<p>RMSProp 算法 (Hinton, 2012) 修改 AdaGrad
以在非凸设定下效果更好，改变梯度积累为指数加权的移动平均。</p>
<p>AdaGrad
旨在应用于凸问题时快速收敛。当应用于非凸函数训练神经网络时，学习轨迹可能穿过了很多不同的结构，最终到达一个局部是凸碗的区域。
AdaGrad
根据平方梯度的整个历史收缩学习率，可能使得学习率在达到这样的凸结构前就变得太小了。</p>
<p>RMSProp
使用指数衰减平均以丢弃遥远过去的历史，使其能够在找到凸碗状结构后快速收敛，它就像一个初始化于该碗状结构的
AdaGrad 算法实例。相比于 AdaGrad，使用移动平均引入了一个新的超参数 <span
class="math inline">\(\rho\)</span>，用来控制移动平均的长度范围。经验上，RMSProp
已被证明是一种有效且实用的深度神经网络优化算法，是深度学习从业者经常采用的优化方法之一。</p>
<!--
![RMSProp算法](/images/body/the-Basics01/RMSProp.png "RMSProp")
-->
<figure>
<img data-src="pics01/RMSProp.png" title="RMSProp" alt="RMSProp算法" />
<figcaption aria-hidden="true">RMSProp算法</figcaption>
</figure>
<!--
![使用Nesterov动量的RMSProp算法](/images/body/the-Basics01/RMSProp-Nesterov.png "RMSProp Nesterov")
-->
<figure>
<img data-src="pics01/RMSProp-Nesterov.png" title="RMSProp Nesterov"
alt="使用Nesterov动量的RMSProp算法" />
<figcaption
aria-hidden="true">使用Nesterov动量的RMSProp算法</figcaption>
</figure>
<h2 id="adam">Adam</h2>
<p>Adam (Kingma and Ba, 2014)
是另一种学习率自适应的优化算法，它可以被看作结合 RMSProp
和具有一些重要区别的动量的变种。</p>
<p>首先，在 Adam
中，动量直接并入了梯度一阶矩（指数加权）的估计。将动量加入 RMSProp
最直观的方法是将动量应用于缩放后的梯度。结合缩放的动量使用没有明确的理论动机。</p>
<p>其次， Adam
包括偏置修正，修正从原点初始化的一阶矩（动量项）和（非中心的）二阶矩的估计。
RMSProp 也采用了（非中心的）二阶矩估计，然而缺失了修正因子。因此，不像
Adam，RMSProp 二阶矩估计可能在训练初期有很高的偏置。</p>
<p>Adam
通常被认为对超参数的选择相当鲁棒，尽管学习率有时需要自行从默认值修改。</p>
<!--
![Adam算法](/images/body/the-Basics01/Adam.png "Adam")
-->
<figure>
<img data-src="pics01/Adam.png" title="Adam" alt="Adam算法" />
<figcaption aria-hidden="true">Adam算法</figcaption>
</figure>
<h1 id="评估指标">评估指标</h1>
<h2 id="分类指标">分类指标</h2>
<p><strong>混淆矩阵（confusion
matrix）</strong>是一个评估分类问题常用的工具，对于 k
元分类，其实它就是一个 k*k
的表格，用来记录分类器的预测结果。对于常见的二分类，它的混淆矩阵是 2*2
的。</p>
<p>在二分类问题中，可以将样例根据其真实类别和预测类别的组合划分为：</p>
<ul>
<li>真正例（true positive）TP</li>
<li>假正例（false positive）FP</li>
<li>真反例（true negative）TN</li>
<li>假反例（false negative）FN</li>
</ul>
<p>显然 TP + FP + TN + FN = 样例总数。分类结果的混淆矩阵如下:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">真实情况</th>
<th style="text-align: center;">预测</th>
<th style="text-align: center;">结果</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;">正例</td>
<td style="text-align: center;">反例</td>
</tr>
<tr class="even">
<td style="text-align: center;">正例</td>
<td style="text-align: center;">TP(真正例)</td>
<td style="text-align: center;">FN(假反例)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">反例</td>
<td style="text-align: center;">FP(假正例)</td>
<td style="text-align: center;">TN(真反例)</td>
</tr>
</tbody>
</table>
<h3 id="准确率精度accuracy">准确率（精度，Accuracy）</h3>
<p>精度Accurac是指模型预测正确（包括真正例TP、真反例TN）的样本数与总体样本数的占比，即：</p>
<p><span class="math display">\[
Accuracy = \frac{Count(correct)}{Count(total)}
\]</span></p>
<p>在二分类问题中：</p>
<p><span class="math display">\[
Accuracy = \frac{TP + TN}{TP + FP + FN + TN}
\]</span></p>
<p>准确率是分类问题中最简单直观的指标，但是在实际中应用不多。原因是：当样本标签分布不均衡时，比如：正样本占比99%，只要模型把所有样本都预测为正样本，则准确率达到99%，但是实际上模型根本没有预测能力。</p>
<h3 id="查准率精确率precision">查准率（精确率，Precision）</h3>
<p>查准率是从预测正例的角度出发（分子分母都是关于Positive）：</p>
<p><span class="math display">\[
Precision = \frac{TP}{TP + FP}
\]</span></p>
<p>假设我们用模型预测了一批西瓜，预测100个瓜为好瓜，其中60个为好瓜，40个坏瓜，则查准率就是60/100=60%.</p>
<p>查准率评估了模型预测的正例中的精度--准确更重要。</p>
<p>假设我们提高阈值，使得预测为正例的数量变少，预测精度更高，那么查准率就变得更高，因此单一查准率指标依然没法对模型性能进行准确评估。因为模型遗漏了大量正例，使得大量正例被误判为负例。</p>
<h3 id="查全率召回率recall">查全率（召回率，Recall）</h3>
<p>召回率从实际正例的角度出发（真正例、假反例）</p>
<p><span class="math display">\[
Recall = \frac{TP}{TP + FN}
\]</span></p>
<p>假设80个好瓜，模型预测出60个好瓜，20个好瓜未被正确预测，则查全率就是60/(60+20)=75%。</p>
<p>召回率评估了针对正例样本，表示样本中的正例有多少被预测正确--少漏更重要，要全。</p>
<p>假设我们降低阈值，就会使得预测为正例的样本数量增多，但查准率会降低。</p>
<p>所以查准率和查全率的矛盾，跟阈值相关。</p>
<h3 id="p-r曲线平衡点和f1衡量">P-R曲线、平衡点和F1衡量</h3>
<h4 id="p-r曲线">P-R曲线</h4>
<p>在上面分析查准率P，查全率R的时候，我们得到了不同阈值下对P、R的影响。那么当我们预测100的样本后（假设样本预测结果以概率形式输出），我们对样本结果进行排序，排在最前面（概率最大）的模型认为“最可能是”正例的样本，排在最后的是模型认为”最不可能“是正例的样本。按此顺序设置不同的阈值（阈值可以是排序后的概率值，或者固定划分点），在不同的阈值下，计算出当前阈值下的查准率P和查全率R。以查准率为纵轴，查全率为横轴作图，就可以得到查准率-查全率曲线，简称P-R曲线，显示改曲线的图称为”P-R图“。</p>
<!--
![P-R曲线与平衡点示意图](/images/body/the-Basics01/P-R-Curve.png "P-R Curve")
-->
<figure>
<img data-src="pics01/P-R-Curve.png" title="P-R Curve"
alt="P-R曲线与平衡点示意图" />
<figcaption aria-hidden="true">P-R曲线与平衡点示意图</figcaption>
</figure>
<p>P-R图直观地显示出学习器在样本总体上的查全率，查准率。在进行比较时，<strong>若一个学习期的P-R曲线被另一个学习器完全”包住“，则可以断言后者的性能优于前者</strong>。例如图中，学习器A的性能优于学习器C；如果两个学习器的P-R曲线发生了交叉，例如图中的A和B，则难以一般性地断言两者优劣，只能在具体地查准率或者查全率条件下进行比较。</p>
<p>然而，在很多情况下，人们往往仍然希望把A和B比出个高低。这时，一个比较合理地判断依据是<strong>比较P-R曲线下面积的大小（Area
under curve
P-R，AUC-PR）</strong>，它在一定程度上表征了学习器在查准率和查全率上取得相对”双高“的比例。但这个值不太容易估算，因此，人们设计了一些综合考虑查准率，查全率的性能度量，比如BEP度量，F1度量。</p>
<h4 id="平衡点break-even-pointbep">平衡点（Break-Even-Point，BEP）</h4>
<p>平衡点（Break-Even-Point），它是”查准率=查全率“时的取值，例如图1中的学习器C的BEP是0.64，基于BEP的比较，可认为A优于B。</p>
<h4 id="f1度量">F1度量</h4>
<p>BEP过于简单，这个平衡点是建立在”查准率=查全率“的前提下，无法满足实际不同场景的应用。我们引入加权调和平均
<span class="math inline">\(F_\beta\)</span> ：</p>
<p><span class="math display">\[
\frac{1}{F_\beta} = \frac{1}{1 + \beta ^2}(\frac{1}{P} + \frac{\beta
^2}{R})
\]</span></p>
<p>当 <span class="math inline">\(\beta = 1\)</span> 时，有 <span
class="math inline">\(\frac{1}{F_1} = \frac{1}{2}(\frac{1}{P} +
\frac{1}{R})\)</span>，即</p>
<p><span class="math display">\[
F_1 = \frac{2 * P * R}{P + R}
\]</span></p>
<p>在一些应用中，对查准率和查全率的重视程度不同。例如在商品推荐中，为了尽可能少打扰用户，更希望推荐的内容确实是用户感兴趣的，此时查准率更重要；而在罪犯信息检索或者病人检查系统中，更希望尽可能少的漏判，此时查全率更重要。F1度量的一般形式是
<span
class="math inline">\(F_\beta\)</span>，能让我们自定义对查准率/查全率的不同偏好：</p>
<p><span class="math display">\[
F_\beta = \frac{(1 + \beta ^2) * P * R}{(\beta ^2 * P) + R}
\]</span></p>
<p>其中，<span class="math inline">\(\beta &gt; 0\)</span>
度量了查全率对查准率的相对重要性，<span class="math inline">\(\beta =
1\)</span> 时退化为标准F1，<span class="math inline">\(\beta &gt;
1\)</span> 时查全率有更大影响；<span class="math inline">\(\beta &lt;
1\)</span> 时，查准率有更大影响。</p>
<h4 id="多分类情况">多分类情况</h4>
<p>很多时候我们有多个二分类混淆矩阵，例如进行多次训练/测试，每次得到一个混淆矩阵；或是在多个数据集上进行训练/测试，希望估计算法的全局性能；或者是执行分类任务，每两两类别的组合都对应一个混淆矩阵；总之是在n个二分类混淆矩阵上综合考察查准率和查全率。</p>
<p>一种直接的做法是现在各个混淆矩阵上分别计算出查准率和查全率，记为(P1,R1)，(P2,R2),...(Pn,Rn)，在计算平均值，这样就得到“宏观查准率”(macro-P)，“宏观查全率”(macro-R)、“宏观F1”(macro-F1)：</p>
<p><span class="math display">\[
macroP = \frac{1}{n}\sum^n_{i = 1} P_i\\
macroR = \frac{1}{n}\sum^n_{i = 1} R_i\\
macroF1 = \frac{2 * macroP * macroR}{macroP + macroR}
\]</span></p>
<p>另一种方法可以将个混淆矩阵对应的元素进行平均，得到TP、FP、TN、FN的平均值，分别记为
<span class="math inline">\(\overline{TP}\)</span>、<span
class="math inline">\(\overline{FP}\)</span>、<span
class="math inline">\(\overline{FN}\)</span>、<span
class="math inline">\(\overline{TN}\)</span>，再基于这些平均值计算出“微观查准率”(micro-P)，“微观查全率”(micro-R)、“微观F1”(micro-F1)：</p>
<p><span class="math display">\[
microP = \frac{\overline{TP}}{\overline{TP} + \overline{FP}}\\
microR = \frac{\overline{TP}}{\overline{TP} + \overline{FN}}\\
microF1 = \frac{2 * microP * microR}{microP + microR}
\]</span></p>
<h3 id="roc与auc">ROC与AUC</h3>
<p>根据上面混淆矩阵的一系列指标计算，可以发现，将样本预测为正例或者负例是与一个分类阈值相关的。若大于阈值则分为正类，否则为反类。</p>
<p>实际上，根据概率预测结果，我们可以将测试样本进行排序，“最可能”是正例的排在最前面，“最不可能”是正例的排在最后面。这样，分类过程就相当于在这个排序中以某个“截断点”(cut
point)将样本分为两部分，前一部分作为正例，后一部分作为反例。</p>
<p>在不同的任务中，我们可以根据任务需求采用不同的阈值，若我们更重视查准率，则选择排序中靠前的位置，若更重视查全率，则可以选择靠后的位置进行截。因此，排序本身的好坏，提现了综合考虑学习器在不同任务下的“期望泛化性能”的好坏。ROC曲线则是从这个角度出发来研究学习器泛化性能的有效工具。</p>
<p>ROC全称是“受试者工作特性”(Receiver Operating
Characteristic)曲线。与上述介绍的P-R曲线相似，我们根据预测结果对样例进行排序，按此顺序逐个将样本预测结果作为阈值进行划分。之后计算两个指标：真正例率（True
Positive Rate，简称TPR），假正例率（False Positive
Rate，简称FPR），公式如下：</p>
<p><span class="math display">\[
TPR = \frac{TP}{TP + FN}\\
FPR = \frac{FP}{FP + TN}
\]</span></p>
<p>以TPR为纵轴，FPR为横轴，得到ROC曲线。在现实任务中通常只有有限个样本来绘制ROC图，此时无法产生图a中光滑的曲线，只能绘制出图b所示的近似曲线。绘制过程如介绍公式时所描述的一样，对样本预测结果进行排序，然后取第一个结果作为阈值，此时所有样本均预测为反例，此时真正例率和假正例率均为0，在坐标(0,0)处标记一个点。随后将第二个样本预测结果作为阈值，得到坐标点，依次类推。</p>
<!--
![ROC曲线与AUC示意图](/images/body/the-Basics01/ROC-AUC.png "ROC AUC")
-->
<figure>
<img data-src="pics01/ROC-AUC.png" title="ROC AUC"
alt="ROC曲线与AUC示意图" />
<figcaption aria-hidden="true">ROC曲线与AUC示意图</figcaption>
</figure>
<p>当要比较两个学习器的性能优劣时，与P-R曲线相似，若一个学习器的ROC曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者；若两个学习器的ROC曲线发生交叉，则一般难以断言两者优劣。此时可以比较ROC曲线下的面积，即AUC(Area
under ROC Curve)。</p>
<p>很明显，AUC的结果不会超过 1，通常ROC曲线都在 y = x
这条直线上面，所以，AUC的值一般在 0.5 ~ 1 之间。</p>
<p>从定义可知，AUC可以通过对ROC曲线下各部分的面积求和而得。假定ROC曲线是由坐标{(x1,y1),(x2,y2)...}的点连接而成。AUC可估算为</p>
<p><span class="math display">\[
AUC = \frac{1}{2}\sum^{m - 1}_{i = 1}(x_{i + 1} - x_i)(y_i + y_{i + 1})
\]</span></p>
<h3 id="ks图kolomogorov-smirnov-chart">KS图（Kolomogorov Smirnov
chart）</h3>
<p>KS值是在模型中用于<strong>区分预测正负样本分隔程度的评价指标</strong>，一般应用于金融风控领域。如果将人口划分为两个独立的组，其中一组包含所有正例而另一组包含所有负例，则K-S值为100。</p>
<p>与ROC曲线相似，ROC是以FPR作为横坐标，TPR作为纵坐标，通过改变不同阈值，从而得到ROC曲线。而在KS曲线中，则是以阈值作为横坐标，以FPR和TPR作为纵坐标，ks曲线则为TPR-FPR，ks曲线的最大值通常为ks值。</p>
<p>为什么这样求KS值呢？我们知道，当阈值减小时，TPR和FPR会同时减小，当阈值增大时，TPR和FPR会同时增大。而在实际工程中，我们希望TPR更大一些，FPR更小一些，即TPR-FPR越大越好，即ks值越大越好。</p>
<p>可以理解TPR是收益，FPR是代价，ks值是收益最大。图中绿色线是TPR、蓝色线是FPR。</p>
<!--
![KS](/images/body/the-Basics01/KS.jpg "KS")
-->
<figure>
<img data-src="pics01/KS.jpg" title="KS" alt="KS" />
<figcaption aria-hidden="true">KS</figcaption>
</figure>
<p>在实际应用中，比如风控模型中，往往单一指标并不能真正比较两个学习器之间的优劣，比如A学习器KS：40，B学习器KS：39。并不能保证A学习器一定比B学习器表现好，就像考试100的同学一定比99分的同学优秀一样。在实际中，通常结合单一指标（比如KS）和图表，综合判断模型在实际应用中，哪一个模型更加有优势。</p>
<h2 id="回归指标">回归指标</h2>
<h3
id="均方误差mean-squared-errormse与均方根误差root-mean-squared-errorrmse">均方误差（Mean
Squared Error，MSE）与均方根误差（Root Mean Squared Error，RMSE）</h3>
<p>MSE计算的是拟合数据和原始数据对应样本点的误差的平方和的均值，其值越小说明拟合效果越好。</p>
<p><span class="math display">\[
MSE = \frac{1}{N}\sum^N_{i = 1}(y^2_i - \^y^2_i)
\]</span></p>
<p>由于MSE与我们的目标变量的量纲不一致，为了保证量纲一致性，我们需要对MSE进行开方，即均方根误差：</p>
<p><span class="math display">\[
RMSE = \sqrt{\frac{1}{N}\sum^N_{i = 1}(y^2_i - \^y^2_i)}
\]</span></p>
<p>以下是RMSE需要考虑的要点：</p>
<ul>
<li>“平方根”使该指标能够显示大的偏差。</li>
<li>此度量标准的“平方”特性有助于提供更强大的结果，从而防止取消正负误差值。换句话说，该度量恰当地显示了错误的合理幅度。</li>
<li>它避免使用绝对误差值，这在数学计算中是非常不希望的。</li>
<li>当我们有更多样本时，使用RMSE重建误差分布被认为更可靠。</li>
<li>RMSE受到异常值的影响很大。因此，请确保在使用此指标之前已从数据集中删除了异常值。</li>
<li>与平均绝对误差( mean absolute
error)相比，RMSE提供更高的权重并惩罚大的错误。</li>
</ul>
<h3 id="平均绝对误差mean-absolute-errormae">平均绝对误差（Mean Absolute
Error，MAE）</h3>
<p>和 MSE 一样，这种度量方法也是在不考虑方向的情况下衡量误差大小。但和
MSE 的不同之处在于，MAE
需要像线性规划这样更复杂的工具来计算梯度。此外，MAE
对异常值更加稳健，因为它不使用平方。</p>
<p><span class="math display">\[
MAE = \frac{1}{N}\sum^N_{i = 1}\vert y_i - \^y_i\vert
\]</span></p>
<h3 id="决定系数-r方r-squarded">决定系数 R方（R-squarded）</h3>
<p>判定系数，其含义是也是解释回归模型的方差得分，其值取值范围是[0,1]，越接近于1说明自变量越能解释因变量的方差变化，值越小则说明效果越差。又称为the
coefficient of
determination。判断的是预测模型和真实数据的拟合程度，最佳值为1，同时可为负值。如果结果是0，就说明我们的模型跟瞎猜差不多。如果结果是1。就说明我们模型无错误。如果结果是0-1之间的数，就是我们模型的好坏程度。如果结果是负数。说明我们的模型还不如瞎猜。</p>
<p>R方可以理解为因变量y中的变异性能能够被估计的多元回归方程解释的比例，它衡量各个自变量对因变量变动的解释程度，<strong>其取值在0与1之间，其值越接近1，则变量的解释程度就越高，其值越接近0，其解释程度就越弱</strong>。</p>
<p>一般来说，增加自变量的个数，回归平方和会增加，残差平方和会减少，所以R方会增大；反之，减少自变量的个数，回归平方和减少，残差平方和增加。为了消除自变量的数目的影响，引入了调整的R方。</p>
<p><span class="math display">\[
\begin{aligned}
R^2 &amp; = 1- \frac{\sum^m_{i = 1}(f_i - y_i)^2}{\sum^m_{i =
1}(\overline{y_i} - y_i)^2}\\
&amp; = \frac{\frac{1}{m}\sum^m_{i = 1}(f_i -
y_i)^2}{\frac{1}{m}\sum^m_{i = 1}(\overline{y_i} - y_i)^2}\\
&amp; = 1 - \frac{MSE(f, y)}{Var(y)}
\end{aligned}
\]</span></p>
<h3 id="对百分比误差mape">对百分比误差（MAPE）</h3>
<p>MAPE（平均绝对百分比误差）MAPE 为0%表示完美模型，MAPE 大于 100
%则表示劣质模型。</p>
<p>MAPE是衡量预测准确性的统计指标，是百分比值，一般认为MAPE小于10时，预测精度较高</p>
<p>如果存在某个实际值At为0，那么MAPE则无法进行计算；</p>
<p><span class="math display">\[
MAPE = \frac{100\sum^n_{i = 1}\vert\frac{y_i - y&#39;_i}{y_i}\vert}{n}
\]</span></p>
<h1 id="归一化">归一化</h1>
<p>不同评价指标（即特征向量中的不同特征就是所述的不同评价指标）往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果，</p>
<p>为了消除指标之间的量纲影响，需要进行数据标准化处理，以解决数据指标之间的可比性。原始数据经过数据标准化处理后，各指标处于同一数量级，适合进行综合对比评价。其中，最典型的就是数据的归一化处理。</p>
<p>简而言之，归一化的目的就是使得预处理的数据被限定在一定的范围内（比如[0,1]或者[-1,1]），从而消除奇异样本数据导致的不良影响。</p>
<blockquote>
<p>奇异样本数据是指相对于其他输入样本特别大或特别小的样本矢量（即特征向量）</p>
</blockquote>
<p>奇异样本数据的存在会引起训练时间增大，同时也可能导致无法收敛，因此，当存在奇异样本数据时，在进行训练之前需要对预处理数据进行归一化；反之，不存在奇异样本数据时，则可以不进行归一化。</p>
<h2 id="归一化的好处">归一化的好处</h2>
<ol type="1">
<li>归一化后加快了梯度下降求最优解的速度，也即加快训练网络的收敛性；</li>
<li>归一化有可能提高精度</li>
</ol>
<h2 id="归一化的方法">归一化的方法</h2>
<h3 id="最大最小标准化min-max-normalization">最大最小标准化（Min-Max
Normalization）</h3>
<p><span class="math display">\[
x&#39; = \frac{x - \min{(x)}}{\max{(x)} - \min{(x)}}
\]</span></p>
<ol type="1">
<li><p>线性函数将原始数据线性化的方法转换到[0 1]的范围,
计算结果为归一化后的数据，X为原始数据；</p></li>
<li><p>本归一化方法比较适用在数值比较集中的情况；</p></li>
<li><p>缺陷：如果max和min不稳定，很容易使得归一化结果不稳定，使得后续使用效果也不稳定。实际使用中可以用经验常量来替代max和min。</p></li>
</ol>
<p><strong>应用场景</strong>：在不涉及距离度量、协方差计算、数据不符合正态分布的时候，如图像处理中，将RGB图像转换为灰度图像后将其值限定在[0
255]的范围。</p>
<h3 id="z-score标准化">z-score标准化</h3>
<p><span class="math display">\[
x^* = \frac{x - \mu}{\sigma}
\]</span></p>
<p>其中，<span class="math inline">\(\mu\)</span>、<span
class="math inline">\(\sigma\)</span> 分别为原始数据集的均值和方差。</p>
<ol type="1">
<li><p>将原始数据集归一化为均值为0、方差1的数据集。</p></li>
<li><p>该种归一化方式要求原始数据的分布可以近似为高斯分布，否则归一化的效果会变得很糟糕。</p></li>
</ol>
<p>应用场景：在分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用PCA技术进行降维的时候，Z-score
standardization表现更好。</p>
<h3 id="神经网络归一化">神经网络归一化</h3>
<p>本归一化方法经常用在数据分化比较大的场景，有些数值很大，有些很小。通过一些数学函数，将原始值进行映射。</p>
<p>该方法包括对数、正切等，需要根据数据分布的情况，决定非线性函数的曲线：</p>
<h4 id="对数函数归一化">对数函数归一化</h4>
<p><span class="math display">\[
y = \log_{10}(x)
\]</span></p>
<p>以10为底的对数转换函数，对应的归一化方法为：</p>
<p><span class="math display">\[
x&#39; = \frac{\log_{10}(x)}{\log_{10}(max)}
\]</span></p>
<p>其中max表示样本数据的最大值，并且所有样本数据均要大于等于1.</p>
<h4 id="反正切函数归一化">反正切函数归一化</h4>
<p><span class="math display">\[
x&#39; = \frac{2}{\pi}\arctan(x)
\]</span></p>
<p>使用这个方法需要注意的是如果想映射的区间为[0，1]，则数据都应该大于等于0，小于0的数据将被映射到[－1，0]区间上.</p>
<h3 id="l2范数归一化">L2范数归一化</h3>
<p>特征向量中每个元素均除以向量的L2范数：</p>
<p><span class="math display">\[
x&#39;_i = \frac{x_i}{norm(x)}
\]</span></p>
<h2 id="什么时候使用归一化">什么时候使用归一化</h2>
<ol type="1">
<li><p>如果对输出结果范围有要求，用归一化。</p></li>
<li><p>如果数据较为稳定，不存在极端的最大最小值，用归一化。</p></li>
<li><p>如果数据存在异常值和较多噪音，用标准化，可以间接通过中心化避免异常值和极端值的影响。</p></li>
</ol>
<blockquote>
<p><strong>归一化与标准化不同</strong></p>
</blockquote>
<h3 id="标准化归一化的对比分析">标准化/归一化的对比分析</h3>
<p>首先明确，在机器学习中，标准化是更常用的手段，归一化的应用场景是有限的。原因有两点：</p>
<ol type="1">
<li>标准化更好保持了样本间距。当样本中有异常点时，归一化有可能将正常的样本“挤”到一起去。比如三个样本，某个特征的值为1,2,10000，假设10000这个值是异常值，用归一化的方法后，正常的1,2就会被“挤”到一起去。如果不幸的是1和2的分类标签还是相反的，那么，当我们用梯度下降来做分类模型训练时，模型会需要更长的时间收敛，因为将样本分开需要更大的努力！而标准化在这方面就做得很好，至少它不会将样本“挤到一起”。</li>
<li>标准化更符合统计学假设对一个数值特征来说，很大可能它是服从正态分布的。标准化其实是基于这个隐含假设，只不过是略施小技，将这个正态分布调整为均值为0，方差为1的标准正态分布而已。</li>
</ol>
<h1 id="dropout">Dropout</h1>
<p>想要提高CNN的表达或分类能力，最直接的方法就是采用更深的网络和更多的神经元，即deeper
and
wider。但是，复杂的网络也意味着更加容易过拟合。于是就有了Dropout，大部分实验表明其具有一定的防止过拟合的能力。</p>
<h2 id="最初的dropout">最初的Dropout</h2>
<p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzEyMDcuMDU4MC5wZGY=">Improving neural
networks by preventing co-adaptation of feature Detectors<i class="fa fa-external-link-alt"></i></span></p>
<!--
![Dropout](/images/body/the-Basics01/Dropout.jpg "Dropout")
-->
<figure>
<img data-src="pics01/Dropout.jpg" title="Dropout" alt="Dropout" />
<figcaption aria-hidden="true">Dropout</figcaption>
</figure>
<p>如上图左，为没有Dropout的普通2层全连接结构，记为 <span
class="math inline">\(r = a(Wv)\)</span> ，其中 <span
class="math inline">\(a\)</span> 为激活函数。</p>
<p>如上图右，为在第2层全连接后添加Dropout层的示意图。即在模型训练时，随机让网络的某些节点不工作（输出置0），其它过程不变。</p>
<p>由于随机的让一些节点不工作了，因此可以避免某些特征只在固定组合下才生效，有意识地让网络去学习一些普遍的共性（而不是某些训练样本的一些特性）。</p>
<p>Bagging方法通过对训练数据有放回的采样来训练多个模型。而Dropout的随机意味着每次训练时只训练了一部分，而且其中大部分参数还是共享的，因此和Bagging有点相似。因此，Dropout可以看做训练了多个模型，实际使用时采用了模型平均作为输出。</p>
<p>训练时，我们通常设定一个dropout ratio <span
class="math inline">\(p\)</span>，即每一个输出节点以概率 <span
class="math inline">\(p\)</span>
置0(不工作)。假设每一个输出都是相互独立的，每个输出都服从二项伯努利分布
<span class="math inline">\(B(1 - p)\)</span>，则大约认为训练时只使用了
<span class="math inline">\((1-p)\)</span> 比例的输出。</p>
<p>测试时，最直接的方法就是保留Dropout层的同时，将一张图片重复测试 M
次，取 M 次结果的平均作为最终结果。假如有 N 个节点，则可能的情况为 <span
class="math inline">\(R = 2^N\)</span>，如果 M 远小于
R，则显然平均效果不好；如果M ≈
N，那么计算量就太大了。因此作者做了一个近似：可以直接去掉Dropout层，将所有输出都使用起来，为此需要将尺度对齐，即比例缩小输出
$ r = r * (1 - p)$。即如下公式：</p>
<p><span class="math display">\[
E_M[a(M * W)v] \approx a(E_M[(M * W)v]) = a((1 - p)Wv)
\]</span></p>
<p>特别的，
为了使用方便，我们不在测试时再缩小输出，而在训练时直接将输出放大1/(1-p)倍。</p>
<p>Dropout得到了广泛的使用，但具体用到哪里、训练一开始就用还是后面才用、dropout_ratio取多大，还要自己多多尝试。有时添加Dropout反而会降低性能。</p>
<h2 id="dropconnect">DropConnect</h2>
<p><span class="exturl" data-url="aHR0cDovL2NzLm55dS5lZHUvfndhbmxpL2Ryb3BjLw==">Regularization of Neural
Networks using DropConnect<i class="fa fa-external-link-alt"></i></span></p>
<!--
![Dropout-DropConnect](/images/body/the-Basics01/Dropout-DropConnect.jpg "Dropout-DropConnect")
-->
<figure>
<img data-src="pics01/Dropout-DropConnect.jpg" title="Dropout-DropConnect"
alt="Dropout-DropConnect" />
<figcaption aria-hidden="true">Dropout-DropConnect</figcaption>
</figure>
<p>由图可知，DropConnect与Dropout的区别很明显：Dropout是将输出随机置0，而DropConnect是将权重随机置0。
文章说之所以这么干是因为原来的Dropout进行的不够充分，随机采样不够合理。这可以从下图进行理
解：</p>
<!--
![DropConnect](/images/body/the-Basics01/DropConnect.jpg "DropConnect")
-->
<figure>
<img data-src="pics01/DropConnect.jpg" title="DropConnect"
alt="DropConnect" />
<figcaption aria-hidden="true">DropConnect</figcaption>
</figure>
<p>如上图所示，a表示不加任何Drop时的一层网络模型。添加Drop相当于给权重再乘以一个随机掩膜矩阵
<span class="math inline">\(M\)</span>。</p>
<p><span class="math display">\[
r = a(Wv)\ \ \ No-Drop\\
r = a((M\ldotp\times W)v)\ \ \ Drop\\
M_{ij}\sim Bernoulli(p)
\]</span></p>
<p>不同的是，DropConnect由于直接对权重随机置0，因此其掩膜显得更加具有随机性，如b所示。而Dropout仅对输出进行随机置0,因此其掩膜相当于是对随机的行和列进行置0，如c所示。</p>
<p>训练的时候，训练过程与Dropout基本相同。测试的时候，我们同样需要一种近似的方法。</p>
<p><span class="math display">\[
r = a((M\ldotp\times W)v)\\
r_i = a(u_i)\\
u_i = \sum_j(W_{ij}v_j)M_{ij} \sim \mathcal{N}(\mu, \sigma^2)\\
\mu = pWv\\
\sigma = p(1 - p)(W \ast W)(v \ast v)
\]</span></p>
<p>注意： 掩膜矩阵M的每一个元素都满足二项伯努利分布。假如M的维度为 <span
class="math inline">\(m\ast n\)</span>，则可能的掩膜有 <span
class="math inline">\(2^{m + n}\)</span>
种，之前提到过我们可以粗暴的遍历所有的掩膜然后计算结果最后求平均。中心极限定理：和分布渐进于正态分布。
于是，我们可以不去遍历，而是通过计算每一维的均值与方差，确定每一维的正态分布，最后在此正态分布上做多次采样后求平均即可获得最终的近似结果。</p>
<p>具体测试时的算法流程如下：</p>
<!--
![DropConnect算法](/images/body/the-Basics01/DropConnect-A.jpg "DropConnect Algorithm")
-->
<figure>
<img data-src="pics01/DropConnect-A.jpg" title="DropConnect Algorithm"
alt="DropConnect算法" />
<figcaption aria-hidden="true">DropConnect算法</figcaption>
</figure>
<p>其中，Z是在正态分布上的采样次数，一般来说越大越好，但会使得计算变慢。</p>
<p>实验：
作者当然要做很多对比试验，但其实发现效果并不比Dropout优秀太多，反而计算量要大很多，因此到目前DropConnect并没有得到广泛的应用。具体的对比，可以参看原文，这里贴一张图来说明对于Drop
ratio的看法：</p>
<!--
![DropConnect实验结果](/images/body/the-Basics01/DropConnect-figure.jpg "DropConnect figure")
-->
<figure>
<img data-src="pics01/DropConnect-figure.jpg" title="DropConnect figure"
alt="DropConnect实验结果" />
<figcaption aria-hidden="true">DropConnect实验结果</figcaption>
</figure>
<p>由此可以看出，drop ratio并不是越大越好，具体需要多做实验体会。</p>
<h1 id="激活函数">激活函数</h1>
<p>神经网络中的每个神经元节点接受上一层神经元的输出值作为本神经元的输入值，并将输入值传递给下一层，输入层神经元节点会将输入属性值直接传递给下一层（隐层或输出层）。在多层神经网络中，上层节点的输出和下层节点的输入之间具有一个函数关系，这个函数称为激活函数。</p>
<p>不使用激活函数的话，神经网络的每层都只是做线性变换，多层输入叠加后也还是线性变换。因为线性模型的表达能力通常不够，所以这时候就体现了激活函数的作用了，<strong>激活函数可以引入非线性因素</strong>。</p>
<!--
![不使用激活函数的神经网络](/images/body/the-Basics01/NN-no-activation-function.png "NN without activation function")
-->
<figure>
<img data-src="pics01/NN-no-activation-function.png"
title="NN without activation function" alt="不使用激活函数的神经网络" />
<figcaption aria-hidden="true">不使用激活函数的神经网络</figcaption>
</figure>
<!--
![使用激活函数的神经网络](/images/body/the-Basics01/NN-with-activation-function.png "NN with activation function")
-->
<figure>
<img data-src="pics01/NN-with-activation-function.png"
title="NN with activation function" alt="使用激活函数的神经网络" />
<figcaption aria-hidden="true">使用激活函数的神经网络</figcaption>
</figure>
<p>加入非线性激励函数后，神经网络就有可能学习到滑的曲线来分割面，而不是用复杂的线性组合逼滑曲线来分割面，使神经网络的表示能力更强了，能够更好的拟合目标函数。</p>
<p>sigmoid和tanh是“饱和激活函数”，而ReLU及其变体则是“非饱和激活函数”。使用“非饱和激活函数”的优势在于两点：</p>
<ol type="1">
<li>"非饱和激活函数”能解决所谓的“梯度消失”问题。</li>
<li>它能加快收敛速度。</li>
</ol>
<h2 id="饱和激活函数">饱和激活函数</h2>
<p>假设 <span class="math inline">\(h(x)\)</span> 是一个激活函数， -
若当n趋向于正无穷，激活函数的导数趋近于0，那么我们称之为<strong>右饱和</strong></p>
<p><span class="math display">\[
\lim\limits_{n\to + \infty}h&#39;(x) = 0
\]</span></p>
<ul>
<li>若当n趋向于负无穷，激活函数的导数趋近于0，那么我们称之为<strong>左饱和</strong></li>
</ul>
<p><span class="math display">\[
\lim\limits_{n\to - \infty}h&#39;(x) = 0
\]</span></p>
<p>当函数既满足左饱和也满足右饱和时，我们称之为饱和。典型的函数有Sigmoid、Tanh函数。</p>
<h3 id="sigmoid">Sigmoid</h3>
<p><span class="math display">\[
Sigmoid(x) = \frac{1}{1 + e^{- x}}
\]</span></p>
<!--
![Sigmoid函数图像](/images/body/the-Basics01/Sigmoid.png "Sigmoid")
-->
<figure>
<img data-src="pics01/Sigmoid.png" title="Sigmoid" alt="Sigmoid函数图像" />
<figcaption aria-hidden="true">Sigmoid函数图像</figcaption>
</figure>
<!--
![Sigmoid导函数图像](/images/body/the-Basics01/dSigmoid.png "dSigmoid")
-->
<figure>
<img data-src="pics01/dSigmoid.png" title="dSigmoid"
alt="Sigmoid导函数图像" />
<figcaption aria-hidden="true">Sigmoid导函数图像</figcaption>
</figure>
<p>Sigmoid函数在历史上曾经非常的常用，输出值范围为[0,1]之间的实数。但是现在它已经不太受欢迎，实际中很少使用。原因是sigmoid存在3个问题：</p>
<ol type="1">
<li>sigmoid函数饱和使梯度消失(Sigmoidsaturate and kill
gradients)。我们从导函数图像中可以看出sigmoid的导数都是小于0.25的，那么在进行反向传播的时候，梯度相乘结果会慢慢的趋于0导致梯度消失。除此之外，为了防止饱和，必须对于权重矩阵的初始化特别留意。如果初始化权重过大，可能很多神经元得到一个比较小的梯度，致使神经元不能很好的更新权重提前饱和，神经网络就几乎不学习。</li>
<li>sigmoid函数输出不是“零为中心”(zero-centered)。一个多层的sigmoid神经网络，如果你的输入x都是正数，那么在反向传播中w的梯度传播到网络的某一处时，权值的变化是要么全正要么全负。</li>
<li>指数函数的计算是比较消耗计算资源的。</li>
</ol>
<h3 id="tanh">Tanh</h3>
<p>实际上，tanh是sigmoid的变形。</p>
<p><span class="math display">\[
\begin{aligned}
Tanh(x) &amp; = 2 Sigmoid(2x) - 1\\
&amp; = \frac{1 - e^{-2x}}{1 + e^{-2x}}
\end{aligned}
\]</span></p>
<!--
![Tanh函数图像](/images/body/the-Basics01/Tanh.png "Tanh")
-->
<figure>
<img data-src="pics01/Tanh.png" title="Tanh" alt="Tanh函数图像" />
<figcaption aria-hidden="true">Tanh函数图像</figcaption>
</figure>
<p>tanh与sigmoid不同的是，tanh是“零为中心”的。因此，实际应用中，tanh会比sigmoid更好一些。但是在饱和神经元的情况下，tanh还是没有解决梯度消失问题。</p>
<p>优点：tanh解决了sigmoid的输出非“零为中心”的问题</p>
<p>缺点：依然有sigmoid函数过饱和的问题，且依然进行的是指数运算</p>
<h2 id="非饱和激活函数">非饱和激活函数</h2>
<h3 id="relu">ReLU</h3>
<p>近年来，ReLU函数变得越来越受欢迎。全称是Rectified Linear
Unit，修正线性单元。ReLU是Krizhevsky、Hinton等人在2012年《ImageNet
Classification with Deep Convolutional Neural
Networks》论文中提出的一种线性且不饱和的激活函数。</p>
<p><span class="math display">\[
ReLU(x) = \max(0, x)
\]</span></p>
<!--
![ReLU函数图像](/images/body/the-Basics01/ReLU.png "ReLU")
-->
<figure>
<img data-src="pics01/ReLU.png" title="ReLU" alt="ReLU函数图像" />
<figcaption aria-hidden="true">ReLU函数图像</figcaption>
</figure>
<p>优点：</p>
<ol type="1">
<li>ReLU解决了梯度消失的问题，至少x在正区间内，神经元不会饱和；</li>
<li>由于ReLU线性、非饱和的形式，在SGD中能够快速收敛；</li>
<li>运算速度要快很多。ReLU函数只有线性关系，不需要指数计算，不管在前向传播还是反向传播，计算速度都比sigmoid和tanh快</li>
</ol>
<p>缺点：</p>
<ol type="1">
<li>ReLU的输出不是“零为中心”(Notzero-centered output)。</li>
<li>随着训练的进行，可能会出现神经元死亡，权重无法更新的情况。这种神经元的死亡是不可逆转的死亡</li>
</ol>
<p>训练神经网络的时候，一旦学习率没有设置好，第一次更新权重的时候，输入是负值，那么这个含有ReLU的神经节点就会死亡，再也不会被激活。设置一个合适的较小的学习率，会降低这种情况的发生。</p>
<p>为了解决神经元节点死亡的情况，有人提出了Leaky
ReLU、P-ReLu、R-ReLU、ELU等激活函数。</p>
<h3 id="leaky-relu">Leaky ReLU</h3>
<p>ReLU是将所有的负值设置为0，造成神经元节点死亡情况。相反，Leaky
ReLU是给所有负值赋予一个非零的斜率。Leaky
ReLU激活函数是在声学模型(2013)中首次提出来的。</p>
<p><span class="math display">\[
LeakyReLU(x) = \begin{cases}x,\ if\ x \geq 0\\
                            \alpha x,\ if\ x &lt; 0
               \end{cases}
\]</span></p>
<!--
![Leaky ReLU函数图像](/images/body/the-Basics01/Leaky-ReLU.png "Leaky ReLU")
-->
<figure>
<img data-src="pics01/Leaky-ReLU.png" title="Leaky ReLU"
alt="Leaky ReLU函数图像" />
<figcaption aria-hidden="true">Leaky ReLU函数图像</figcaption>
</figure>
<p>优点：</p>
<ol type="1">
<li>神经元不会出现死亡的情况。</li>
<li>对于所有的输入，不管是大于等于0还是小于0，神经元不会饱和。</li>
<li>由于Leaky ReLU线性、非饱和的形式，在SGD中能够快速收敛。</li>
<li>计算速度要快很多。Leaky
ReLU函数只有线性关系，不需要指数计算，不管在前向传播还是反向传播，计算速度都比sigmoid和tanh快。</li>
</ol>
<p>缺点：Leaky ReLU函数中的参数 <span
class="math inline">\(\alpha\)</span>，需要通过先验知识人工赋值。</p>
<p>Leaky ReLU很好地解决了“dead ReLU”的问题。因为Leaky
ReLU保留了x小于0时的梯度，在x小于0时，不会出现神经元死亡的问题。对于Leaky
ReLU给出了一个很小的负数梯度值α，这个值是很小的常数。比如：0.01。这样即修正了数据分布，又保留了一些负轴的值，使得负轴信息不会全部丢失。</p>
<h3 id="rrelu">RReLU</h3>
<p>RReLU的英文全称是“Randomized Leaky
ReLU”，中文名字叫“随机修正线性单元”。RReLU是Leaky ReLU的随机版本。</p>
<p><span class="math display">\[
y_{ji} = \begin{cases}x_{ji},\ if\ x_{ji} \geq 0\\
                            \alpha_{ji} x_{ji},\ if\ x_{ji} &lt; 0
               \end{cases}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\alpha_{ji} \sim U(l, u),\ l &lt; u\ and\ l,\ u \in [0, 1)
\]</span></p>
<p><!--
![RReLU函数图像](/images/body/the-Basics01/RReLU.png "RReLU")
--></p>
<figure>
<img data-src="pics01/RReLU.png" title="RReLU" alt="RReLU函数图像" />
<figcaption aria-hidden="true">RReLU函数图像</figcaption>
</figure>
<p>RReLU的核心思想是，在训练过程中，<span
class="math inline">\(\alpha\)</span> 是从一个高斯分布 <span
class="math inline">\(U(l, u)\)</span>
中随机出来的值，然后再在测试过程中进行修正。在测试阶段，把训练过程中所有的
<span class="math inline">\(\alpha_{ij}\)</span> 取个平均值。</p>
<ol type="1">
<li><p>RReLU是Leaky
ReLU的random版本，在训练过程中，α是从一个高斯分布中随机出来的，然后再测试过程中进行修正。</p></li>
<li><p>数学形式与PReLU类似，但RReLU是一种非确定性激活函数，其参数是随机的</p></li>
</ol>
<h3 id="elu">ELU</h3>
<p>ELU的英文全称是“Exponential Linear
Units”，中文全称是“指数线性单元”。它试图将激活函数的输出<em>均值接</em>零，从而加快学习速度。同时，它还能通过正值的标识来避免梯度消失的问题。根据一些研究显示，ELU分类精确度是高于ReLU的。</p>
<p><span class="math display">\[
ELU(x) = \begin{cases}x,\ if\ x &gt; 0\\
                \alpha(e^x - 1),\ if\ x \leq 0
               \end{cases}
\]</span></p>
<p><!--
![ReLU及其变种对比](/images/body/the-Basics01/contrast.png "contrast")
--></p>
<figure>
<img data-src="pics01/contrast.png" title="contrast"
alt="ReLU及其变种对比" />
<figcaption aria-hidden="true">ReLU及其变种对比</figcaption>
</figure>
<p>优点：</p>
<ol type="1">
<li>ELU包含了ReLU的所有优点。</li>
<li>神经元不会出现死亡的情况。</li>
<li>ELU激活函数的输出均值是接*于零的。</li>
</ol>
<p>缺点：计算的时候是需要计算指数的，存在计算效率低的问题。</p>
<h3 id="maxout">Maxout</h3>
<p>Maxout “Neuron”
是由Goodfellow等人在2013年提出的一种很有特点的神经元，它的激活函数、计算的变量、计算方式和普通的神经元完全不同，并有两组权重。先得到两个超平面，再进行最大值计算。激活函数是对ReLU和Leaky
ReLU的一般化归纳，没有ReLU函数的缺点，不会出现激活函数饱和神经元死亡的情况。Maxout出现在ICML2013上，作者Goodfellow将maxout和dropout结合，称在MNIST，CIFAR-10，CIFAR-100，SVHN这4个数据集上都取得了start-of-art的识别率。</p>
<p><span class="math display">\[
f_i(x) = \max_{j\in [1, k]}z_{ij}
\]</span></p>
<p>其中，<span class="math inline">\(z_{ij} = x^TW_{\ldots ij} +
b_{ij}\)</span>，假设 <span class="math inline">\(W\)</span>
是二维的，那么我们有</p>
<p><span class="math display">\[
f(x) = \max(w^T_1x + b_1, w^T_2x + b_2)
\]</span></p>
<p>Maxout的拟合能力非常强，它可以拟合任意的凸函数。Goodfellow在论文中从数学的角度上也证明了这个结论，只需要2个Maxout节点就可以拟合任意的凸函数，前提是“隐含层”节点的个数足够多。</p>
<p>优点：</p>
<ol type="1">
<li>Maxout具有ReLU的所有优点，线性、不饱和性。</li>
<li>同时没有ReLU的一些缺点。如：神经元的死亡。</li>
</ol>
<p>缺点：从这个激活函数的公式中可以看出，每个neuron将有两组 <span
class="math inline">\(w\)</span>，那么参数就增加了一倍。这就导致了整体参数的数量激增。</p>
<h2 id="如何选择合适的激活函数">如何选择合适的激活函数?</h2>
<p>在实践过程中更多还是需要结合实际情况，考虑不同激活函数的优缺点综合使用。</p>
<ol type="1">
<li><p>通常来说，不能把各种激活函数串起来在一个网络中使用。</p></li>
<li><p>如果使用ReLU，那么一定要小心设置学习率(learning
rate)，并且要注意不要让网络中出现很多死亡神经元。如果死亡神经元过多的问题不好解决，可以试试Leaky
ReLU、PReLU、或者Maxout。</p></li>
<li><p>尽量不要使用sigmoid激活函数，可以试试tanh，不过还是建议非饱和激活函数。</p></li>
</ol>
<h1 id="损失函数">损失函数</h1>
<p>损失函数使用主要是在模型的训练阶段，每个批次的训练数据送入模型后，通过前向传播输出预测值，然后损失函数会计算出预测值和真实值之间的差异值，也就是损失值。得到损失值之后，模型通过反向传播去更新各个参数，来降低真实值与预测值之间的损失，使得模型生成的预测值往真实值方向靠拢，从而达到学习的目的。</p>
<h2 id="基于距离度量的损失函数">基于距离度量的损失函数</h2>
<h3 id="msel1l2">MSE、L1、L2</h3>
<p>见<a href="#mse">相应部分</a>。</p>
<h3 id="smooth-l1损失函数">Smooth L1损失函数</h3>
<p>Smooth L1损失是由Girshick R在Fast
R-CNN中提出的，主要用在目标检测中防止梯度爆炸。</p>
<p><span class="math display">\[
L(Y|f(x)) = \begin{cases}\frac{1}{2}(Y - f(x))^2,\ if\ \vert Y -
f(x)\vert &lt; 1\\
                \vert Y - f(x)\vert - \frac{1}{2},\ if\ x\vert Y -
f(x)\vert \geq 1
               \end{cases}
\]</span></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def Smooth_L1(x,y):</span><br><span class="line">    assert len(x)==len(y)</span><br><span class="line">    loss=0</span><br><span class="line">    for i_x,i_y in zip(x,y):</span><br><span class="line">        tmp = abs(i_y-i_x)</span><br><span class="line">        if tmp&lt;1:</span><br><span class="line">            loss+=0.5*(tmp**2)</span><br><span class="line">        else:</span><br><span class="line">            loss+=tmp-0.5</span><br><span class="line">    return loss</span><br></pre></td></tr></table></figure>
<h3 id="huber损失函数">Huber损失函数</h3>
<p>huber损失是平方损失和绝对损失的综合，它克服了平方损失和绝对损失的缺点，不仅使损失函数具有连续的导数，而且利用MSE梯度随误差减小的特性，可取得更精确的最小值。尽管huber损失对异常点具有更好的鲁棒性，但是，它不仅引入了额外的参数，而且选择合适的参数比较困难，这也增加了训练和调试的工作量。</p>
<p><span class="math display">\[
L(Y|f(x)) = \begin{cases}\frac{1}{2}(Y - f(x))^2,\ if\ \vert Y -
f(x)\vert \leq \delta\\
                \delta\vert Y - f(x)\vert - \frac{1}{2}\delta^2,\ if\
x\vert Y - f(x)\vert &gt; \delta
               \end{cases}
\]</span></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">delta=1.0  # 先定义超参数</span><br><span class="line"></span><br><span class="line">def huber_loss(x,y):</span><br><span class="line">    assert len(x)==len(y)</span><br><span class="line">    loss=0</span><br><span class="line">    for i_x,i_y in zip(x,y):</span><br><span class="line">        tmp = abs(i_y-i_x)</span><br><span class="line">        if tmp&lt;=delta:</span><br><span class="line">            loss+=0.5*(tmp**2)</span><br><span class="line">        else:</span><br><span class="line">            loss+=tmp*delta-0.5*delta**2</span><br><span class="line">    return loss</span><br></pre></td></tr></table></figure>
<h3 id="log-cosh损失函数">Log-Cosh损失函数</h3>
<p>Log-Cosh是应用于回归任务中的另一种损失函数，它比L2损失更平滑。Log-cosh是预测误差的双曲余弦的对数。</p>
<p>log-cosh损失函数比均方损失函数更加光滑，具有huber损失函数的所有优点，且二阶可导。因此可以使用牛顿法来优化计算，但是在误差很大情况下，一阶梯度和Hessian会变成定值，导致牛顿法失效。</p>
<p><span class="math display">\[
L(y, y^p) = \sum^n_{i = 1}\log(\cosh(y^p_i - y_i))
\]</span></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># log cosh 损失</span><br><span class="line">def logcosh(true, pred):</span><br><span class="line">    loss = np.log(np.cosh(pred - true))return np.sum(loss)</span><br></pre></td></tr></table></figure>
<h3 id="分位数损失函数">分位数损失函数</h3>
<p>预测的是目标的取值范围而不是值。<span
class="math inline">\(\gamma\)</span>
是所需的分位数，其值介于0和1之间，<span
class="math inline">\(\gamma\)</span> 等于0.5时，相当于MAE。 设置多个
<span class="math inline">\(\gamma\)</span>
值，得到多个预测模型，然后绘制成图表，即可知道预测范围及对应概率(两个
<span class="math inline">\(\gamma\)</span> 值相减)</p>
<p><span class="math display">\[
L_\gamma(y, y^p) = \sum_{i = y_i &lt; y^p_i}(\gamma - 1)\ldotp\vert y_i
- y^p_i\vert + \sum_{i = y_i\geq y^p_i}(\gamma)\ldotp\vert y_i -
y^p_i\vert
\]</span></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def quantile_loss(y_pred, y_true, r=0.5):</span><br><span class="line">    greater_mask = K.cast((y_true &lt;= y_pred), &#x27;float32&#x27;)</span><br><span class="line">    smaller_mask = K.cast((y_true &gt; y_pred), &#x27;float32&#x27;)</span><br><span class="line">    loss = K.sum((r-1)*K.abs(smaller_mask*(y_true-y_pred)), -1) +\</span><br><span class="line">           K.sum(r*K.abs(greater_mask*(y_true-y_pred)), -1)</span><br><span class="line">    return loss</span><br></pre></td></tr></table></figure>
<h2 id="基于概率分布度量的损失函数">基于概率分布度量的损失函数</h2>
<p>基于概率分布度量的损失函数是将样本间的相似性转化为随机事件出现的可能性，即通过度量样本的真实分布与它估计的分布之间的距离，判断两者的相似度，一般用于涉及概率分布或预测类别出现的概率的应用问题中，在分类问题中尤为常用。</p>
<h3 id="kl散度函数相对熵">KL散度函数（相对熵）</h3>
<p>KL散度（ Kullback-Leibler
divergence）也被称为相对熵，是一种非对称度量方法，常用于度量两个概率分布之间的距离。KL散度也可以衡量两个随机分布之间的距离，两个随机分布的相似度越高的，它们的KL散度越小，当两个随机分布的差别增大时，它们的KL散度也会增大，因此KL散度可以用于比较文本标签或图像的相似性。基于KL散度的演化损失函数有JS散度函数。JS散度也称JS距离，用于衡量两个概率分布之间的相似度，它是基于KL散度的一种变形，消除了KL散度非对称的问题，与KL散度相比，它使得相似度判别更加准确。</p>
<p>相对熵是恒大于等于0的。当且仅当两分布相同时，相对熵等于0。</p>
<p><span class="math display">\[
L(Y|f(x)) = \sum^n_{i = 1}Y_i \times \log(\frac{Y_i}{f(x_i)})
\]</span></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def kl_loss(y_true:list,y_pred:list):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    y_true,y_pred，分别是两个概率分布</span><br><span class="line">    比如：px=[0.1,0.2,0.8]</span><br><span class="line">          py=[0.3,0.3,0.4]</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    assert len(y_true)==len(y_pred)</span><br><span class="line">    KL=0</span><br><span class="line">    for y,fx in zip(y_true,y_pred):</span><br><span class="line">        KL+=y*np.log(y/fx)</span><br><span class="line">    return KL</span><br></pre></td></tr></table></figure>
<h3 id="交叉熵损失">交叉熵损失</h3>
<p>交叉熵是信息论中的一个概念，最初用于估算平均编码长度，引入机器学习后，用于评估当前训练得到的概率分布与真实分布的差异情况。为了使神经网络的每一层输出从线性组合转为非线性逼近，以提高模型的预测精度，在以交叉熵为损失函数的神经网络模型中一般选用tanh、sigmoid、softmax或ReLU作为激活函数。</p>
<p>交叉熵损失函数刻画了实际输出概率与期望输出概率之间的相似度，也就是交叉熵的值越小，两个概率分布就越接近，特别是在正负样本不均衡的分类问题中，常用交叉熵作为损失函数。目前，交叉熵损失函数是卷积神经网络中最常使用的分类损失函数，它可以有效避免梯度消散。在二分类情况下也叫做<strong>对数损失函数</strong>。</p>
<p><span class="math display">\[
L(Y|f(x)) = - \sum^n_{i = 1}Y_i\log f(x_i)
\]</span></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def CrossEntropy_loss(y_true:list,y_pred:list):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    y_true,y_pred，分别是两个概率分布</span><br><span class="line">    比如：px=[0.1,0.2,0.8]</span><br><span class="line">          py=[0.3,0.3,0.4]</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    assert len(y_true)==len(y_pred)</span><br><span class="line">    loss=0</span><br><span class="line">    for y,fx in zip(y_true,y_pred):</span><br><span class="line">        loss+=-y * np.log(fx)</span><br><span class="line">    return loss</span><br></pre></td></tr></table></figure>
<p>当正负样本不均衡的时候，通常会在交叉熵损失函数类别前面加个参数α</p>
<p><span class="math display">\[
CE = \begin{cases} -\alpha\log(p),\ y = 1\\
                   -(1 - \alpha)\log(1 - p),\ y = 0
     \end{cases}
\]</span></p>
<h3 id="softmax损失函数">Softmax损失函数</h3>
<p>从标准形式上看，softmax损失函数应归到对数损失的范畴，在监督学习中，由于它被广泛使用，所以单独形成一个类别。softmax损失函数本质上是逻辑回归模型在多分类任务上的一种延伸，常作为CNN模型的损失函数。softmax损失函数的本质是将一个k维的任意实数向量x映射成另一个k维的实数向量，其中，输出向量中的每个元素的取值范围都是(0,1)，即softmax损失函数输出每个类别的预测概率。由于softmax损失函数具有类间可分性，被广泛用于分类、分割、人脸识别、图像自动标注和人脸验证等问题中，其特点是类间距离的优化效果非常好，但类内距离的优化效果比较差。</p>
<p>softmax损失函数具有类间可分性，在多分类和图像标注问题中，常用它解决特征分离问题。在基于卷积神经网络的分类问题中，一般使用softmax损失函数作为损失函数，但是softmax损失函数学习到的特征不具有足够的区分性，因此它常与对比损失或中心损失组合使用，以增强区分能力。</p>
<p><span class="math display">\[
L(Y|f(x)) = - \frac{1}{n}\sum^n_{i = 1}\log\frac{e^{f_{Y_i}}}{\sum^c_{j
= 1}e^{f_j}}
\]</span></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def softmax(x):</span><br><span class="line">    x_exp = np.exp(x)</span><br><span class="line">    x_sum = np.sum(x_exp, axis=1, keepdims=True)</span><br><span class="line">    s = x_exp / x_sum</span><br><span class="line">    return s</span><br><span class="line"></span><br><span class="line"># Tensorflow2.0版</span><br><span class="line">softmax_fc = tf.keras.activations.softmax(x)</span><br><span class="line"># pytorch版</span><br><span class="line">softmax_fc = torch.nn.Softmax()</span><br><span class="line">output = softmax_fc(x)</span><br></pre></td></tr></table></figure>
<h3 id="focal-loss">Focal loss</h3>
<p>focal
loss的引入主要是为了解决难易样本不均衡的问题，注意有区别于正负样本不均衡的问题。难易样本分为四个类型：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">难</th>
<th style="text-align: center;">易</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">正</td>
<td style="text-align: center;">正难</td>
<td style="text-align: center;">正易</td>
</tr>
<tr class="even">
<td style="text-align: center;">负</td>
<td style="text-align: center;">负难</td>
<td style="text-align: center;">负易</td>
</tr>
</tbody>
</table>
<p>易分样本虽然损失很低，但是数量太多，对模型的效果提升贡献很小，模型应该重点关注那些难分样本，因此需要把置信度高的损失再降低一些。</p>
<p><span class="math display">\[
FE = \begin{cases}-\alpha(1 - p)^\gamma\log(p),\ y = 1\\
                  -(1 - \alpha)p^\gamma\log(1 - p),\ y = 0
     \end{cases}
\]</span></p>
<h2 id="如何选择损失函数">如何选择损失函数</h2>
<p>通常情况下，损失函数的选取应从以下方面考虑：</p>
<ol type="1">
<li>选择最能表达数据的主要特征来构建基于距离或基于概率分布度量的特征空间。</li>
<li>选择合理的特征归一化方法，使特征向量转换后仍能保持原来数据的核心内容。</li>
<li>选取合理的损失函数，在实验的基础上，依据损失不断调整模型的参数，使其尽可能实现类别区分。</li>
<li>合理组合不同的损失函数，发挥每个损失函数的优点，使它们能更好地度量样本间的相似性。</li>
<li>将数据的主要特征嵌入损失函数，提升基于特定任务的模型预测精确度。</li>
</ol>
<h1 id="反向传播算法公式推导">反向传播算法（公式推导）</h1>
<p>反向传播算法（Backpropagation）是目前用来训练人工神经网络（Artificial
Neural Network，ANN）的最常用且最有效的算法。其主要思想是：</p>
<ol type="1">
<li>将训练集数据输入到ANN的输入层，经过隐藏层，最后达到输出层并输出结果，这是ANN的前向传播过程；</li>
<li>由于ANN的输出结果与实际结果有误差，则计算估计值与实际值之间的误差，并将该误差从输出层向隐藏层反向传播，直至传播到输入层；</li>
<li>在反向传播的过程中，根据误差调整各种参数的值；不断迭代上述过程，直至收敛。</li>
</ol>
<h2 id="变量定义">变量定义</h2>
<p><!--
![神经网络](/images/body/the-Basics01/NN.png "NN")
--></p>
<figure>
<img data-src="pics01/NN.png" title="NN" alt="神经网络" />
<figcaption aria-hidden="true">神经网络</figcaption>
</figure>
<p>上图是一个三层人工神经网络，layer1至layer3分别是输入层、隐藏层和输出层。</p>
<p>定义变量：</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">变量</th>
<th style="text-align: center;">表示</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span
class="math inline">\(w^l_{jk}\)</span></td>
<td style="text-align: center;">第 <span class="math inline">\((l -
1)\)</span> 层的第 <span class="math inline">\(k\)</span>
个神经元连接到第 <span class="math inline">\(l\)</span> 层的第 <span
class="math inline">\(j\)</span> 个神经元的权重</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span
class="math inline">\(b^l_j\)</span></td>
<td style="text-align: center;">第 <span
class="math inline">\(l\)</span> 层的第 <span
class="math inline">\(j\)</span> 个神经元的偏置</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span
class="math inline">\(z^l_j\)</span></td>
<td style="text-align: center;">第 <span
class="math inline">\(l\)</span> 层的第 <span
class="math inline">\(j\)</span> 个神经元的输入，即：<span
class="math inline">\(z^l_j = \sum_kw^l_{jk}a^{l - 1}_k +
b^l_j\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span
class="math inline">\(a^l_j\)</span></td>
<td style="text-align: center;">第 <span
class="math inline">\(l\)</span> 层的第 <span
class="math inline">\(j\)</span> 个神经元的输出，即：<span
class="math inline">\(a^l_j = \sigma(z^l_j)\)</span>，其中 <span
class="math inline">\(\sigma\)</span> 表示激活函数</td>
</tr>
</tbody>
</table>
<h2 id="代价函数">代价函数</h2>
<p>代价函数被用来计算ANN输出值与实际值之间的误差。常用的代价函数是二次代价函数（Quadratic
cost function）：</p>
<p><span class="math display">\[
C = \frac{1}{2n}\sum_x\Vert y(x) - a^L(x)\Vert^2
\]</span></p>
<p>其中，<span class="math inline">\(x\)</span> 表示输入的样本，<span
class="math inline">\(y\)</span> 表示实际的分类，<span
class="math inline">\(a^L\)</span> 表示预测的输出，<span
class="math inline">\(L\)</span>表示神经网络的最大层数。</p>
<h2 id="公式及其推导">公式及其推导</h2>
<p>首先，将第 <span class="math inline">\(l\)</span> 层第 <span
class="math inline">\(j\)</span>
个神经元中产生的错误(即实际值与预测值之间的误差)定义为:</p>
<p><span class="math display">\[
\delta^l_j = \frac{\partial C}{\partial z^l_j}
\]</span></p>
<p>以一个输入样本为例,此时代价函数为：</p>
<p><span class="math display">\[
C = \frac{1}{2}\Vert y - a^L\Vert^2 = \frac{1}{2}\sum_j(y_j - a^L_j)^2
\]</span></p>
<h3
id="计算最后一次神经网络产生的错误">计算最后一次神经网络产生的错误：</h3>
<p><span class="math display">\[
\delta^L = \nabla_a C \odot \sigma&#39;(z^L)
\]</span></p>
<p>其中，<span class="math inline">\(\cdot\)</span>
表示Hadamard乘积，用于矩阵或向量之间点对点的乘法运算。推导过程如下：</p>
<p><span class="math display">\[
\because \delta^L_j = \frac{\partial C}{\partial z^L_j} = \frac{\partial
C}{\partial a^L_j}\cdot\frac{\partial a^L_j}{\partial z^L_j}\\
\therefore \delta^L = \frac{\partial C}{\partial a^L}\odot\frac{\partial
a^L}{\partial z^L} = \nabla_a C \odot \sigma&#39;(z^L)\\
\]</span></p>
<h3
id="从后向前计算每一层神经网络产生的错误">从后向前，计算每一层神经网络产生的错误</h3>
<p><span class="math display">\[
\delta^l = ((w^{l + 1})^T\delta^{l+1})\odot\sigma&#39;(z^l)
\]</span></p>
<p>推导过程：</p>
<p><span class="math display">\[
\begin{aligned}
\because \delta^l_j = \frac{\partial C}{\partial z^l_j} &amp; =
\sum_k\frac{\partial C}{\partial z^{l+1}_k}\cdot\frac{\partial
z^{l+1}_k}{\partial a^l_j}\cdot\frac{\partial a^l_j}{\partial z^l_j}\\
&amp; = \sum_k\delta^{l+1}_k\cdot\frac{\partial(w^(l+1)_{kj}a^l_j +
b^{l+1}_k)}{\partial a^l_j}\cdot\sigma&#39;(z^l_j)\\
&amp; = \sum_k\delta^{l+1}_k\cdot w^{l+1}_{kj}\cdot\sigma&#39;(z^l_j)\\
\therefore \delta^l = ((w^{l + 1})^T\delta^{l+1})\odot\sigma&#39;(z^l)
\end{aligned}
\]</span></p>
<h3 id="计算权重的梯度">计算权重的梯度</h3>
<p><span class="math display">\[
\frac{\partial C}{\partial w^l_{jk}} = a^{l-1}_k\delta^l_j
\]</span></p>
<p>推导过程：</p>
<p><span class="math display">\[
\frac{\partial C}{\partial w^l_{jk}} = \frac{\partial C}{\partial
z^l_j}\cdot\frac{\partial z^l_j}{\partial w^l_{jk}} =
\delta^l_j\cdot\frac{\partial(w^l_{jk}a^{l-1}_k + b^l_j)}{\partial
w^l_{jk}} = a^{l-1}_k\delta^l_j
\]</span></p>
<h3 id="计算偏置的梯度">计算偏置的梯度</h3>
<p><span class="math display">\[
\frac{\partial C}{\partial b^l_j} = \delta^l_j
\]</span></p>
<p>推导过程：</p>
<p><span class="math display">\[
\frac{\partial C}{\partial b^l_j} = \frac{\partial C}{\partial
z^l_j}\cdot\frac{\partial z^l_j}{\partial b^l_j} =
\delta^l_j\cdot\frac{\partial(w^l_{jk}a^{l-1}_k + b^l_j)}{\partial
b^l_j} = \delta^l_j
\]</span></p>
<h1 id="过拟合与欠拟合">过拟合与欠拟合</h1>
<h2 id="过拟合">过拟合</h2>
<p>定义1（摘自周志华机器学习）：当学习器把训练样本学的“太好”了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降，这种现象称为过拟合。</p>
<p>定义2：具体表现就是最终模型在训练集上效果好；在测试集上效果差。模型泛化能力弱。</p>
<p>具体表现就是最终模型在训练集上效果好；在测试集上效果差。模型泛化能力弱。</p>
<h3 id="产生过拟合的原因">产生过拟合的原因</h3>
<ol type="1">
<li>训练数据中噪音干扰过大，使得学习器认为部分噪音是特征从而扰乱学习规则。</li>
<li>建模样本选取有误，例如训练数据太少，抽样方法错误，样本label错误等，导致样本不能代表整体。</li>
<li>模型不合理，或假设成立的条件与实际不符。</li>
<li>特征维度/参数太多，导致模型复杂度太高。</li>
<li>对于决策树模型，如果我们对于其生长没有合理的限制，其自由生长有可能使节点只包含单纯的事件数据(event)或非事件数据(no
event)，使其虽然可以完美匹配（拟合）训练数据，但是无法适应其他数据集。</li>
<li>对于神经网络模型：a)对样本数据可能存在分类决策面不唯一，随着学习的进行,，BP算法使权值可能收敛过于复杂的决策面；b)权值学习迭代次数足够多(Overtraining)，拟合了训练数据中的噪声和训练样例中没有代表性的特征。</li>
</ol>
<h3 id="过拟合的解决办法">过拟合的解决办法</h3>
<p>过拟合无法彻底避免，只能缓解。</p>
<h4 id="数据角度">数据角度</h4>
<ul>
<li>从数据源头获取更多数据</li>
<li>数据增强（Data
Augmentation）:通过一定规则扩充数据。如物体在图像中的位置、姿态、尺度、整体图片明暗度等都不会影响分类结果。我们可以通过图像平移、反转、缩放、切割等手段将数据库成倍扩充。</li>
<li>保留验证集</li>
<li>获取额外数据进行交叉验证</li>
</ul>
<h4 id="模型角度">模型角度</h4>
<ul>
<li>降低模型复杂度：
<ul>
<li>对于神经网络：减少网络的层数、神经元个数等均可以限制网络的拟合能力。dropout，在向前传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型的泛化性更强，因为它不会太依赖某些局部的特征。</li>
<li>对于决策树：限制树深，剪枝，限制叶节点数量。</li>
<li>增大分割平面间隔</li>
</ul></li>
<li>特征选择、特征降维</li>
<li>early stopping、Dropout</li>
<li>正则化（限制权值weight-decay）：将权值的大小作为惩罚项加入到损失函数里。</li>
<li>增加噪声：
<ul>
<li>在输入中加噪声。噪声会随着网络传播，按照权值的平方放大，并传播到输出层，会在输出中生成
<span class="math inline">\(\sum_iw^2_i\cdot\sigma^2_i\)</span>
的干扰项。训练时减小损失函数时也会减小权值，与L2正则化有类似效果。</li>
<li>在权值上加噪声。在初始化网络的时候，用0均值的高斯分布作为初始化。</li>
<li>对网络等响应加噪声。在前向传播的过程中，让某些神经元的输出变为random，从而打乱网络的训练过程，让训练更慢。</li>
</ul></li>
</ul>
<h4 id="ensemble">ensemble：</h4>
<ul>
<li>Bagging:从训练集中自助采样，训练多个相互独立的弱学习器，通过一定结合策略形成一个强学习器。</li>
<li>Boosting:
初始化训练一个基学习器→根据表现调整样本分布（预测错误的样本在后续收到更多关注）→训练下一个基学习器→多个学习器加权结合。</li>
</ul>
<h2 id="欠拟合">欠拟合</h2>
<p>定义：欠拟合是指对训练样本的一般性质尚未学好。在训练集及测试集上的表现都不好。</p>
<h3 id="产生欠拟合的原因">产生欠拟合的原因</h3>
<ol type="1">
<li>模型复杂度过低</li>
<li>特征量过少</li>
</ol>
<h3 id="欠拟合的解决办法">欠拟合的解决办法</h3>
<ul>
<li>增加特征数；当特征不足或者现有特征与样本标签的相关性不强时，模型易出现欠拟合。可以通过挖掘上下文特征，ID类特征，组合特征等新的特征，可以取得较好的效果。这属于特征工程相关的内容，如因子分解机，梯度提升决策树，deep_crossing都可以丰富特征。</li>
<li>增加模型复杂度；模型简单时其表达能力较差，容易导致欠拟合，因此可以适当地增加模型复杂度，使模型拥有更强的拟合能力。如线性模型中添加高次项，神经网络中增加网络层数或神经元个数。尝试非线性模型，比如核SVM
、决策树、DNN等模型。</li>
<li>减小正则化系数。正则化是用于防止过拟合的，但是当出现欠拟合时，就有必要针对性地减小正则化系数。</li>
<li>Boosting，Boosting 往往会有较小的 Bias。</li>
<li>调整参数和超参数</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Zheng. w/ his five DADs</title>
    <url>/Life/Zheng-with-his-five-dads/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Invalid Password. Check And Try Again! (♯｀∧´)" data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="829dc106f00c1fccc50f3c3896421b07f1d55067ab91d6cf050486eb3e50c8a5">0009b526956f94ef03d39ae6245de4b0df62b63f810ef18ffb43c6d81bdca6991be1f6e0866728f514015e28f5044dd4ac2f1795ab3bd0116158934acf82b72bd25dcda50818f8d4cf33a37357c9374c723876b61a498860ee8fdf1b12077043fcd6b404272af65618fedf26cd30b6a69779d185c4384f8ae27aded4c0256986c9ef47dbab462ee421a50e8d638bd825692ca8c88398e10aec78ad2760785fe0c0456d699da3235a3fa08cab02bf249d233ffa3f5fa3020663eacb74c4d20c242cc5ba696dec7c3cd0b1d20dc794e17b85767b027f33d8cca1f58dbbbf9e2e29cda4ba686efed03445c5e350787d813fee5a587572d1ef414dbcac1d6281fcd49b1504cd7be104b854274c578f010bb957d830841333a1504ff8eb82147a071a4a898d366e0c86d32d191b74ec2ab4d8b274289945603309db9e952a7cc58b5c900b5bd83a758db3790f329379a536ed295ff04a16c4ec327e21081a88fd0bb73a639445e25a01a52fe83a52d34bacc5c1b9389c4a30e42736516c0702eba18cdda59b840d7b3749301e382d09f130db66ec9934d2dd1d3afa1c3416627e2c31031aa1e438f71b11a3c36beed4e3c1f8238cfc4190cefeebd4100b51ad179226e544295c1518d69a2a1fae2da133c5b3babeb3712fb8234c1ce2a2450656b38f8e5b9eeb5b59303aebdcdc974180ace91f30d0cde5c343cb57ee780692fc76982432686cc0e485c5685f268e262c085b79e44af526317f2dbd98134dddd15e31d7588d1e91ad0ed1862f2edcbbe639207e5a3866544e6df0dd1ca61dfe4ab17985b61e5c1ab88c0744dd7dba3d4a72dd05e9380a0f19de47f2e82c5c16e6db31a28132b44e39fa3ed4b752d87eb86ad94192e75056a40c2fb76f0acf409fb3ca569a2c760565c01ddc59c035c4f9ef7f019f311439047de63e96d971b86548cb7e1f18503de2de073e330abeac6b5f67e8dfab3495d842388d560bf8cf5e2cc488609444d9f87813c3faa1067c0ea09a257b89626c9180613a2e7d20658647408b19b72df90f4a79668966890e35371e78f1ef0927db62d8db5fe7ba629dd3f405c0e405a2391728dd5a7a8840b324d65b3e9ab135f50844dc38e5cc5ea5a9729d2b4d53174cdca391bd5bf684adbe089f4ab6a50a505d30c6e0618134ac56ea47cf6b600bf8507180f656cce16c6dc538dc6778f9f20901c50a6a9b14cb695d1fe5a8ff5987594c435274bc163129c321476c6b6c8c9257b06e14eb4f159fa5dbf070fede9d71bf7ebe417a6236518a44c39f9e2389591a333442ef7173160cc54944bc1597cff439278db5054dbc9770a7f806131d8cde31607157e2550a7082570fd1190a39547506c36b44b47095eb24459419bf2a0fe879553407117d1f727f1d504cfe48b2aaa7d5d9b808884c79ed34992ae5931f8f039267790efe2a8405151ba0f4840b2d9add8dffb99c94a255648e193eba7774ff845891533ec64bb2c7af32a71ab1a97c81d8ff5ae5839f04029da00ea0ba8c510ea52807c30b3abd4101da2cf6b11a433a9e8b1809ac2108aa433ecebb0707c02eb4a3978867f9fdcab4f66415b6c9a386a9cd795cfd5e867463f683419f0e6724a9949e100a846ecd70472642635eb6095b5efaebb91a840e9d5e62e26342101c80bcc21f57fde6916edba81156df70c9a10374083eb0c0ecb9003392536b5f5fbfde9e1634d738d9416a3bfb781f624ed5da7594d818c1b98d8c4771d6cf0b6c2c0c7580d78490e3dea05419061289ebe8d8a53d7421fa29a65b070b43d120c41295e7ad1342763ba435e73d276e20a4a4c3bbb1541c2aedbdaa3631d65a7c643514af1e534577c635d5983e253a53c81edfd41a2c84a57be2b40aafa071f45b5f66eef3f1729482eb882f7f332f3eb4cf4e4e1e61655e14896745d50d5e6cacdaf7441e3b93a8f532eb1836705b8050b2d694a3cc28580da4e606f1acddb69f593aa9b614c6e394bdf14d39194527c23f44a9fec05b4c0b8eb13200b91a456e1d5382d79837306ad8f4a6ced669f16a5248e71ec5d967235ea11d4fa292dec74c6be65e98e054ce3648b8b51a2414567cdcebd87d845c12aa8fc62d8d30c27b2b589ebf5bacc21d6cba77efbe8e060f64ea3aa36caecdd7e967794dd70c559c2760f1105380d9cd7a5a4b3bab2806e9a65d01be4332375240a136c4012d4e01a08baca807201b345cdcea61758c546ef1c01be0030c76ef728eacb1d8766bef9b0e74c4f4a86f5b9674756b1bf4e0f47977b8f9386d07b3650bc98c1ecb4854459bdb4236c8e649b8ce78bb5d78c6b2f1ba817d21a7ce6e69636947ac6630ced3301a775b057fde8e523ac09fd4f42ba77351246df76b900a2c0a5c68f6f657bb4426f23f704bdc9be2b259677e9c935bcfaf6065534d154cf28af0b64ce8eb5d76b85e31</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>Life</tag>
        <tag>529</tag>
        <tag>Suda</tag>
      </tags>
  </entry>
  <entry>
    <title>Nintendo Memo</title>
    <url>/Game/Nintendo_Memo/</url>
    <content><![CDATA[<p>来这里加任天堂系列掌机好友！</p>
<span id="more"></span>
<h1 id="switch-pro-.jpn">Switch pro .jpn</h1>
<ul>
<li>SW <kbd>6096-3331-7333</kbd></li>
</ul>
<h1 id="clear-black-2ds-.jpn">Clear Black 2DS .jpn</h1>
<ul>
<li>FC <kbd>2638-6497-9254</kbd></li>
<li>NNID zx-will</li>
<li>E-mail <span class="exturl" data-url="bWFpbHRvOno0OTYzNzMxNThAMTYzLmNvbQ==">z496373158@163.com<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<h1 id="pikachu-new-3ds-xl-.usa">Pikachu New 3DS xl .usa</h1>
<ul>
<li>FC <kbd>1221-3439-8867</kbd></li>
<li>NNID willkyu</li>
<li>E-mail <span class="exturl" data-url="bWFpbHRvOjQ5NjM3MzE1OEBxcS5jb20=">496373158@qq.com<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<h1 id="colourful-star-new-3ds-.jpn">Colourful Star New 3DS .jpn</h1>
<ul>
<li>FC <kbd>1049-5610-3284</kbd></li>
<li>NNID willQkyu</li>
<li>E-mail <span class="exturl" data-url="bWFpbHRvOndpbGwxMjMzMjEwQDE2My5jb20=">will1233210@163.com<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<h1 id="ambassador-new-3ds-.eur">Ambassador New 3DS .eur</h1>
<ul>
<li>FC <kbd>1264-3252-0970</kbd></li>
<li>NNID willkyu13</li>
<li>E-mail <span class="exturl" data-url="bWFpbHRvOndpbGxxa3l1QGdtYWlsLmNvbQ==">willqkyu@gmail.com<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<h1 id="pearl-white-new-3ds-ll-.jpn">Pearl White New 3DS ll .jpn</h1>
<ul>
<li>FC <kbd>1135-2937-9812</kbd></li>
<li>NNID willQQ</li>
<li>E-mail <span class="exturl" data-url="bWFpbHRvOjIxMzY3MDc2NjJAcXEuY29t">2136707662@qq.com<i class="fa fa-external-link-alt"></i></span></li>
</ul>
]]></content>
      <categories>
        <category>Memo</category>
      </categories>
      <tags>
        <tag>Game</tag>
        <tag>Memo</tag>
        <tag>Nintendo</tag>
      </tags>
  </entry>
  <entry>
    <title>锁闪宝可梦汇总</title>
    <url>/Pokemon/Shiny-Lock/</url>
    <content><![CDATA[<p>游戏内锁闪宝可梦汇总.
不包含配信的闪光宝可梦与联动的宝可梦(如SwSh伙伴皮卡丘伊布、BdSp首发特典等).</p>
<p>如有纰漏请在下方留言或<a href="/about/">与我联系</a>.</p>
<p>封面 [ID:57993916].</p>
<span id="more"></span>
<h1 id="shiny-lock">Shiny-Lock</h1>
<p>若想要直接查看所有能够闪光的定点宝可梦，点击<a
href="https://aminoapps.com/c/pokemon/page/item/gen-1-7-shiny-locked/28hw_ImqqrQ6q8LKZodjqnv7exBnle">这里</a>查看英文版本（不全）.</p>
<p><strong>几乎所有与游戏内NPC交换的宝可梦均无法闪光</strong>，参见神百<a
href="https://wiki.52poke.com/wiki/%E6%B8%B8%E6%88%8F%E5%86%85%E8%BF%9E%E6%8E%A5%E4%BA%A4%E6%8D%A2%E5%88%97%E8%A1%A8">游戏内连接交换列表</a>.
<strong><em>除了第一世代与NPC的交换、LpLe与NPC的交换、SwSh铠之孤岛中与易蒂的交换、XD中与NPC的交换</em></strong>.</p>
<h2 id="第一世代与第二世代">第一世代与第二世代</h2>
<ul>
<li><strong>梦幻</strong>（存在争议）</li>
<li><strong>所有性别比7：1中，性别为母的宝可梦</strong></li>
<li>第一世代<strong>所有路闪</strong></li>
</ul>
<h2 id="第三世代">第三世代</h2>
<ul>
<li>日版Co特典盘的<strong>时拉比</strong>与<strong>皮卡丘</strong></li>
<li>Co黄铁镇赠送的<strong>正电拍拍</strong></li>
<li>XD所有黑暗宝可梦</li>
</ul>
<h2 id="第四世代">第四世代</h2>
<ul>
<li><strong>刺刺耳皮丘</strong></li>
<li><strong>玛纳霏的蛋</strong>（可以通过游戏漏洞刷闪）</li>
<li>HgSs湛蓝市NPC赠送的<strong>壶壶</strong>（原版金银不锁）</li>
<li>HgSs满金市闸口裕司赠送的<strong>烈雀</strong>（原版金银不锁）</li>
<li>HgSs所有计步器宝可梦</li>
</ul>
<h2 id="第五世代">第五世代</h2>
<ul>
<li>自由庭园岛的<strong>比克提尼</strong></li>
<li>BW飞云市赠送的<strong>索罗亚</strong>（需要四代配信的时拉比触发剧情）</li>
<li>BW迷幻森林的<strong>索罗亚克</strong>（需要四代配信的闪光凤王卫队之一触发剧情）</li>
<li>BW与BW2的<strong>雷希拉姆</strong>与<strong>捷克罗姆</strong></li>
<li>BW2的所有<strong>隐藏洞穴宝可梦</strong></li>
<li>BW2的所有<strong>N的宝可梦</strong></li>
<li>BW2的所有<strong>赠送宝可梦</strong>（如松露赠送的隐藏特性伊布）</li>
</ul>
<h2 id="第六世代">第六世代</h2>
<ul>
<li>XY７号道路拦路的<strong>卡比兽</strong></li>
<li>XY的<strong>哲尔尼亚斯</strong>与<strong>伊裴尔塔尔</strong></li>
<li>XY游走的<strong>急冻鸟</strong>、<strong>闪电鸟</strong>与<strong>火焰鸟</strong></li>
<li>XY无名洞窟的<strong>超梦</strong></li>
<li>XY剧情赠送的<strong>路卡利欧</strong></li>
<li>XY终结洞窟50%的<strong>基格尔德</strong></li>
<li>XY密阿雷市旭日咖啡馆卡露妮赠送的<strong>拉鲁拉丝</strong></li>
<li>OrAs初始<strong>土狼犬</strong></li>
<li>OrAs<strong>换装皮卡丘</strong></li>
<li>OrAs的<strong>古拉顿</strong>、<strong>盖欧卡</strong>与<strong>裂空座</strong></li>
<li>OrAs的<strong>代欧奇希斯</strong></li>
</ul>
<h2 id="第七世代">第七世代</h2>
<ul>
<li>SM与UsUm的守护神<strong>卡璞・鸣鸣</strong>、<strong>卡璞・蝶蝶</strong>、<strong>卡璞・哞哞</strong>与<strong>卡璞・鳍鳍</strong></li>
<li>SM与UsUm日轮湖月轮湖进入另一个世界的<strong>科斯莫古</strong></li>
<li>SM与UsUm的<strong>索尔迦雷欧</strong>、<strong>露奈雅拉</strong>与<strong>奈克洛兹玛</strong></li>
<li>SM与UsUm的<strong>基格尔德</strong></li>
<li>SM与UsUm购物广场古董精品店赠送的<strong>玛机雅娜</strong></li>
<li>SM的所有<strong>究极异兽</strong></li>
<li>UsUm火箭队城堡的<strong>顽皮雷弹</strong></li>
<li>UsUm的所有<strong>霸主宝可梦</strong></li>
<li>帽子皮卡丘（没有闪光形态但可以闪光）</li>
<li>LpLe初始搭档<strong>皮卡丘</strong>与<strong>伊布</strong></li>
</ul>
<h2 id="第八世代">第八世代</h2>
<ul>
<li>SwSh初始御三家<strong>敲音猴</strong>、<strong>炎兔儿</strong>与<strong>泪眼蜥</strong></li>
<li>SwSh５号道路寄放屋赠送的<strong>毒电婴</strong></li>
<li>SwSh３号道路工厂禁区附近岩石上的<strong>蓝鸦</strong></li>
<li>SwSh对战塔的<strong>属性：空</strong></li>
<li>SwSh的<strong>苍响</strong>、<strong>藏玛然特</strong>与<strong>无极汰那</strong></li>
<li>SwSh木杆镇的伽勒尔<strong>呆呆兽</strong></li>
<li>SwSh丹帝赠送的<strong>小火龙</strong></li>
<li>SwSh铠之孤岛地鼠训练家赠送的所有<strong>阿罗拉宝可梦</strong></li>
<li>SwSh冠之雪原球湖湖畔的<strong>凯路迪欧</strong></li>
<li>SwSh冠之雪原冻凝村赠送的<strong>科斯莫古</strong></li>
<li>SwSh冠之雪原极巨巢穴赠送的<strong>毒贝比</strong></li>
<li>SwSh铠之孤岛马师傅武馆赠送的<strong>熊徒弟</strong>、<strong>妙蛙种子</strong>、<strong>杰尼龟</strong>与<strong>多边兽</strong></li>
<li>SwSh冠之雪原王冠神殿的<strong>雪暴马</strong>、<strong>灵幽马</strong>与<strong>蕾冠王</strong></li>
<li>SwSh冠之雪原伽勒尔形态的<strong>急冻鸟</strong>、<strong>闪电鸟</strong>与<strong>火焰鸟</strong></li>
<li>BdSp狗都不玩</li>
<li>La初始御三家<strong>木木枭</strong>、<strong>火球鼠</strong>与<strong>水水獭</strong></li>
<li>La纯白冻土副任务83赠送的<strong>阿罗拉六尾</strong></li>
<li>La湖之传说的宝可梦<strong>由克希</strong>、<strong>艾姆利多</strong>与<strong>亚克诺姆</strong></li>
<li>La神话的宝可梦<strong>帝牙卢卡</strong>、<strong>帕路奇亚</strong>与<strong>骑拉帝纳</strong></li>
<li>La的<strong>席多蓝恩</strong>、<strong>克雷色利亚</strong>与<strong>雷吉奇卡斯</strong></li>
<li>La海边小洞副任务66的<strong>霏欧纳</strong>与<strong>玛纳霏</strong>，以及之后刷新的<strong>霏欧纳</strong></li>
<li>La的化身宝可梦<strong>龙卷云</strong>、<strong>雷电云</strong>、<strong>土地云</strong>和<strong>眷恋云</strong></li>
<li>La的<strong>阿尔宙斯</strong></li>
</ul>
]]></content>
      <categories>
        <category>Pokemon</category>
      </categories>
      <tags>
        <tag>Pokemon</tag>
        <tag>Shiny</tag>
      </tags>
  </entry>
  <entry>
    <title>LATEX笔记</title>
    <url>/Learning/Notes/LATEX/</url>
    <content><![CDATA[<p>记录LATEX的一些知识点.</p>
<p>大部分内容来自中国 CTEX 用户小组译制的<em>一份不太简短的 LATEX 2ε
介绍</em>.</p>
<p>未完待续.</p>
<span id="more"></span>
<h1 id="基本知识">基本知识</h1>
<h2 id="latex源文件">LATEX源文件</h2>
<p>LATEX 源文件的格式为普通的 ASCII
文件，你可以使用任何文本编辑器来创建。</p>
<h3 id="空白距离">空白距离</h3>
<p>LATEX
将空格和制表符等空白字符视为相同的空白距离（space）。<strong>多个连续的空白字符等同为一个空白字符。</strong>在
LATEX
文件中，每行开始的空白字符将被忽略，而单个的回车符被视为一空格。</p>
<p>LATEX
使用空行来结束段落，两行文本中的空行标志上一段落的结束和新段落的开始。如同空格一样，多个空行所起的作用和一个空行的作用是相同的。</p>
<h3 id="特殊字符">特殊字符</h3>
<p>下面的这些字符是 LATEX 的保留字符:</p>
<p># $ % ^ &amp; _ { } ~ \</p>
<p>在这些字符（除' \ '）前加上' \ '就可以在文本中得到，而'
\ '为断行命令.</p>
<p>命令<code>$\backslash$</code>将生成 ' \ '。</p>
<h3 id="latex命令">LATEX命令</h3>
<p>LATEX 命令（commands）是大小写敏感的并有下面两种格式：</p>
<ul>
<li>以一反斜线' \
'开始，加上只包含字母字符命令名组成。命令名后的空格符、数字或其它非字母字符标志该命令的结束。</li>
<li>由一反斜线和一特殊字符组成。</li>
</ul>
<p>LATEX
忽略命令后面的空格。如果你希望在命令后面得到一空格，可以在命令后面加上
{} 和一个空格，或者加上一个特殊的空白距离命令。{} 将阻止 LATEX
吞噬掉命令后面的空格。例如: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">I read that Knuth divides the people working with \TeX&#123;&#125; into \TeX&#123;&#125;nicians and \TeX perts.\\ Today is \today.</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>得到</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">I read that Knuth divides the people working with TEX into TEXnicians and EXperts. </span><br><span class="line">Today is 8th March 2003.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>许多命令需要一个参数（parameter）并用一对大括号（curly braces）{
}将其括起来置于命令名称的后面。也有一些命令支持用方括号（square
brace）括起来的可选参数。</p>
<h3 id="注释">注释</h3>
<p>当 LATEX 在处理源文件时，如果遇到一个百分号字符 %，那么 LATEX将忽略 %
后的该行文本，分行符以及下一行开始的空白字符。这样，我们就可以在源文件中写一些注释，而不会担心他们会出现在最后的排版结果中。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">This is an % stupid</span><br><span class="line">% Better: instructive &lt;----</span><br><span class="line">example: Supercal%</span><br><span class="line">             ifragilist%</span><br><span class="line">      icexpialidocious</span><br></pre></td></tr></table></figure>
<p>得到</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">This is an example: Supercalifragilisticexpialidocious</span><br></pre></td></tr></table></figure>
<p>% 也可以用来分割不允许有空格或分行的较长输入文本。</p>
<h2 id="源文件的结构">源文件的结构</h2>
<p>LATEX 需要所处理的源文件遵从一定的结构，每个 LATEX
文档必须以如下的命令开始： <code>\documentclass&#123;...&#125;</code></p>
<p>这个命令指定了你所写的文档的类别。在此之后，你可以加入控制文档式
样的命令，或者使用命令 <code>\usepackage&#123;...&#125;</code>
来调入一些宏集，进而为 LATEX 系统增添 一些新的功能。</p>
<p>当完成所有的设置后，你可利用命令<code>\begin&#123;document&#125;</code>来开始你的文档.<code>\documentclass</code>
和 <code>\begin&#123;document&#125;</code> 之间的区域称作导言区。</p>
<p>现在你可以输入你所希望排版的文本和所使用的一些 LATEX
命令。在文档的最后键入命令<code>\end&#123;document&#125;</code>来告诉 LATEX
你的文档到此结束，从而使 LATEX忽略文档在此命令之后的部分。</p>
<h2 id="文档布局">文档布局</h2>
<h3 id="文档类">文档类</h3>
<p>当 LATEX
处理源文件时，首先需要知道的是作者所要创建的文档类型。该信息可以通过命令<code>\documentclass[options]&#123;class&#125;</code>来提供给
LATEX。例如，一个 LATEX 源文件以下面一行开始：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\documentclass[11pt,twoside,a4paper]&#123;article&#125;</span><br></pre></td></tr></table></figure>
<p><code>&#123;class&#125;</code>可以是： - article
排版科技期刊、短报告、程序文档、邀请函等。 - report
排版多章节的长报告、短篇的书籍、博士论文等。 - book 排版书籍。 - slides
排版幻灯片。其中使用了较大的 sans serif 字体。也可以考虑使用 FoilTEX
来得到相同的效果。</p>
<p><code>options</code>可以包含： - 10pt, 11pt, 12pt
设置文档所使用的字体的大小。如果没有声明任何选项，缺省将使用 10pt 字体。
- a4paper, letterpaper, . . .
定义纸张的大小，缺省的设置为letterpaper。此外，还可以使用a5paper，b5paper，executivepaper
和 legalpaper。 - fleqn 设置该选项将使数学公式左对齐，而不是中间对齐。 -
leqno 设置该选项将使数学公式的编号放置于左侧。 - titlepage, notitlepage
指定是否在文档标题（document title）后开始一新页。article
文档类缺省不开始新页，而 book 文档类则相反。 - onecolumn, twocolumn 指定
LATEX 以单列（one column）或双列（two column）方式排版文档。 - twoside,
oneside 指定 LATEX 排版的文档为双面或单面格式。article 和 report
缺省使用单面格式，而 book
则缺省使用双面格式。需要注意的是该选项仅作用于文档的式样。twoside选项不会通知你的打印机让以得到双面的打印输出。
- openright, openany
此选项决定新的章是仅仅在右边页（奇数页）还是在下一可用页开始。该选项对
article 文档类不起作用，因为该类中并没有定义“章”（Chapter）。report
类中新的一章开始于下一可用页，而 book 类中新的一章总是开始于右边页。</p>
<h3 id="宏包">宏包</h3>
<p>如果你想插入图形、彩色文本或源代码文件，你需要使用宏包来增强 LATEX
的功能。调入宏包使用如下的命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\usepackage[options]&#123;package&#125;</span><br></pre></td></tr></table></figure>
<p>这里 package 是宏包的名称，options
是用来触发宏包中的特殊功能的一组关键词。</p>
<h2 id="各类latex文件">各类LATEX文件</h2>
<ul>
<li>.tex LATEX 或 TEX 源文件。可以用 latex 处理。</li>
<li>.sty LATEX 宏包文件。可使用命令
将其加载到你的 LATEX 文件中。</li>
<li>.dtx 文档化 TEX 文件。这也是 LATEX 宏包发布的主要格式。通过处理一个
dtx 文件就可以得到该 LATEX 宏中所包括的宏代码文档。</li>
<li>.ins 为相应的 .dtx 文件的安装文件。如果你在网络上下载了一 LATEX
宏包，你通常会发现会有一个 .dtx 和一个 .ins 文件。使用 LATEX 对 .ins
文件进行处理，可以从 .dtx 文件中提取出宏包。</li>
</ul>
<p>当你运行 LATEX 处理你的源文件时，会得到下列文件：</p>
<ul>
<li>.dvi 与设备无关文件。这是 LATEX 编译运行的主要结果。你可以使用
DVI预览器浏览其内容，或者使用像 dvips 这样的应用程序输出到打印机。</li>
<li>.log 记录了上次编译运行时的详细信息。</li>
<li>.toc
存储了所有章节标题。该文件将在下次编译运行时被读入并生成目录。</li>
<li>.lof 类似 .toc 文件，可生成图形目录。</li>
<li>.lot 类似 .toc 文件，可生成表格目录。</li>
<li>.aux
另一个用来向下次编译运行传递信息的辅助文件。除了其它信息外，.aux
文件通常包含交叉引用信息。</li>
<li>.idx 如果你的文件中包含有索引，LATEX
使用此文件存储所有的索引词条。此文件需要使用 makeindex 处理。</li>
<li>.ind 经过处理后的 .idx
文件。可在下次编译运行时加入到你的文档中。</li>
<li>.ilg 运行 makeindex 时生成的记录文件。</li>
</ul>
<h3 id="页面式样">页面式样</h3>
<p>LATEX
支持三种预定的页眉、页脚（header/footer）格式，称为页面式样（page
styles）。命令 <code>\pagestyle&#123;style&#125;</code>
中的参数定义了所使用页面式样。</p>
<ul>
<li>plain 页眉为空，页脚由居中的的页码组成。这是默认的页面式样。</li>
<li>headings 页眉由当前的章节标题和页码组成，页脚为空。</li>
<li>empty 设置页眉、页脚均为空。</li>
</ul>
<p>可以使用下面的命令改变当前页的页面式样：
<code>\thispagestyle&#123;style&#125;</code></p>
<h2 id="大型文档">大型文档</h2>
<p>当处理大型文档时，最好将源文件分成几个部分。LATEX
有两条命令来处理这种情况。</p>
<p>在文档的正文中使用命令 <code>\include&#123;filename&#125;</code> 可将文件名为
<strong>filename.tex</strong> 的内容包括进来。注意 LATEX 在开始处理
<strong>filename.tex</strong> 的内容之前将会开始一新页。</p>
<p>第二个命令 <code>\includeonly&#123;filename,filename,. . . &#125;</code>
可用在文档的导言区，它允许你指导 LATEX 仅仅读入某些 <strong>*
文件。这条命令在导言区被 LATEX 读入执行后，在所有的 </strong>*
命令中，只有 <strong>*
命令参数中列出的文件才会被执行。</strong><em>注意在参数中，文件名和逗号之间不能有空格</em>**。</p>
<p><strong>* 命令在新页上排版包括进来的文本，这对于使用
</strong>*命令很有帮助。应为即使一些包括的文件被忽略，分页处也不会变更。如果不想在新页排版包括进来的文本，可使用下面的命令：<strong></strong>
该命令只是简单地将指定的文件包括进来，并没有其它限制。</p>
<p>使用 <em>syntonly</em> 宏包可以让 LATEX 快速的检查你的文档：LATEX
浏览你的文档，仅仅检查语法和所使用的命令是否正确，不会产生 DVI
输出。在这种模式下，LATEX
运行的非常快，可以节省可观的时间。使用方法非常简 单：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\usepackage&#123;syntonly&#125;</span><br><span class="line">\syntaxonly</span><br></pre></td></tr></table></figure>
<hr />
<h1 id="文档排版">文档排版</h1>
<h2 id="文档和语言的结构">文档和语言的结构</h2>
<p>在 LATEX
中段落是最重要的文档单位。我们之所以称之为“文档单位”，因为段落是反映一个连贯思想或观点的排版风格形式。在下面的章节中你将学习如何用
<code>\\</code>
强行断行，通过在源文件中留一空行强行转段。所以，<strong>如果开始一个新思想，就另起一段，否则，只应使用断行</strong>。如果还犹豫是否应转段，可以把文档想象为观点和思想的传递者。如果旧的思路还在继续，就不应转段。如果同一段中出现了全新的思路，就应该另起一段。</p>
<p>下一个较小的文档单位是句子。在英语文档中，在一个句子结尾处句号后的空间大于缩写词句号后的空间。LATEX
试图分辨出你需要那一个。如果 LATEX 分辨错了，你必须告诉 LATEX
你到底需要什么。</p>
<p>句子也有结构。大多数语言具有非常复杂的标点符号系统，但是在很多语言中（包括德语和英语）只要你记住它表示什么：语言流中的短暂停顿，你就能近乎完美地使用逗号。如果你不肯定在哪里使用逗号，就大声地朗读这个句子，在每个逗号处做一短呼吸。在什么地方如果你感到别扭，就删掉这个逗号；如果在什么地方，你感到必须呼吸（或做了短暂停顿）就插入一个逗号。</p>
最后，通过分成章、节、子节等形式，文档中的段落应该按逻辑在更高的层次进行组织。但是，使用
<p>的排版效果是如此明显，以致如何使用这些高水平的结构几乎是不证自明的。</p>
<h2 id="断行和分页">断行和分页</h2>
<h3 id="段落整理">段落整理</h3>
<p>通常书籍是用等长的行来排版的。为了优化整个段落的内容，LATEX
在单词之间插入必要的断行点（linebreak）和间隔。如果一行的单词排不下，LATEX
也会进行必要的断字。段落如何排版依赖于文档类别。通常，每一段的第一行有缩进，在两段之间没有额外的间隔。</p>
<p>在特殊情形下，有必要命令 LATEX 断行：</p>
<ul>
<li><code>\\</code> 或 <code>\newline</code>
另起一行，而不另起一段。</li>
<li><code>\\*</code> 在强行断行后，还禁止分页。</li>
<li><code>\newpage</code> 另起一新页。</li>
<li><code>\linebreak[n], \nolinebreak[n], \pagebreak[n] and \nopagebreak[n]</code>上述命令的效果可以从它们的名称看出来。通过可选参数
n，作者可以影响这些命令的效果。n 可以置为 0 和 4
之间的数。如果命令的效果看起来非常差，把 n 取为小于 4 的数，可以让 LATEX
选择忽略这个命令。不要这些“break” 命令与 “new” 命令混淆。即使你给出了
“break” 命令，LATEX
仍然试图对齐页面的右边界。如果你真想另起一行，就使用相应的命令。</li>
</ul>
<p>LATEX 总是尽可能产生最好的断行效果。如果断行无法达到 LATEX
的高标准，就让这一行在段落的右侧溢出。然后在处理输入文件的同时，报告溢出的消息（“overfull
hbox”）。这最可能发生在 LATEX 找不到合适的地方断字时候。你可以使用
<code>\sloppy</code> 命令，告诉 LATEX
降低一点儿标准。虽然最终的输出结果不是最优的，它通过增加单词之间的间隔，以防止出现过长的行。在这种情况下给出警告（“underfull
hbox”）。在大多数情况下得到的结果看起来不会非常好。<code>\fussy</code>
命令把 LATEX 恢复为缺省状态。</p>
<p>当发生（“overfull hbox”）时，虽然 LATEX
给出一个警告并显示溢出的那一行，但是不太容易发现溢出的行。如果你在
<strong>\documentclass</strong> 命令中使用选项 <em>draft</em>，LATEX
就在溢出行的右边标以粗黑线。</p>
<h3 id="断字">断字</h3>
<p>必要时就会出现断字。如果断字算法不能确定正确的断字点，可以使用如下命令告诉
TEX 如何弥补这个缺憾。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\hyphenation&#123;word list&#125;</span><br></pre></td></tr></table></figure>
<p>使列于参量中的单词仅在注有 “-”
的点断字。命令的参量仅由正常字母构成的单词，或由激活文本中视为正常字母的符号组成。应用于（特殊）语言的已存好，当断字命令出现时，就为激活的语言储存断字可选点。这意
味着如果你在文档导言中设置了断字命令，它将影响英文的断字。如果断字命令置于
\begin{document} 后面，而且你正使用类似 babel
的国际语言支持宏包，那么断字可选点在由 babel
激活的语言中就处于活动状态。</p>
<p>下面的例子允许对 “hyphenation” 和 “Hyphenation”
进行断字，却根本不允许 “FORTRAN”, “Fortran” 和 “fortran”
进行断字。在参量中不允许出现特殊的字符和符号。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\hyphenation&#123;FORTRAN Hy-phen-a-tion&#125;</span><br></pre></td></tr></table></figure>
<p>命令 <code>\-</code>
在单词中插入一个自主的断字点。它也就成为这个单词中允许出现的唯一断字点。对于包含特殊字符（注音字符）的单词，这个命令是特别有用的，因为对于包含特殊字符的单词
LATEX 不自动断字。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">I think this is: su\-per\-cal\-%</span><br><span class="line">i\-frag\-i\-lis\-tic\-ex\-pi\-%</span><br><span class="line">al\-i\-do\-cious</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">I think this is: supercalifragilisticexpialido-</span><br><span class="line">cious</span><br></pre></td></tr></table></figure>
<p>命令 <code>\mbox&#123;text&#125;</code>
保证把几个单词排在同一行上。在任何情况下，这个命令把它的参量排在一起（同一行上）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">My phone number will change soon.</span><br><span class="line">It will be \mbox&#123;0116 291 2319&#125;.</span><br><span class="line">The parameter</span><br><span class="line">\mbox&#123;\emph&#123;filename&#125;&#125; should</span><br><span class="line">contain the name of the file.</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">My phone number will change soon. It will</span><br><span class="line">be 0116 291 2319.</span><br><span class="line">The parameter *filename* should contain the</span><br><span class="line">name of the file.</span><br></pre></td></tr></table></figure>
<blockquote>
<p>上述两星号之间为斜体</p>
</blockquote>
<p>命令 和 类似，此外它还能围绕内容画一个框。</p>
<h2 id="特殊字符串和符号">特殊字符串和符号</h2>
<h3 id="引号">引号</h3>
<p>不要像在打字机上那样，把 " 用作引号。在 LATEX
中有专门的左引号和右引号。在 LATEX 中，用两个 ‘ 产生左引号，用两个 ’
产生右引号。一个 ‘ 和一个 ’ 产生一个单引号。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">‘‘Please press the ‘x’ key.’’</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">“Please press the ‘x’ key.”</span><br></pre></td></tr></table></figure>
<h3 id="破折号和连字号">破折号和连字号</h3>
<p>LATEX
中有四种短划标点符号。连续用不同数目的短划，可以得到其中的三种。第四个实际不是标点符号，它是数学中的减号：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">daughter-in-law, X-rated\\</span><br><span class="line">pages 13--67\\</span><br><span class="line">yes---or no? \\</span><br><span class="line">$0$, $1$ and $-1$</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">daughter-in-law, X-rated</span><br><span class="line">pages 13–67</span><br><span class="line">yes—or no?</span><br><span class="line">0, 1 and −1</span><br></pre></td></tr></table></figure>
<p>这些短划线的名称是: ‘-’ 连字号，‘--’ 短破折号，‘---’ 长破折号和 ‘−’
减号。</p>
<h3 id="波浪号">波浪号</h3>
<p>波浪号经常和网址用在一起。它在 LATEX 中，可用 ~ 产生，但其结果：˜
却不是你真正想要的。试一下这个：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http://www.rich.edu/\~&#123;&#125;bush \\</span><br><span class="line">http://www.clever.edu/$\sim$demo</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http://www.rich.edu/˜bush</span><br><span class="line">http://www.clever.edu/∼demo</span><br></pre></td></tr></table></figure>
<h3 id="度的符号">度的符号 (◦)</h3>
<p>在LATEX中如何排度的符号？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Its $-30\,^&#123;\circ&#125;\mathrm&#123;C&#125;$,</span><br><span class="line">I will soon start to</span><br><span class="line">super-conduct.</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Its −30 ◦C, I will soon start to super-conduct.</span><br></pre></td></tr></table></figure>
<h3 id="省略号">省略号</h3>
<p>在打字机上，逗号或句号占据的空间和其他字母相等。在书籍印刷中，这些字符仅占据一点儿空间，并且与前一个字母贴得非常紧。所以不能只键入三个点来输出‘省略号’，因为间隔划分得不对。我们使用专门的命令
<code>\ldots</code> 输出省略号。</p>
<h3 id="连字">连字</h3>
<p>一些字母组合不是简单键入一个个字母得到得的，而实际上用到了一些特殊符号。
在两个字母之间插入一个
，可以禁止连字。对于由两个词构成的单词，这可能是必要的。</p>
<h3 id="注音符号和特殊字符">注音符号和特殊字符</h3>
<p>LATEX 支持来自许多语言中的注音符号和特殊字符。在字母 i 和 j
上标一个注音符号，它的点儿必须去掉。这个可由 <code>\i</code> 和
<code>\j</code> 做到。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">H\^otel, na\&quot;\i ve, \’el\‘eve,\\</span><br><span class="line">sm\o rrebr\o d, !‘Se\~norita!,\\</span><br><span class="line">Sch\&quot;onbrunner Schlo\ss&#123;&#125;</span><br><span class="line">Stra\ss e</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Hˆotel, na¨ıve, ´el`eve,</span><br><span class="line">smørrebrød, ¡Se˜norita!,</span><br><span class="line">Sch¨onbrunner Schloß Straße</span><br></pre></td></tr></table></figure>
<blockquote>
<p>上述为注音符号</p>
</blockquote>
<h2 id="支持使用国际语言">支持使用国际语言</h2>
<p>略</p>
<h2 id="单词的间隔">单词的间隔</h2>
<p>为了使输出的右边界对齐，LATEX
在单词间插入不等的间隔。在句子的末尾插入的空间稍多一些，因为这使得文本更具可读性。<strong>LATEX
假定句子以句号、问号或惊叹号结尾</strong>。<strong>如果句号紧跟一个大写字母，它就不视为句子的结尾</strong>。因为一般在有缩写地方，才出现句号紧跟大写字母的情况。</p>
<p>作者必须详细说明，这些假设中的任何一个例外。空格前的反斜线符号产生一个不能伸长的空格。波浪字符
‘~’ 也产生一个不能伸长的空格，并且禁止断行。句号前的命令 @
说明这个句号是句子的末尾，即使它紧跟一个大写字母。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Mr.~Smith was happy to see her\\</span><br><span class="line">cf.~Fig.~5\\</span><br><span class="line">I like BASIC\@. What about you?</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Mr. Smith was happy to see her</span><br><span class="line">cf. Fig. 5</span><br><span class="line">I like BASIC. What about you?</span><br></pre></td></tr></table></figure>
<p>命令 <code>\frenchspacing</code> 能禁止在句号后插入额外的空间，它告诉
LATEX
在句号后不要插入比正常字母更多的空间。除了参考文献，这在非英语语言中非常普遍。如果使用了
<code>\frenchspacing</code>，命令 <code>\@</code> 就不必要了。</p>
<h2 id="标题章和节">标题，章和节</h2>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>LATEX</tag>
      </tags>
  </entry>
  <entry>
    <title>稀疏矩阵及其存储格式（COO、CSR、CSC）</title>
    <url>/Learning/Notes/Sparse-Matrix/</url>
    <content><![CDATA[<blockquote>
<p>在矩阵中，若数值为0的元素数目远远多于非0元素的数目，并且非0元素分布没有规律时，则称该矩阵为<strong>稀疏矩阵</strong>；与之相反，若非0元素数目占大多数时，则称该矩阵为稠密矩阵。定义非零元素的总数比上矩阵所有元素的总数为矩阵的稠密度。简单来说,<em>稀疏矩阵就是绝大部分都是0的矩阵,只包含很少的非零值</em>.</p>
</blockquote>
<p>封面 [ID:79498766].</p>
<span id="more"></span>
<h1 id="稀疏矩阵">稀疏矩阵</h1>
<p>例如：</p>
<p><span class="math display">\[
\begin{pmatrix}
    1 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 3 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 5 &amp; 6 &amp; 7 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 8 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 9 \\
\end{pmatrix}
\]</span></p>
<p>上述稀疏矩阵非零元素有9个，26个零值，稀疏性是74%。</p>
<p>稀疏矩阵因为绝大部分都是0元素,如果我们仍然按照普通方式存储,无疑会浪费很多空间;同时如果进行运算时,0元素对最终结果也没有帮助,增加了许多无效计算.
因此,我们需要设计出新的存储方式,或者说数据结构来存储稀疏矩阵.比较常见的有：</p>
<ul>
<li>DOK: Dictionary of keys. 将非零元素的坐标 <strong>(row,
column)</strong>
作为<strong>key</strong>,非零元素值作为<strong>value</strong>,只存储非零元素值.
可以以任意顺序逐渐构建稀疏矩阵;但是按某种顺序访问非零元素时比较困难.
通常用来构建矩阵,然后再把矩阵转换成别的方式.</li>
<li>COO: Coordinate list. 坐标格式.
三个数组<strong>row</strong>,<strong>col</strong>,<strong>value</strong>分别存储非零元素坐标的行,列以及非零值.
理论上稀疏矩阵中的元素在存储时顺序是任意的,但是为了方便元素访问,存储时先按照先左后右,先上后下顺序进行存储(left
to right, top to buttom).</li>
<li>CSR: Compressed Sparse Row. 压缩稀疏行</li>
<li>CSC: Compressed Sparse Column. 压缩稀疏列,和CSR类似.</li>
</ul>
<h1 id="coo">COO</h1>
<p>我们使用三个数组row,column和data分别用来存储非零元素坐标的row_index,col_index,以及数值.比如:</p>
<figure>
<img data-src="/images/body/Sparse-Matrix/COO.webp" alt="COO" />
<figcaption aria-hidden="true">COO</figcaption>
</figure>
<p>三个数组的长度都是NNO.data[i] (NNO:The number of
nonzero.矩阵非零元素个数),在原稀疏矩阵中的坐标为(row[i],col[i]]).</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; from scipy.sparse import *</span><br><span class="line">&gt;&gt;&gt; </span><br><span class="line">&gt;&gt;&gt; row = [0,0,1,1,2,2,2,3,3]</span><br><span class="line">&gt;&gt;&gt; col = [0,1,1,2,0,2,3,1,3]</span><br><span class="line">&gt;&gt;&gt; data = [1,7,2,8,5,3,9,6,4]</span><br><span class="line">&gt;&gt;&gt; import numpy as np</span><br><span class="line">&gt;&gt;&gt; coo = coo_matrix((data,(row,col)),shape=(4,4),dtype=np.int)</span><br><span class="line">&gt;&gt;&gt; coo</span><br><span class="line">&lt;4x4 sparse matrix of type &#x27;&lt;class &#x27;numpy.int64&#x27;&gt;&#x27;</span><br><span class="line">    with 9 stored elements in COOrdinate format&gt;</span><br><span class="line">&gt;&gt;&gt; coo.todense()</span><br><span class="line">matrix([[1, 7, 0, 0],</span><br><span class="line">        [0, 2, 8, 0],</span><br><span class="line">        [5, 0, 3, 9],</span><br><span class="line">        [0, 6, 0, 4]])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>可以发现,这种存储方式中,row数组和column数组中有一定的重复元素.我们是否可以针对这个冗余特性进一步进行压缩?
之后的CSR,CSC,分别是对row数组和column数组进行了压缩.</p>
<h1 id="csr与csc">CSR与CSC</h1>
<ul>
<li>V，用来存储矩阵中的非零元素的值；</li>
<li>COL_INDEX，第i个元素记录了V[i]元素的列数；</li>
<li>ROW_INDEX, 第i个元素记录了前i-1行包含的非零元素的数量。
进一步，令a=ROW_INDEX[row], b = ROW_INDEX[row+1]，则V[a,
b)的行数等于row，再结合COL_INDEX，即可得到非零元素的行数和列数。</li>
</ul>
<p><span class="math display">\[
\begin{pmatrix}
    1 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 3 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 5 &amp; 6 &amp; 7 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 8 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 9 \\
\end{pmatrix}
\]</span></p>
<p>其中 V = [1, 2, 3, 4, 5, 6, 7, 8, 9] COL_INDEX = [0, 1, 1, 2, 2, 3,
4, 5, 6] ROW_INDEX = [0, 2, 4, 7, 8, 9]</p>
<p>假如我们想得到“7”的坐标位置，通过V得到index为6，通过COL_INDEX得到列数为4；
4 ∈ [4,7) ，所以行数为2，最终7的坐标为(2, 4).</p>
<p><strong>CSC同理.</strong></p>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>Knowledage-Graphs</tag>
      </tags>
  </entry>
  <entry>
    <title>GraIL相关论文阅读笔记</title>
    <url>/Learning/Notes/Papers/GraIL/</url>
    <content><![CDATA[<p>论文 <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE5MTEuMDY5NjI=">Inductive relation
prediction by subgraph reasoning<i class="fa fa-external-link-alt"></i></span> 阅读笔记. 译文可见<a
href="https://pan.baidu.com/s/1IXtIZhYJFkEciqEPflWKuQ"
class="uri">https://pan.baidu.com/s/1IXtIZhYJFkEciqEPflWKuQ</a>，提取码<em>will</em>.</p>
<span id="more"></span>
<p>相关代码见<a
href="https://github.com/kkteru/grail">作者的GitHub</a>.</p>
<h1 id="背景">背景</h1>
<h2 id="现实背景">现实背景</h2>
<p>知识图谱（Knowledge
Graph，KG）是人工智能的重要分支技术，它在2012年由谷歌提出，是结构化的语义知识库，用于以符号形式描述物理世界中的概念及其相互关系，其基本组成单位是
<strong>“实体—关系—实体”（Facts： Head_Entity - Relation - Tail_Entity,
i.e., (h; r;
t)）三元组，以及实体及其相关属性—值对</strong>，实体间通过关系相互联结，构成网状的知识结构<a
href="#reference">1</a>。知识图谱本质上是一种叫作语义网络的知识库，即一个具有有向图结构的知识库，其中图的结点代表实体或者概念，而图的边代表实体/概念之间的各种语义关系<a
href="#reference">2</a>.</p>
<p>知识图谱的链接预测方法主要通过学习和操作实体和关系的潜在表示（即嵌入
embeddings）。然而这些基于嵌入的方法并没有明确地捕获知识图谱背后的组合逻辑规则，本质上假设图中的实体集是固定的——这种假设通常被称为直推式设置（Transductive
Setting），仅限于<em>直推式学习（Transductive
learning）</em>而不是<em>归纳式学习（Inductive
learning）</em>。因此我们使用了一个基于图神经网络的关系预测框架
<strong>GraIL</strong><a
href="#reference">3</a>，其对局部子图结构进行推理，并且具有很强的归纳能力来学习与实体无关的关系语义。与基于嵌入的模型不同，GraIL
是自身便具有归纳能力，可以在训练后泛化到无联通增量中。<a
href="#reference">3</a>提供了理论证明和强有力的经验证据，证明 GraIL
可以代表有用的一阶逻辑子集，还表明 GraIL
在归纳设置中优于现有的Baseline。<a
href="#reference">3</a>还展示了通过在直推式设置中将 GraIL
与各种知识图谱嵌入方法集成来获得的显著收益，突出了该方法的互补归纳倾向。</p>
<h2 id="在做什么">在做什么</h2>
<p>预测与另一个给定实体具有特定关系的实体，即<em>链接预测（Link
Prediction）</em>————给定头尾实体、关系三者中的任意两者，预测剩下那个，即<em>实体预测（Entity
Prediction）</em>或<em>实体排名（Entity Ranking）</em> <strong>（(?; r;
t)、(h; r; ?)）</strong> 和 <em>关系预测（Relation Prediction）</em>
<strong>（(h; ?; t)）</strong>。这本质上是
KG补全，即向图中添加缺失的知识（实体/关系），
通过事先学习的实体和关系表示，链接预测可以简单地通过排序过程来执行。例如预测任务(?;
r; t) 要预测头实体，可以将KG中的每个实体 h0 作为候选答案，计算得分fr(h0,
t)后进行排序。一旦在 KG
上训练了嵌入模型，就可以通过使用学习的嵌入和评分函数轻松实现这一点。</p>
<p>一种常见的做法是在有序列表中记录正确答案的排名，以便查看正确答案是否可以排在错误答案之前。例如预测
(?, DirectorOf, Psycho) 时，得到了有序列表[JamesCameron,
AlfredHitchcock, GeorgeLucas, QuentinTarantino]，正确答案
AlfredHitchcock 的排名为
2。排名越靠前表示性能越好。基于这些排名设计了各种评估指标，例如，<strong>mean
rank</strong>（预测排名的平均值）、<strong>mean reciprocal rank</strong>
（倒数排名的平均值）、<strong>Hits@n</strong>（排名不大于 n
的比例）、<strong>AUC-PR</strong>（精确召回曲线下的面积）。</p>
<h2 id="存在什么问题">存在什么问题</h2>
<p>对于直推式学习来说，链接预测如上所述般简单，但在许多情况下，我们通过引入与实体无关的逻辑规则来寻求具有归纳能力的算法。许多现实世界的知识图谱都在不断发展，随着时间的推移会添加新的节点或实体，例如电子商务平台上的新用户和产品或生物医学知识图谱中的新分子。面对无联通增量知识图谱进行链接预测，需要归纳式学习模型。训练无需昂贵的重新计算即可对这些新实体进行预测的能力的机器学习模型至关重要。尽管归纳式学习模型具有这一关键优势，但它们仍存在可扩展性问题，并且缺乏那些基于嵌入的方法的表达能力。</p>
<h2 id="使用的方法">使用的方法</h2>
<p>使用<em>图神经网络（GNN: Graph Neural Networks）框架</em>
<strong>GraIL（Graph Inductive Learning）</strong>，
其具有很强的归纳学习与实体无关的关系语义的能力。通过学习候选关系周围的子图结构来进行关系预测，学习对独立于任何特定节点身份的子图结构进行推理，能够自然地推广到无联通增量知识图谱中的节点。<a
href="#reference">3</a>提供了理论证明和强有力的经验证据。</p>
<p>除了 GraIL
框架，我们还为归纳关系预测问题引入了一系列<strong>benchmark
tasks</strong>。由于用于知识图谱补全的现有基准数据集是为直推式学习设置的，即它们确保测试集中的所有实体都在训练数据中。因此为了测试具有归纳式学习能力的模型，通过从不同的知识图谱数据集中采样子图来构建几个新的归纳式基准数据集。在这些新的基准数据集上的实验表明，GraIL
能够大大优于最先进的baseline，在 AUC-PR 和 Hits@10
方面，平均相对性能分别提高了 5.25% 和 6.75%。</p>
<p>最后，我们将 GraIL
与现有的基于嵌入的直推式学习模型进行比较。特别地，我们假设我们的方法具有与基于嵌入的方法互补的归纳偏差，并且研究了使用基于嵌入的方法集成
GraIL 后的能力。我们发现集成 GraIL 后性能显著提高。</p>
<h2 id="研究现状related-work">研究现状（Related Work）</h2>
<ul>
<li><p><strong>基于嵌入的模型</strong> 如前所述，大多数现有的 KG
补全方法都属于基于嵌入的范畴。 RotatE、ComplEx、ConvE 和 TransE
是为训练集中的每个节点训练浅嵌入的一些代表性方法，使得这些低维嵌入可以检索图的关系信息。GraIL
体现了另一种归纳倾向，明确地对结构规则进行编码。此外，虽然 GraIL
是自然归纳的，但在归纳式学习设置中采用嵌入方法进行预测，需要为新节点重新训练嵌入，代价很高。</p>
<p>与 GraIL 类似，R-GCN 模型也使用 GNN
来执行关系预测。尽管最初提出的这种方法本质上是直推式的，但如果给定一些节点特征，它便具有归纳的潜力。与
GraIL 不同的是，R-GCN 仍然需要学习特定于节点的嵌入，而 GraIL
将关系预测视为子图推理问题。</p></li>
<li><p><strong>归纳嵌入</strong>
无联通知识图谱的嵌入很有前景，尽管它们在某些方面受到限制。汉密尔顿等人和
Bojchevski &amp; Günnemann 依赖于许多 KG 中不存在的节点特征的存在。
(Wang et al., 2019) 和 (Hamaguchi et al., 2017) 通过使用 GNN
聚合相邻节点嵌入来学习为无联通增量知识图谱生成嵌入。然而，这两种方法都需要新节点被已知节点包围，且不能处理全新的图。</p></li>
<li><p><strong>规则归纳法</strong>
与基于嵌入的方法不同，统计规则挖掘方法通过枚举知识图中存在的统计规律和模式来诱导概率逻辑规则。这些方法本质上是归纳式学习，因为规则独立于节点。但这些方法存在可扩展性问题，并且由于它们基于规则的性质而缺乏表达能力。受这些统计规则归纳方法的启发，NeuralLP
模型使用 TensorLog 运算符以端到端的可微方式从 KG 中学习逻辑规则。基于
NeuralLP，Sadeghian 等人最近提出了
DRUM，它可以学习更准确的规则。这组方法构成了我们在归纳设置中的Baseline。</p></li>
<li><p><strong>使用 GNN 进行链接预测</strong> 在 KG 文献之外，Zhang
&amp; Chen (2018) 从理论上证明了 GNN
可以学习常见的图启发式方法，用于简单图中的链接预测。Zhang &amp; Chen
Inductive Relation Prediction by Subgraph Reasoning (2020) 提出了一种与
GraIL
非常相似的方法，并在归纳矩阵完成和迁移学习方面十分有效。虽然存在方法上的相似性，但
GraIL 的重点是多关系知识图与模型诱导逻辑规则的能力。</p></li>
<li><p><strong>逻辑推理和 GNN</strong>
最近的许多工作同时探索了逻辑推理和图神经网络的联系。 Barcel´o 等人
(2020) 提出了 GNN 的表达能力与一阶谓词逻辑子集 FOC2
之间的紧密联系，利用与 WL 同构测试的联系（Cai 等人，1992
年）。然而，他们的发现集中在简单的图表和一元逻辑公式上，而 GraIL
的结果通过在多关系图和二元逻辑公式的上下文中展示类似的连接来增强他们的发现。另一条并行工作将图神经网络与强大的概率推理引擎——马尔可夫逻辑网络（Markov
Logic Networks）相结合（Qu &amp; Tang，2019；Zhang
等人，2020）。这些方法侧重于使用一组给定的预定义规则对 KG
进行演绎和推理。事实上，张等人 (2020) 在其预处理步骤中使用
NeuralLP（我们的Baseline之一）来推导逻辑规则。GraIL
与他们的方法互补，因为其隐含地执行规则归纳以及演绎和推理。</p></li>
</ul>
<h1 id="嵌入方法">嵌入方法</h1>
<h2 id="传统世界嵌入">传统世界嵌入</h2>
<ul>
<li>距离转移方法：TransE (2013-NIPS)、TransH (2014-AAAI)、TransR
(2015-AAAI)</li>
<li>矩阵分解方法：RESCAL (ICML-2011)、DistMult (ICLR-2015)</li>
<li>传统神经网络方法：NTN (NIPS-2013)、MLP (SIGKDD-2014)</li>
<li>深度学习方法：ConvE (2018-AAAI)、ParamE (2020-AAAI)</li>
<li>图神经网络方法：R-GCN (2018-ESWC)、SACN (2019-AAAI)</li>
</ul>
<h2 id="开放世界嵌入">开放世界嵌入</h2>
<ul>
<li>附加信息：附加图片信息 IKRL (2016-IJCAI)、附加文本信息 DKRL
(2016-AAAI)</li>
<li>图神经网络：MEAN (2017-IJCAI)、LAN (2019-AAAI)、VN
Network（2020-CIKM)</li>
<li>规则推理：GraIL(2020-ICML)、TACT (2021-AAAI)</li>
<li>元学习：GEN (2020-NIPS)</li>
</ul>
<h1 id="做法">做法</h1>
<h2 id="baseline">baseline？</h2>
<h2 id="模型介绍">模型介绍</h2>
<p>GraIL
方法背后的关键思想是<strong>根据两个节点周围的子图结构来预测这两个节点之间的关系</strong>。其建立在图形神经网络(GNN)(Hamilton等人，2007a)(或神经消息传递(Gilmer等人，2017))形式主义基础上，不使用任何节点属性从而测试
GraIL 仅从结构学习和泛化的能力。由于 GraIL
只接受结构信息(即子图结构和结构节点特征)作为输入，因此学习知识图谱背后的结构语义是完成关系预测任务的唯一途径。总体任务是对三元组<span
class="math inline">\({u, r_t,
v}\)</span>进行评分，即预测KG中头节点u和尾节点v之间可能的关系rt的可能性，其中我们将节点u和v称为目标节点，并将rt称为目标关系。我们对这样的三元组进行评分的方法可以大致分为三个子任务：
- (I)提取目标节点周围的包围子图 - (II)标记提取的子图中的节点 -
(III)使用GNN对标记的子图进行评分</p>
<h2 id="模型算法">模型算法</h2>
<h3 id="子图提取">子图提取</h3>
<p>我们假设<em>KG中特定三元组的局部图邻域包含推导目标节点之间关系所需的逻辑证据</em>。特别地，我们假设连接两个目标节点的路径包含可能隐含目标关系的信息。因此，作为第一步，我们提取目标节点周围的封闭子图。我们将节点u和v之间的封闭子图定义为出现在u和v之间的路径上的所有节点所得到的图，它是两个目标节点相邻节点的交集。随后进行剪枝。即，设<span
class="math inline">\(N_k(u)\)</span>和<span
class="math inline">\(N_k(v)\)</span>是KG中两个目标节点的<a
href="https://support.huaweicloud.com/usermanual-ges/ges_01_0034.html">k跳（k-hop）</a>(无向)邻域中的节点集合。我们通过取这些k跳邻域集合的交集<span
class="math inline">\(N_k(u) ∩
N_k(v)\)</span>来得到封闭子图，然后<strong>修剪与任一目标节点独立或距离大于k的节点</strong>。由<em>Observation
1</em>知，这会得到在节点u和v之间的长度至多为k+1的路径上出现的所有节点。</p>
<ul>
<li><em>Observation
1：在任何给定图中，设两个不同节点x和y之间的长度为λ的路径上的节点构成集合Pxy(λ)。这样的路径v∈Pxy(λ)上的任何节点到x或y的最大距离是λ−1。</em></li>
</ul>
<p>注意，在提取封闭子图时，我们将其视为无向图。然而，在使用GNN传递消息时，我们考虑有向图，这将在后文提到。此外，我们将目标元组/边<span
class="math inline">\({u, r_t,
v}\)</span>添加到提取出的子图中来实现两个目标节点之间的消息传递。</p>
<h3 id="节点标记">节点标记</h3>
<p>GNN 需要将节点特征矩阵 <span class="math inline">\(X∈ R^{|V| ×
d_i}\)</span>
作为输入来初始化神经消息传递算法(Gilmer等人，2017年)。由于我们在输入KG中没有假设任何节点属性，因此我们遵循Zhang&amp;Chen(2018)，并将他们的<strong>双半径顶点标注方案</strong>扩展到我们的设置中。节点u和v周围的子图中的每个节点i用元组
<em>(d(i，u)，d(i，v))</em> 标记，其中 <em>d(i，u)</em>
表示节点i和u之间的不通过v的最短距离( <em>d(i，v)</em>
也是如此)。这将捕获每个节点相对于目标节点的拓扑位置，并反映其在子图中的结构角色。两个目标节点u和v被唯一地标记为(0，1)和(1，0)，以便模型可识别。因此，节点特征是
<strong>[One-Hot(d(i，u)) ⊕ One-Hot(d(i，v))]</strong>
，其中⊕表示两个向量的连接。注意，作为 <em>Observation 1</em>
的结果，以这种方式构建的节点特征的维度受提取封闭子图时所考虑的跳数的限制。</p>
<h3 id="gnn评分">GNN评分</h3>
<p>我们框架中的最后一步是给定G(u，v，rt)，使用GNN对元组<span
class="math inline">\({u, r_t,
v}\)</span>的可能性进行评分，其中G(u，v，rt)是目标节点周围提取和标记的子图。我们采用了Xu等人描述的
<em>通用消息传递方案</em>
(2019年)，其通过将节点表示与其相邻节点表示的聚集组合来迭代更新节点表示。特别地，我们GNN的第k层由下列公式给出</p>
<p><span class="math display">\[
a_t^k = AGGREGATE^k(\{h_s^{k-1}: s∈N(t)\}, h_t^{k-1})
\]</span></p>
<p><span class="math display">\[
h_t^k = COMBINE^k(h_t^{k-1}, a_t^k)
\]</span></p>
<p>其中<span
class="math inline">\(a_t^k\)</span>是来自相邻节点的聚合消息，<span
class="math inline">\(h_t^k\)</span> 表示第k层中节点t的潜在表示，<span
class="math inline">\(N(t)\)</span>表示节点t的直接相邻节点的集合。任何节点
<span class="math inline">\(i\)</span>，<span
class="math inline">\(h_i^0\)</span>
的初始潜在节点表示被初始化为步骤2中描述的<strong>双半径顶点标注方案</strong>构建的节点特征
<span
class="math inline">\(X_i\)</span>。该框架可以插入不同的AGGREGATE和COMBINE函数，从而拥有各种GNN架构。</p>
<p>受多关系R-GCN(Schlichtkrull等人，2017)和edge
attention的启发，我们将聚合函数定义为</p>
<p><span class="math display">\[
a^k_t = \sum_{r=1}^R\sum_{s∈N_r(t)}α^k_{rr_tst}W^k_rh^{k−1}_s
\]</span></p>
<p>其中，<span
class="math inline">\(R\)</span>是知识图中存在的关系的总数；<span
class="math inline">\(N_r(t)\)</span>表示关系r下节点t的直接传出邻节点集合；<span
class="math inline">\(W^k_r\)</span>是用于在关系r上的第k层中传播消息的变换矩阵；<span
class="math inline">\(α^k_{rr_tst}\)</span>是对应于经由关系r连接节点s和t的边的第k层的边attention权重。该attention权重是源节点t、邻节点s、边类型r和要预测的目标关系<span
class="math inline">\(r_t\)</span>的函数，定义为</p>
<p><span class="math display">\[
s=ReLU(A^k_1[h^{k-1}_s ⊕ h^{k-1}_t ⊕ e^a_r ⊕ e^a_{r_t}]+b^k_1)
\]</span></p>
<p><span class="math display">\[
α^k_{rr_tst}=σ(A^k_2s+b^k_2)
\]</span></p>
<p>这里，<span class="math inline">\(h^k_s\)</span>和<span
class="math inline">\(h^k_t\)</span>表示GNN的第k层的各个节点的潜在节点表示，<span
class="math inline">\(e^a_r\)</span>和<span
class="math inline">\(e^a_{r_t}\)</span>表示各个关系的学习注意嵌入。注意，attention权重并不是标准化的，而是来自一个Sigmoid门，该门控制着从每个相邻节点那里聚集来的信息。我们采用了Schlichtkrull等人(Schlichtkrull等人，2017)提出的<em>基共享机制</em>来正则化，，在每层的变换矩阵<span
class="math inline">\(W^k_r\)</span>中。我们还实现了一种<em>边丢弃</em>的方法，将边从图中随机丢弃，同时聚合来自相邻节点的信息。</p>
<p>有最好效果的COMBINE函数也是由R-GCN架构派生而来的。</p>
<p><span class="math display">\[
h^k_t=ReLU(W^k_{self}h^{k-1}_t+a^k_t)
\]</span></p>
<p>使用上述GNN体系结构，我们在L层消息传递之后获得节点表示。<span
class="math inline">\(G(u，v，r_t)\)</span>的子图表示是通过对所有潜在节点表示进行平均池化（average-
pooling）得到的：</p>
<p><span class="math display">\[
h^L_{G(u, v r_t)}=\frac{1}{V}\sum_{i∈V}h^L_i
\]</span></p>
<p>其中V表示<span
class="math inline">\(G(u，v，r_t)\)</span>的顶点集。</p>
<p>最后，为了获得三元组<span class="math inline">\({u, r_t,
v}\)</span>的可能性得分，我们串联四个向量：子图表示 (<span
class="math inline">\(h^L_{G(u, v r_t)}\)</span>)、目标节点的潜在表示
(<span class="math inline">\(h^L_u\)</span> 和 <span
class="math inline">\(h^L_v\)</span>)以及已学习的目标关系的嵌入 (<span
class="math inline">\(e_{r_t}\)</span>)，并通过线性层传递这些连接表示：</p>
<p><span class="math display">\[
score(u, r_t, v) = W^T[h^L_{G(u, v, r_t)} ⊕ h^L_u ⊕ h^L_v ⊕ e_{r_t} ]
\]</span></p>
<p>在我们的最佳性能模型中，除了使用最后一层的节点表示外，我们还使用间歇层的表示。这是受Xu等人介绍的<em>JK-Connection机制</em>的启发(2018)，为每个节点提供灵活的邻域范围。这种JK连接的加入使得我们的模型的性能对于GNN的层数是稳健的。</p>
<h2 id="训练制度">训练制度</h2>
<p>根据标准和成功的实践，我们使用噪声对比铰链损失训练模型以使正三元组得分高于负三元组（Bordes
et al.,
2013）。更准确地说，对于训练图中存在的每个三元组，我们通过用均匀采样的随机实体替换三元组的头部（或尾部）来获得一个负三元组。
然后我们使用以下损失函数通过随机梯度下降训练我们的模型：</p>
<p><span class="math display">\[
L = \sum^{|E|}_{i=1}max(0, score(n_i) − score(p_i) + γ)
\]</span></p>
<p>其中 <span class="math inline">\(E\)</span>
是训练图中所有边/三元组的集合；<span class="math inline">\(p_i\)</span>
和 <span class="math inline">\(n_i\)</span> 分别表示正负三元组；γ
是边距超参数。</p>
<h2 id="理论分析">理论分析</h2>
<p>我们可以证明，GraIL
架构能够编码流行规则归纳模型中使用的同一类基于路径的逻辑规则，如 RuleN和
NeuralLP以及在最近使用神经网络进行逻辑推理的工作的研究。为了便于说明，我们将知识图谱中的边
(u, r, v) 等同于二元逻辑谓词 r(u, v)，其中边 (u, r, v)
存在于图中当且仅当r(u,v) = true。 定理 1. 令 R
为以下形式的二元谓词上的任何逻辑规则（即子句）：</p>
<p><span class="math display">\[
r_t (X,Y)← r_1 (X,Z_1 )∧ r_2 (Z_1,Z_2 )∧ …∧ r_k (Z_(k-1),Y )
\]</span></p>
<p>其中rt, r1, ..., rk是知识图谱中的（不一定是唯一的）关系，X, Z1, ...,
Zk, Y 是可以被任意唯一实体绑定的自由变量。对于任何这样的
R，都存在一个参数设置为Θ的 GraIL
模型，其具有k个GNN层，且所有潜在嵌入的维度为d = 1，使得<span
class="math inline">\(score(u,r_t,v)≠0\)</span>,当且仅当∃Z1,…,
Zk，使R的主体满足X = u和Y = v。</p>
<p>定理 1
指出，知识图中路径对应的任何逻辑规则都可以被模型编码。GraIL将输出一个非零值当且仅当此逻辑规则的主体基于一组特定的查询实体
X = u 和 Y = v 时。定理 1
的完整证明在附录中有详细说明，其关键思想如下：可以使用边注意力权重设置模型参数，使得节点的隐藏嵌入在一轮消息传递后非零（即h_s^i≠0）当且仅当节点
s 通过关系 ri
有至少一个邻节点。换句话说，边缘注意机制允许模型指示特定关系是否与特定实体相关，并且——因为我们已经唯一标记了目标节点
u 和 v——我们可以使用这种关系指示属性来检测是否存在节点 u 和 v
之间的特定路径。 我们可以直接对定理 1进行扩展得到显示以下推论：</p>
<p><strong>推论 1.</strong> 令 R1,…, Rm 是一组与定理 1
中有着相同结构的逻辑规则，每个规则具有相同的头部rt(X, Y )。令</p>
<p><span class="math display">\[
β = |{R_i ∶∃Z_1,…,Z_k  where R_i=true with X = u and Y = v}|.
\]</span></p>
<p>那么便存在一个与定理1相同假设的GraIL模型的参数设置，为</p>
<p><span class="math display">\[
score(u,r_t,v)∝β
\]</span></p>
<p>这个推论表明，给定一组暗示相同目标关系的逻辑规则，GraIL
可以计算对于特定的查询实体u和
v，这些规则有多少是满足的。换句话说，类似于规则归纳模型，如RuleN，GraIL
可以结合来自多个规则的证据来进行预测。</p>
<p>有趣的是，定理 1 和推论 1 表明 GraIL
可以仅使用实体和关系的一维嵌入来学习逻辑规则，这与我们的经验相吻合，即
GraIL 的性能在维度d = 1, ..., 64
范围内相当稳定。但是，上述分析只对应于固定类别的逻辑规则，我们期望GraIL可以受益于更大的潜在维度来学习不同种类的逻辑规则以及这些规则之间更复杂的组合。</p>
<h2 id="复杂度分析">复杂度分析</h2>
<p>与传统的基于嵌入的方法不同，GraIL
模型中的推理需要提取和处理候选边（u、rt、v）周围的子图，并在该提取的子图上运行
GNN。鉴于我们的处理需要评估提取的子图中从目标节点到所有其他节点的最短路径，我们认为
GraIL 对候选边 (u, rt, v) 进行评分的推理时间复杂度为</p>
<p><span class="math display">\[
O(log(V)E + Rdk)
\]</span></p>
<p>其中 V、R 和 E 分别是由u和v导出的封闭子图中的节点、关系和边的数量。d
是节点/关系嵌入的维度。
因此GraIL推理的成本很大程度上取决于提取的子图大小，实际的运行时间一般由在这些子图上运行Dijkstra算法来决定。</p>
<h1 id="模型实验">模型实验</h1>
<p><strong><em>该章节的所有图表请见原文或我的译文</em></strong></p>
<p>我们在三个基准知识完成数据集上进行实验：WN18RR、FB15k-237和
NELL-995（以及其他由他们衍生而来的数据集）。我们的实证研究主要关注以下问题：</p>
<ol type="1">
<li>归纳式关系预测。通过定理 1，我们知道 GraIL
可以编码归纳式逻辑规则。与在归纳式设置中明确进行规则归纳的现有统计和可微方法相比，它的表现如何？</li>
<li>直推式关系预测。我们的方法具有很强的结构归纳偏差，我们假设它是对现有最先进的知识图嵌入方法的补充。这种互补的归纳偏置能否对传统直推式设置中现有的最先进的知识图谱嵌入方法进行任何改进？</li>
<li>灵敏度分析。我们提出的框架的各个组成部分有多重要？比如，定理 1
依赖于注意力和节点标记方案的使用，但这些模型方面在实践中有多重要？</li>
</ol>
<p>所有提及的实验代码与数据都在：https://github.com/kkteru/grail。</p>
<h2 id="归纳式关系预测">归纳式关系预测</h2>
<p>如图 1c
所示，归纳式设置评估模型泛化到新实体的能力。完全归纳式的设置中，在训练和测试期间看到的实体集是没有交集的。更一般地，新实体的数量范围可以从仅引入几个新实体到完全的归纳设置（图
1c）。只要关系的底层语义（即知识图的模式）保持不变，GraIL
得到的节点特性是不变的。我们展示了我们的归纳结果在非常极端的情况下：一个带有新的实体集的全新的测试图。</p>
<p><strong>数据集。</strong>WN18RR、FB15k-237 和 NELL-995
基准数据集最初是为直推式设置开发的。换句话说，标准测试拆分的实体是训练拆分中实体的子集（图
1b）。为了促进归纳测试，我们通过从这些数据集中采样不相交的子图来创建新的全归纳基准数据集。特别地，我们的每个数据集都由一对图组成：train-graph
和 ind-test-graph。这两个图(i)具有完全不相交的实体集，并且(ii)
train-graph包含ind-test-graph中存在的所有关系。生成该数据集的过程在附录中有详细说明。为了进行稳健的评估，我们采样了四对不同的train-graph和ind-test-graph，其中每对基准知识图的节点和边数都在增加。在附录的表中给出了这些归纳基准的统计数据。在归纳式设置中，模型在
train-graph 上进行训练并在 ind-test-graph 上进行测试。我们随机选择
ind-test-graph 中10%的边/元组作为测试边。</p>
<p><strong>Baseline和实施细节。</strong>我们将 GraIL
与其他两种端到端可微分方法NeuralLP17和
DRUM19进行了比较。据我们所知，这些是唯一能够进行归纳关系预测的可微方法。我们使用作者公开提供的最佳配置实现。我们还与最先进的统计规则归纳方法
RuleN15进行了比较，该方法在直推式设置表现得比与其他基于嵌入的方法更好。
RuleN 代表了KG上归纳关系预测的当前最先进技术。它显式地提取了等式 (1)
中所示的那种基于路径的规则。我们使用 RuleN 的原始术语来训练它学习长度为
4 的规则。通过Observation 1，这对应于目标节点周围的 3
跳邻域。为公平起见，我们在 GNN 方法的目标链接周围采样 3
跳封闭子图。我们使用了一个 3 层 GNN，所有潜在嵌入的维度都等于
32，基础维度设置为 4，边缘丢失率设置为 0.5。在我们的实验中，GraIL
对超参数相对稳健，并且在各种设置下都具有稳定的性能。更多的超参数选择在附录中有详细说明。</p>
<p><strong>结果。</strong>我们在分类和排名指标上评估模型，即分别在精确召回曲线
(AUC-PR) 下的面积和 Hits@10。为了计算
AUC-PR，连同测试集中存在的三元组，我们使用随机实体替换头部（或尾部）的标准做法对相同数量的负三元组进行评分。由于第
3.4 节中描述的推理复杂性，我们通过在 50
个其他随机采样的负三元组中对每个测试三元组进行排名来近似 Hits@10。在表 1
和表 2 中，我们分别列出了 5 次运行的平均 AUC-PR 和 Hits@10。
（所有设置中的方差都非常低，因此这些表中省略了标准误差。）</p>
<p>正如我们所见，GraIL
在两个指标中的所有数据集上都显著优于归纳基线。仔细观察，之前的可微分方法（Neural-LP
和 DRUM）的性能明显比 GraIL 差。此外，如图 3 所示，GraIL
的强结构归纳偏置使其能够以数量级更少的参数数量实现极高的参数效率。GraIL
还始终优于统计规则归纳方法 RuleN，这表明 GraIL
不仅能够学习基于路径的逻辑规则，而且 GraIL
还能够利用更复杂的结构模式并有效地组合多个规则（推论
1）。为了完整起见，我们还在附录中列出了这些生成的数据集的直推式性能。请注意，与直推式设置相比，归纳式性能（在所有数据集和模型中）相对低于转导性能，这体现了归纳关系预测任务的难度。</p>
<h2 id="直推式关系预测">直推式关系预测</h2>
<p>正如之前所展示的，GraIL
具有很强的归纳偏差来编码知识图谱背后的逻辑规则和复杂的结构模式。我们相信，这与当前最先进的直推式知识图谱补全方法相辅相成，后者依赖于基于嵌入的方法。基于这一观察，在本节中，我们将探讨（i）GraIL
在直推式设置中的表现以及（ii）将 GraIL
与现有的基于嵌入的方法集成的效益。由于相较基于嵌入的方法，GraIL拥有很强的互补归纳偏差，我们预计通过将其与现有的基于嵌入的方法集成可以获得显着的收益。</p>
<p>我们的主要集成策略是后期融合，即集成各组成方法的输出分数。我们使用要集成的方法对每个测试三元组进行评分，每种方法输出的分数形成了每个测试点的特征向量。该特征向量被输入到一个线性分类器中，将该分类器训练得能够使正三元组得分高于负三元组。我们使用验证集训练这个线性分类器。</p>
<p><strong>数据集。</strong>我们使用标准的 WN18RR、FB15k-237 和 NELL-995
基准。对于 WN18RR 和 FB15k-237，我们使用文献中可用的拆分。对于
NELL-995，我们以 70/15/15
的比例将整个数据集拆分为训练集/验证集/测试集，确保拆分出的验证集和测试集中所有实体和关系在训练集中至少出现一次。</p>
<p><strong>Baseline和实施细节。</strong>我们将 GraIL 与
TransE、DistMult、ComplEx和
RotatE中的每一个进行了集成，它们构成了一组代表性的KGE方法。对于所有方法，我们使用5提供的实现和超参数，其给出了所有方法的最新结果。为了公平比较所有方法，我们禁用了5提出的自我对抗负采样。对于
GraIL，我们对 WN18RR 和 NELL-995 使用2跳邻域子图，对
FB15k-237使用1跳邻域子图。其他所有超参数与归纳式设置中的相同。</p>
<p><strong>结果。</strong>表3、4、5展示了不同KGE方法之间以及与 GraIL
的成对集成的AUC-PR性能。这些表中的一个特定条目对应于由行和列标签表示的一对方法的集合，每个方法的单独性能在对角线上。从这些表的最后一列可以看出，在这三个数据集的其中两个，使用GraIL集成可以在所有直推式方法中获得一致的性能提升。此外，使用
GraIL
进行集成比使用其他任何两种方法获得更多收益。更精确地，我们定义了通过集成两种方法获得的增益，G(M1,
M2)，如下</p>
<p><span class="math display">\[
G(M_1,M_2 )=\frac{P(M_1,M_2 )-max⁡(P(M_1 ),P(M_2))}{max⁡(P(M_1 ),P(M_2 )}
\]</span></p>
<p>换句话说，它实现的百分比改进是相较于两种方法中最好的。因此，通过使用GraIL集成获得的平均增益由下式给出</p>
<p><span class="math display">\[
G_{avg}^{GraIL}=\frac{1}{4} \sum_{|M_1 |∈KGE}G(M_1,GraIL)
\]</span></p>
<p>通过KGE方法之间的成对集成获得的平均增益由下式给出，</p>
<p><span class="math display">\[
G_{avg}^{GraIL}=\frac{1}{12}\sum_{(|M_1 |,|M_2 |)∈KGE}G(M_1,M_2 )
\]</span></p>
<p>GraIL 在 WN18RR 和 NELL-995 上获得的平均增益分别为 1.5% 和
0.62%。这比 KGE 集成获得的平均增益好几个数量级：0.007% 和
0.08%。令人惊讶的是，没有一个集成获得FB15k-237的显着收益。因此，虽然
GraIL
本身针对归纳式设置进行了优化，而不是最先进的直推式预测，但它确实通过集成对最先进的直推式方法进行了有意义的改进。</p>
<p>表 6 显示了当节点特征（由我们的原始节点标记方案计算）与 TransE
模型学习的节点嵌入连接时GraIL
的性能。添加这些预训练嵌入可以显着提升性能。因此，虽然后期融合展示了
GraIL 所体现的互补归纳偏差，但这种早期融合展示了 GraIL
利用任何可用节点嵌入/节点特征的自然能力。可以在附录中看到，所有
Hits@10的结果均呈现相似的趋势。</p>
<h2 id="灵敏度分析">灵敏度分析</h2>
<p>在本节中，我们强调 GraIL
的三个关键组件的重要性：i）封闭子图提取，ii）双半径节点标记方案，以及
iii）GNN 中的注意力机制，结果总结在表 7 中。</p>
<p>封闭子图提取。如前所述，我们假设特定链接的逻辑证据可以在链接的两个目标节点周围的子图中找到。因此，我们建议提取由两个目标节点之间的路径上出现的所有节点诱导的子图。在这里，我们想强调仅提取路径，而不是天真地提取由目标节点的所有k-hop邻接点得到的子图的重要性。在这种配置下，性能急剧下降。事实上，该模型严重地过度拟合训练数据，训练AUC超过
99%。该模式适用于所有数据集。</p>
<p>双半径节点标记。定理 1
的证明假设了目标节点u和v具有唯一的标记。我们通过使用 (1, 1)
的恒定节点标签而不是最初提出的节点标签方案来评估 GraIL
，结果的性能下降证实了我们的节点标记方案的重要性。</p>
<p>GNN中的注意力机制。正如定理 1
的证明中所指出的，注意机制是我们模型编码路径规则时的重要组成部分。我们在没有注意机制的情况下评估GraIL并注意到性能明显下降，这与我们的理论发现相呼应。</p>
<h1 id="总结">总结</h1>
<p>我们提出了一个基于 GNN 的框架
GraIL，用于归纳式知识图推理。与基于嵌入的方法不同，GraIL
模型能够预测在训练期间没有的节点之间的关系，并在这种归纳式设置中实现最先进的结果。此外，我们展示了
GraIL
带来了与当前最先进的知识图谱补全方法之间互补的归纳偏差。特别是，我们通过一组完整的实验证明了与
GraIL
集成时各种知识图谱嵌入方法的性能提升。此外，我们还从理论上了解了关于GNN在编码有用的逻辑规则子集方面的表达能力。</p>
<p>这项工作通过一组新的基准数据集与对现有归纳关系预测方法的全面研究，为知识图谱背景下的归纳式推理探索开辟了一个新方向。例如，进一步探索的明显方向包括从
GraIL
中提取可解释的规则和结构模式，分析关系分布的变化如何影响归纳性能，以及将
GraIL 与元学习策略相结合来处理小样本学习设置。</p>
<h1 id="致谢">致谢</h1>
<p>这项研究的部分资金来自微软研究院的学术资助，以及由 Mila - Quebec AI
研究所的 Hamilton 教授担任的Canada CIFAR AI 主席。此外，IVADO
通过本科生研究奖学金为 Etienne 提供支持。</p>
<h1 id="reference">Reference</h1>
<p>[1] 刘峤, 等.知识图谱构建技术综述[J]. 计算机研究与发展, 2016, 53
(3):582-600. [2] 漆桂林, 高桓, 吴天星. 知识图谱研究进展[J]. 情报工程,
2017, 3(1): 4-25 [3] Teru, Komal K. Inductive Relation Prediction by
Subgraph Reasoning, ProQuest Dissertations Publishing, 2020.</p>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>Knowledage-Graphs</tag>
        <tag>GraIL</tag>
      </tags>
  </entry>
  <entry>
    <title>宝可梦六代实机乱数（破解机插件辅助 &amp; 不包含蛋）</title>
    <url>/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen6/</url>
    <content><![CDATA[<p>本文内容不涉及3ds/2ds系列的破解过程，本篇内容均建立在读者已经将3ds/2ds系列破解了的基础上.</p>
<p>同时本文使用的是<strong>正版卡带 +
辅助插件</strong>，相应盗版软件无法正常操作.</p>
<p>封面 [ID:50105089].</p>
<span id="more"></span>
<p><strong>注意，本教程仅支持宝可梦六代正作游戏：</strong></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Version</th>
<th style="text-align: center;">X</th>
<th style="text-align: center;">Y</th>
<th style="text-align: center;">欧米伽红宝石</th>
<th style="text-align: center;">阿尔法蓝宝石</th>
<th style="text-align: center;">其他</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Support</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✘</td>
</tr>
</tbody>
</table>
<p>本篇搬运+修改自<strong>無論</strong>的原博客：<a
href="https://wulun0102.github.io/2021-08-21/%E5%8F%A3%E8%A2%8B%E5%A6%96%E6%80%AA%E7%AC%AC%E5%85%AD%E4%B8%96%E4%BB%A3-ORAS%E4%B9%B1%E6%95%B0%E8%AE%B0%E5%BD%95/">口袋妖怪第六世代-ORAS乱数记录</a>.</p>
<p>授权图： <img
src="/images/body/Pokemon-RNG-Abuse-Gen6/Authorization.jpg"
alt="Authorization" /></p>
<h1 id="前言">前言</h1>
<p>本文仅写出了自己在使用插件过程中遇到的BUG，如果有其他小伙伴出现了其他问题，可以跳转到参考网址中相关插件的发布网址寻求答案.
关于原始 <strong>（非破解）</strong> 的Seed确定方法我找到了一篇文章：<a
href="https://sina-poke.hatenablog.com/entry/2017/05/06/000557">第六世代固定シンボル乱数調整のやり方
- かけらの記録ノート</a>. 总的来说非常繁琐，值得尝试但不建议推广.
参考文章中也有说到六代的乱数麻烦在哪里，在这里就不再赘述了.</p>
<p>成果展示：<a
href="https://www.bilibili.com/video/BV13v411N74t?spm_id_from=333.999.0.0">無論的b站视频</a></p>
<blockquote>
<p>如果你在找 3DS 系列的破解教程，请参考 <a
href="https://stray-soul.com/index.php/3dshack-getstarted">3DS/2DS破解-开始
-一只火狐的杂物间</a> 或者 <a
href="https://3ds.hacks.guide/">这里</a>.</p>
</blockquote>
<h1 id="辅助插件准备及使用">辅助插件准备及使用</h1>
<blockquote>
<p><strong>PCalc</strong> 和 <strong>pokeCalcNTR</strong> 是一个东西.
对于 alc 我只搜到了 <em>ALC MAXScript</em>（以下称为<em>ALC</em>）</p>
</blockquote>
<p>安装一个插件（PCalc）来辅助您的Pokemon游戏，以下内容将引导您如何让插件正常运行.
<strong>pokeCalcNTR for Gen 6 - v0.3.0</strong></p>
<h2 id="所需工具">所需工具：</h2>
<ul>
<li>一台有CFW（Custom Firmware）的3DS系列掌机（即俗称破解3DS）</li>
<li><a
href="https://github.com/wwwwwwzx/3DSRNGTool/releases">3DSRNGTool</a></li>
<li>PCalc for Gen 6
<ul>
<li><a
href="https://pokemonrng.com/downloads/pcalc/pcalc-oras.zip">PCalc-oras</a></li>
<li><a
href="https://pokemonrng.com/downloads/pcalc/pcalc-xy.zip">PCalc-xy</a></li>
</ul></li>
</ul>
<h2 id="step-1安装-ntr">Step 1：安装 NTR</h2>
<p>通过安装一种引导器（BootNTR Selector）来完成安装 NTR.</p>
<ul>
<li>N3DS and N2DSXL: Download and install BootNTR Selector.
<ul>
<li>Download either of the CIAs that are not Mode 3. (Difference is
Banner when loading BootNTR Selector, so you can choose either one.)
Then copy CIA to SD card and install using FBI. &gt; Note：
如果使用FBI安装CIA，请在控制台启动FBI然后导航到目标CIA文件，然后按<strong>A键</strong>安装</li>
</ul></li>
</ul>
<p>启动引导NTR选择器并选择修改默认设置 -
版本3.6（替换3.4和3.5）是唯一适用于插件的版本，因此每次启动 NTR
时都会选择该版本 - <strong>针对 O3DS 和 O2DS</strong>：请在<a
href="https://www.pokemonrng.com/misc-3ds-installing-pcalc">How to
Install PCalc</a>中寻找，但是ORAS对O3DS并不支持.</p>
<h2 id="故障排除">故障排除：</h2>
<ul>
<li><p>（主要是3DS固件版本过高和Luma的问题？）</p></li>
<li><p>BootNTR Selector 下最高版本的没有问题（需要）</p></li>
<li><p>我用的是 <strong>Luma3ds 10.2.1</strong> 与 <strong>3DS 11.14.0
固件</strong></p></li>
<li><p><a
href="https://support.sudomemo.net/info-about-2ds-3ds-system-version-11-14/">Important
Information about 2DS/3DS System Version 11.14</a></p>
<ul>
<li>这个里面导致NTR安装失败出问题的是<strong>boot.firm</strong></li>
<li>我不知道网上在哪里找了一个做替换，然后就成了</li>
<li>最后升级游戏时升级3DS固件版本到11.15现在也没啥问题</li>
</ul></li>
<li><p>在下面贴出当时使用的 <strong>Luma10.2.1原文件</strong> 和
<strong>现在使用的文件</strong></p>
<ul>
<li><a
href="https://pan.baidu.com/s/1Yjeuk1-qx2sC1cFhxXR57w">Luma10.2.1原文件</a>
可以用来升级Luma什么的</li>
<li><a
href="https://pan.baidu.com/share/init?surl=l0SK4vuE5qv_dcetW3tuaQ">现在使用的文件</a>
请提取对应的 <strong>boot.firm</strong> 文件</li>
<li>提取密码都是：<strong>0102</strong></li>
</ul></li>
</ul>
<blockquote>
<p>更新 Luma 可以参考<a
href="https://stray-soul.com/index.php/updateluma10-2">更新Luma10.2.1
-一只火狐的杂物间</a></p>
</blockquote>
<h2 id="step-2下载-pcalc-文件">Step 2：下载 PCalc 文件</h2>
<p>第二步是下载 PCalc
插件（其他版本的插件可以找下面参考网址中的帖子去下载）</p>
<p><a
href="https://pokemonrng.com/downloads/pcalc/pcalc-oras.zip">OR/AS</a>
<span class="exturl" data-url="aHR0cHM6Ly9wb2tlbW9ucm5nLmNvbS9kb3dubG9hZHMvcGNhbGMvcGNhbGMteHkuemlw">X/Y<i class="fa fa-external-link-alt"></i></span> <a
href="https://pokemonrng.com/downloads/pcalc/pcalc-tport.zip">Transporter</a></p>
<ol type="1">
<li>下载 <code>.zip</code> 文件，以获得对应的版本并解压内容.</li>
<li>将插件文件夹从 <code>.zip</code> 移动到SD卡的根部.
如果出现提示，选择合并并覆盖内容.</li>
<li>在SD卡上的<code>root部分</code>应有文件夹，并且应有 2/4/6/8
个文件夹（这取决于您下载并安装的 PCCALCS）. 并且每个文件夹内应有
<code>.Plugin</code> <code>cheat.plg</code> 的文件组成</li>
</ol>
<h2 id="step-3启动-pcalc">Step 3：启动 PCalc</h2>
<p>启动NTR选择器，然后应用您的选择 <code>NTR 3.6</code>.
屏幕会闪烁一下蓝色，当你启动游戏的时候如果屏幕闪烁绿色，恭喜你做到了！</p>
<blockquote>
<p>Note: PCalc Menu can be opened by pressing X+Up on D-pad. NTR Menu
can be opened by pressing X+Y. Useful for taking screenshots for proofs,
all screenshots are saved to root of SD card as .bmp files.</p>
</blockquote>
<h1 id="游戏更新及插件启动故障排除">游戏更新及插件启动故障排除</h1>
<h2 id="ds固件版本故障排除">3DS固件版本故障排除</h2>
<p>如果您更新到 11.6，NTR 无法工作，请确保您拥有最新的 BootNTR
选择器和/或引导选择器模式 3. &gt; 您可以在启动X时通过按住X轻松更新.</p>
<h2 id="游戏版本故障排除">游戏版本故障排除</h2>
<p>如果使用 ORAS 和 PCalc 不起作用： - 确保你有最新更新的游戏补丁. -
ORAS为v1.4. 游戏版本可以在系统设置里面找到.</p>
<blockquote>
<p>（System Settings —&gt; Data Management —&gt; NINTENDO 3DS —&gt;
Downloadable Content）</p>
</blockquote>
<p>-更新可以从 Eshop 下载或使用 CFW 从另一台机器中提取.</p>
<h2 id="其他原因故障排除">其他原因故障排除</h2>
<p>如果游戏更新到最新版本，并且PCalc和/或NTR未加载： - 删除 SD
卡上的所有 NTR 相关文件. - 删除 SD 卡根部的任何 NTR .bin文件. -
删除这些文件夹及其内容： - SD:/Nintendo 3DS/EBNTR/ - SD:/3ds/ntr/ -
SD:/3ds/BootNTRSelector/ -
通过启动引导NTR选择器和启动NTR选择器模式3，再次重新下载所需的NTR文件.</p>
<h2 id="关于神奇宝贝第-67-代游戏更新">关于神奇宝贝第 6/7
代游戏更新：</h2>
<ul>
<li>如果您有一个固件区域更改<code>console or emunand</code>，这可以从其他来源获得，例如从其他console、emunand
或 sysnand 中丢掉您的更新.</li>
<li>口袋妖怪游戏更新不是区域锁定（即日版破解机也能通过插入美版卡带下载游戏更新，即更新补丁各个区域的卡带通用）.</li>
<li>游戏卡带和数字更新存储在 SD
卡上，并且<code>console/emunand</code>是每个机子特定的，并且必须安装在您正在使用游戏对应的<code>console/emunand</code>上.</li>
</ul>
<h2 id="主机相关报错">主机相关报错</h2>
<h3 id="err-009-2920">err 009-2920</h3>
<ul>
<li>问题描述：
<ul>
<li>我遇到的情况就是OR游戏可以正常更新，但是AS的不行，猜测是之前有遗留没有删干净的残余文件（在删干净主界面能看到的应用之后）</li>
</ul></li>
<li>修复方法：
<ul>
<li>打开FBI —&gt; 打开 ticket 选项 —&gt; 看到红色字的ID一律删除</li>
<li>疯狂选中按A就好了，然后直接就更新正常了</li>
</ul></li>
</ul>
<h1 id="乱数id">乱数ID</h1>
<p>详情 <span class="exturl" data-url="aHR0cHM6Ly93d3cucG9rZW1vbnJuZy5jb20vcmV0YWlsLW9yYXMtdGlk">Trainer ID
RNG（ORAS）<i class="fa fa-external-link-alt"></i></span>、<a
href="https://www.pokemonrng.com/pcalc-xy-tid">Trainer ID, Secret ID,
and/or TSV RNG（XY）</a>中已经写明了，我在这里只简单的说一些事项. <img
src="/images/body/Pokemon-RNG-Abuse-Gen6/Trainer-ID-RNG.png"
alt="Trainer ID RNG" /></p>
<ol type="1">
<li>打开 <code>wwwwwwzx</code> 大佬的乱数工具
<strong>3DSRNGTool</strong></li>
<li>获取开始帧信息（gen6下方的四组数据）</li>
</ol>
<ul>
<li>方法1：使用NTR助手（非必须，需要在局域网下进行）</li>
<li>方法2：手动填入</li>
<li><strong>注意事项</strong>：这里不需要关注frame对应的seed，因为这里的乱数信息在很早就已经确定并且不是以60帧/s的速度改变ID数据，只需要注意给<strong>角色取名</strong>时的关键节点进行帧信息的获取就好.
（具体方法请看上面的网址和<a
href="https://github.com/wwwwwwzx/3DSRNGTool#readme">wwwwwwzx大佬GitHub中的<code>Readme.md</code>文件</a>）</li>
</ul>
<ol start="3" type="1">
<li>决定ID信息</li>
</ol>
<ul>
<li>如上面所述这里的乱数信息不是跟随图像变化的，消耗帧的方法是<strong>给角色取名之后再取消</strong>，过程相对比较繁琐所以我当时只刷了几遍，看到4999就收了emmm</li>
<li>乱这个的时候建议多过几遍最开始的剧情找个好的开始帧…这样轻松一些（建议使用NTR助手）</li>
<li>NTR Helper里面的那个自动过帧我没玩儿明白反正…</li>
</ul>
<ol start="4" type="1">
<li>记录ID信息</li>
</ol>
<ul>
<li>我个人建议在你乱出来ID之后，记录一下对应的表里ID（也就是TID &amp;
SID）他们共同决定了你的闪值（TSV） &gt;
在六七代中训练家的TSV和获得宠物（初次取名）时的PSV是否相同决定了宠物是否为异色</li>
</ul>
<h1 id="确定tsv">确定TSV</h1>
<ul>
<li>如果你之前乱数过ID并记录了对应的TSV，请跳过这步并在乱数工具对应的位置上填好tsv</li>
<li>如果没有乱数过，请继续往下看</li>
</ul>
<h2 id="额外需要工具">额外需要工具：</h2>
<ul>
<li>Checkpoint（宝可梦游戏存档导出导入工具包）</li>
<li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2t3c2NoL1BLSGVYL3JlbGVhc2Vz">PKHex<i class="fa fa-external-link-alt"></i></span>
仅用于查看 <strong>tsv</strong>.</li>
</ul>
<h3 id="step-1导出存档">STEP 1：导出存档</h3>
<p>如何导出存档请看 <a
href="/Pokemon/Strategies/In-Game/How-To-Back-Up-Your-Savefiles/#NDS-%E4%B8%8E-3DS-%E5%8D%A1%E5%B8%A6-%E4%BB%A5%E5%8F%8A-3DS-VC-%E7%B3%BB%E5%88%97">如何备份你的存档
相应部分</a>或者直接点击<a
href="https://projectpokemon.org/home/tutorials/save-editing/managing-3ds-saves/using-checkpoint-r25/">这里</a>来查看.
然后在 <code>/3ds/Checkpoint/saves/(your game)/</code>目录中的
<code>main</code> 文件就是你的游戏存档，将其放到电脑合适地方以便于后面在
<strong>PKHeX</strong> 中打开</p>
<h3 id="step-2打开-pkhex">STEP 2：打开 PKHEX</h3>
<ul>
<li>打开PKHeX （ 黄色框中参数选项中可以将软件调成中文 ）</li>
<li>将Step 1中获得的main文件拖入到PKHeX中</li>
<li>再选择红色框中的那个“OT/…”（初训家&amp; ？）</li>
<li>鼠标悬浮到SID（or TID）里面的数字上就能看到你的TSV了</li>
</ul>
<table>
<colgroup>
<col style="width: 46%" />
<col style="width: 53%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">需要注意的参数</th>
<th style="text-align: center;">TSV显示</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><img
src="/images/body/Pokemon-RNG-Abuse-Gen6/pkhex1.png"
alt="pkhex1" /></td>
<td style="text-align: center;"><img
src="/images/body/Pokemon-RNG-Abuse-Gen6/pkhex2.png"
alt="pkhex2" /></td>
</tr>
</tbody>
</table>
<h1 id="乱数宝可梦">乱数宝可梦</h1>
<h2 id="dsrngtool界面设置">3DSRNGTOOL界面设置</h2>
<p>以下是3DS乱数工具中会用到以及需要调整的部分 -
蓝色框中注意TSV是否填写正确（如果不知道请跳转到上方<a
href="#确定tsv">确定TSV</a>） - 红色框中注意每次的 <em>Init Seed</em>
（在点击神兽界面变化之后的）和延迟（因为不同神兽的捕获地点入场动画不同，所以对应的延迟参数也不同）
- 请确认蓝色框和红色框的数据之后再点击绿色框 -
<strong>注意！</strong>黄色框的同步性格选项不会对下面结果有任何影响
依旧是是50%几率替换对应帧的性格Orz</p>
<h2 id="pcalc-工具使用">PCALC 工具使用</h2>
<p>组合键使用 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- X+Up: Key Combo Menu</span><br><span class="line">- Start+Down: Egg Seed View</span><br><span class="line">- Start+Up: RNG Tools</span><br><span class="line">- Start+Left: Wild Pokemon View</span><br><span class="line">- Start+Right: Party Pokemon View</span><br><span class="line">- Select+Left: Party Pokemon View -1 Slot</span><br><span class="line">  - Plugin switches to the other daycare in Egg View</span><br><span class="line">  - Plugin switches Horde Pokemon -1 Slot in Wild View</span><br><span class="line">- Select+Right: Party Pokemon View +1 Slot</span><br><span class="line">  - Plugin switches to the other daycare in Egg View</span><br><span class="line">  - Plugin switches Horde Pokemon +1 Slotin Wild View</span><br><span class="line">- Start+Select: Pause Game</span><br><span class="line">- Pause+A: Unpause Game</span><br><span class="line">  - Additionally, press any D-Pad and the &quot;Y&quot; button plus A to unpause as well</span><br><span class="line">    - (This helps with certain RNG types)</span><br><span class="line">- Pause+Start: Unpause Game</span><br><span class="line">- Pause+Select: Advance One Frame</span><br></pre></td></tr></table></figure> 这个里面我们主要用到
<code>Start+Select</code> &amp;
<code>Pause+Select</code>，简单翻译就是先使用 <code>Start+Select</code>
暂停帧跳动，然后再在 <em>Pause</em> 状态下单独按 <code>Select</code>
让游戏消耗一帧.</p>
<h3 id="部分故障排除">部分故障排除</h3>
<ul>
<li>我按了"A"，但我的战斗没有开始/没有点击上"A"
<ul>
<li>确保按住"A"，而不是轻点它</li>
</ul></li>
<li>我暂停在一个奇数/偶数的帧，但我的目标是在一个偶数/奇数帧
<ul>
<li>保存您的游戏通常会将帧从奇数切换到偶数 or 偶数切换到奇数
<ul>
<li>请在到达目标帧之前操作，以免后面无法调整</li>
</ul></li>
</ul></li>
<li>other：<a
href="https://gbatemp.net/threads/pokecalcntr-for-gen-6-the-rng-tool-suite-for-the-3ds.473221/">pokeCalcNTR
for Gen 6 - The RNG Tool Suite for the 3ds</a></li>
</ul>
<h2 id="操作流程通用">操作流程（通用）</h2>
<ol type="1">
<li>进入 <strong>BootNTR Selector</strong> 显示 <em>Succeeded</em> &amp;
屏幕一篮 ---&gt; 进入游戏屏幕一绿（就可以开工了）</li>
<li>在选择存档界面输入 <em>Init Seed</em> 到 3DSRNGTool
里面计算是否有合适的目标帧</li>
</ol>
<ul>
<li>如果没有，按 <strong>B</strong> 回到神兽界面，再按
<strong>A</strong> 进入刷新 <em>Init Seed</em> ，道理同SL <img
src="/images/body/Pokemon-RNG-Abuse-Gen6/InitSeed.png"
alt="InitSeed" /></li>
</ul>
<ol start="3" type="1">
<li>确定停止界面（离目标帧大约100帧内 然后用select慢慢逼近）</li>
<li>校准延迟（不同神兽的场景对应这不同击中时机，可以根据自己机器的情况改变
3DSRNGTool 中的延迟参数）</li>
<li>精确调整帧数（逐步使用<strong>Select</strong> <a
href="#部分故障排除">注意：击中的帧数是奇数还是偶数</a>）</li>
</ol>
<ul>
<li>使用 PCalc，在游戏选择屏幕上等待，直到接近您想要的Frame</li>
<li>一旦你接近你想要的Frame，按<strong>Start+Select</strong>暂停游戏</li>
<li>按<strong>Select</strong>逐帧前进，直到达到您想要的Frame</li>
<li>到达所需Frame后，<strong>按住A</strong></li>
</ul>
<ol start="6" type="1">
<li>击中目标帧</li>
</ol>
<h2
id="部分场景的逐步调整击中帧的界面">部分场景的逐步调整击中帧的界面</h2>
<ul>
<li>御三家 <img
src="/images/body/Pokemon-RNG-Abuse-Gen6/initialFlash.jpg"
alt="initialFlash" /></li>
<li>水都剧情闪（OR的哥哥，AS的妹妹） <img
src="/images/body/Pokemon-RNG-Abuse-Gen6/Latios.gif"
alt="Latios" /></li>
<li>定点闪
<ul>
<li>充满雷电的云 <img
src="/images/body/Pokemon-RNG-Abuse-Gen6/Thundurus.gif"
alt="Thundurus" /></li>
<li>时空裂缝 <img data-src="/images/body/Pokemon-RNG-Abuse-Gen6/Palkia.gif"
alt="Palkia" /></li>
</ul></li>
</ul>
<h1 id="reference">Reference</h1>
<ul>
<li><a
href="https://wulun0102.github.io/2021-08-21/%E5%8F%A3%E8%A2%8B%E5%A6%96%E6%80%AA%E7%AC%AC%E5%85%AD%E4%B8%96%E4%BB%A3-ORAS%E4%B9%B1%E6%95%B0%E8%AE%B0%E5%BD%95/">口袋妖怪第六世代-ORAS乱数记录</a></li>
<li><a
href="https://stray-soul.com/index.php/3dshack-getstarted">3DS/2DS破解-开始
-一只火狐的杂物间</a></li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cucG9rZW1vbnJuZy5jb20vbWlzYy0zZHMtaW5zdGFsbGluZy1wY2FsYw==">How
to Install PCalc<i class="fa fa-external-link-alt"></i></span></li>
<li><a
href="https://sina-poke.hatenablog.com/entry/2017/05/06/000557">第六世代固定シンボル乱数調整のやり方
- かけらの記録ノート</a></li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cucG9rZW1vbnJuZy5jb20vcmV0YWlsLW9yYXMtdGlk">Trainer ID
RNG<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cucG9rZW1vbnJuZy5jb20vcGNhbGMteHktdGlk">Trainer ID, Secret
ID, and/or TSV RNG<i class="fa fa-external-link-alt"></i></span></li>
<li><a
href="https://gbatemp.net/threads/pokecalcntr-for-gen-6-the-rng-tool-suite-for-the-3ds.473221/">pokeCalcNTR
for Gen 6 - The RNG Tool Suite for the 3ds</a></li>
<li><a
href="https://tieba.baidu.com/p/5168730356?pid=108235360876&amp;cid=0#108235360876">【乱数】3ds乱数工具+6代一些游戏机制的补充【口袋妖怪吧】</a></li>
<li><a
href="https://tieba.baidu.com/p/5168730356?pid=108235360876&amp;cid=0#108235360876">常见问题
- 3DS Hacks Guide</a></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9zdHJheS1zb3VsLmNvbS9pbmRleC5waHAvaG93LXRvLXVzZS1ib290bnRy">3DS
BootNTR金手指使用教程 - 一只火狐的杂物间一只火狐的杂物间<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly90aWViYS5iYWlkdS5jb20vcC83MTA4NDczNTI5">BootNTRSelector
2.13.4更新支持11.14【3ds破解吧】_百度贴吧<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<h1 id="appreciation">Appreciation</h1>
<ul>
<li>感谢<strong>無論</strong>的授权，可以去<a
href="https://wulun0102.github.io/">無論的博客</a>看看.</li>
<li>感谢<strong>wwwwwwzx</strong>大佬的研究成果.</li>
</ul>
]]></content>
      <categories>
        <category>Pokemon</category>
      </categories>
      <tags>
        <tag>Pokemon</tag>
        <tag>Pokemon-RNG-Abuse</tag>
        <tag>Pokemon-Gen6</tag>
      </tags>
  </entry>
  <entry>
    <title>宝可梦四代实机乱数</title>
    <url>/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen4/</url>
    <content><![CDATA[<p>这是宝可梦四代的实机乱数教程. 包含 ID 与 Egg 的乱数教程.
如有纰漏，请<a href="/about/">与我联系</a>，万分感谢！</p>
<p>封面 [ID:92026700].</p>
<span id="more"></span>
<p><strong>注意，本教程仅支持宝可梦四代正作游戏：</strong></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Version</th>
<th style="text-align: center;">珍珠</th>
<th style="text-align: center;">钻石</th>
<th style="text-align: center;">白金</th>
<th style="text-align: center;">心金</th>
<th style="text-align: center;">魂银</th>
<th style="text-align: center;">其他</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Support</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✘</td>
</tr>
</tbody>
</table>
<p>前人栽树，后人乘凉. 本篇对转载原文:<a
href="https://tieba.baidu.com/p/6552613197?pid=130747309042&amp;cid=0#130747309042">【转载】四代乱数教程及工具</a>稍作修改，无法找到原作者，见谅.
如果你认识原作者，可以<a href="/about/">与我联系</a>！</p>
<h1 id="前言">前言</h1>
<ol type="1">
<li>四代乱数的原理，机制. 还有各种乱数相关的知识，大多源自于外文网站<a
href="https://www.smogon.com/ingame/rng/dpphgss_rng_intro">Smogon</a>(虽然Smogon的一些资料也是翻译自日文资料).
没有多少是原作者原创的.
这篇教程更多是一篇翻译+整理，加上实际乱数的一些技巧.
感谢各位大大做的努力，造福广大口袋玩家.</li>
<li>本教程采用傻瓜式渐进方式，从头开始一点一点的讲解四代乱数，希望能带来一些帮助.</li>
</ol>
<h1 id="准备工作">准备工作</h1>
<p>如果你想要乱数闪光宝可梦，你需要知道你的<a
href="https://wiki.52poke.com/wiki/ID_No.#.E9.87.8CID_No.">SID</a>.</p>
<blockquote>
<p>如果你想要乱数的是已经创建好的存档，这可能会需要你导出存档并使用
<em>PKHex</em>
等软件查看你的存档（不涉及修改与导入），请根据自身接受程度使用.<br>
不会导出存档？看看这篇博客：<a
href="/Pokemon/Strategies/In-Game/How-To-Back-Up-Your-Savefiles/">如何备份你的存档</a>.</p>
</blockquote>
<h2 id="硬件准备">硬件准备</h2>
<ul>
<li>能够游玩第四世代宝可梦卡带的机器（<em>NDS</em> 或 <em>3DS</em>
系列）.</li>
<li>电脑.</li>
<li>（若需要导出存档）<em>NDS</em>烧录卡与读卡器.</li>
</ul>
<blockquote>
<p>如果不准备使用烧录卡，可能需要准备足够的神奇糖果.</p>
</blockquote>
<h2 id="下载乱数所需工具">下载乱数所需工具：</h2>
<ul>
<li>计时器<a
href="https://github.com/dylmeadows/EonTimer/releases">EonTimer</a>
如果因为国内 GitHub 下载速度原因不好下载，可以点击<a
href="/download/EonTimer.rar">这里</a>进行下载.</li>
<li>乱数工具<a
href="https://github.com/Admiral-Fish/RNGReporter/releases">RNGReporter</a>
如果因为国内 GitHub 下载速度原因不好下载，可以点击<a
href="/download/RNGReporter.zip">这里</a>进行下载.</li>
</ul>
<h2 id="了解四代乱数机制">了解四代乱数机制</h2>
<p>说到乱数，就不得不提 <strong>Seed</strong>.
对数论和密码学没什么了解的玩家，对于 <strong>Seed</strong>
可以简单的这么理解. <strong>Seed</strong>
是一个数值，在游戏开始的时候会确定下来. 然后游戏系统会根据
<strong>Seed</strong>
计算出一个长长长长的随机数序列，然后游戏内的随机事件，就会由这个数列里的随机数来决定如何发生.</p>
<blockquote>
<p>举一个最简单的例子，某一次我进入游戏. 当前 <strong>Seed</strong>
生成的前三个随机数是 F011，F410，0112. 那么此时我按下 <strong>A</strong>
键与我面前的一只闪电鸟进入战斗(身上无同步率).
此时系统会根据第一个随机数来决定闪电鸟的性格. F011 / A3E = 17.
查表可以知道，17对应的是Quiet性格.
所以我进入战斗遇到的这只闪电鸟性格一定是Quiet.</p>
</blockquote>
<p>既然 <strong>Seed</strong> 决定了游戏内的随机事件如何发生.
那么我们怎么来得到我们想要的 <strong>Seed</strong> 呢？</p>
<p>四代的 <strong>Seed</strong> 由两个因素决定.</p>
<ol type="1">
<li>在游戏内，按下 <strong>A</strong>
键读档进入游戏这一刻的时间，年月日时分秒全部参与计算，也只精确到秒.</li>
<li>从启动游戏这一刻，到按下 <strong>A</strong>
键读档进入游戏这一刻，所经过的时间. 这个时间的精度为 1/30
秒，即约0.033秒.</li>
</ol>
<p>这是四代乱数最基础的两点知识，想要着手开始四代乱数的各位一定要牢记.
最后，本教程默认读者了解涉及的一些基础知识，例如何为<a
href="https://wiki.52poke.com/wiki/ID_No.">ID</a>， <a
href="https://wiki.52poke.com/wiki/ID_No.#.E9.87.8CID_No.">SID</a>， <a
href="https://wiki.52poke.com/wiki/%E6%80%A7%E6%A0%BC%E5%80%BC">PID</a>，
<a
href="https://wiki.52poke.com/wiki/%E4%B8%AA%E4%BD%93%E5%80%BC">IV(个体值)</a>.</p>
<h1 id="id乱数">ID乱数</h1>
<h2 id="目的">目的</h2>
<p>通常大家追求ID，SID，是为了两个目的：</p>
<ol type="1">
<li>获得自己喜欢的表ID.</li>
<li>获得高个体的闪光宝可梦.
因为四代乱数机制的关系，一只宝可梦如果IVs全部确定，那么这只宝可梦就只有少数几种可能的
PID.
例如最常说的6V神兽，就只有6种可能的PID(火钢除外)，如果不借助乱数，自然获得一个ID，SID进入游戏.
那么我们获得6V闪光神兽的概率，也就和BW异国孵蛋出闪光的概率一样(而且性格还不一定是自己想要的).
所以，为了心仪的闪光神兽，乱一个 ID，SID 开始游戏，也是有必要的.</li>
</ol>
<h2 id="确认目标">确认目标</h2>
<ol type="1">
<li><p>打开 RNGReporter，选择 <strong>Time Finder --&gt; 4th Generation
Time Finder</strong>. <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure1.jpg"
alt="Figure1" /></p></li>
<li><p>在这个界面，按图中所示的填入各项. year可以随便填. Min，Max
Delay，Min，Max Frame如果不理解的话，都和图上一样的填好.
然后填上自己想要的个体，性格，特性，性别. 点击 <strong>Generate</strong>
. <img data-src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure2.png"
alt="Figure2" /></p>
<blockquote>
<p>另外，这里有一个成对的概念.
具体原理略不过不谈，只需要知道，对同一组个体值，同一组
ID，SID，有两个PID会同时对应闪光.
例如图上最后两行对应的Timid，Modest，就是成对的. 一组 ID，SID
只要能让其中一个闪光，就必定能闪另一个.
从图上观察，只要两个分布具有相同的 Frame，Hour，并且 PID
的末三位都相同，那它们就是成对闪光的.</p>
</blockquote></li>
<li><p>找到目标之后，就记下这对分布的任意一个PID. 这里我们以最后一对
TIMID，MODEST 为例，记下 PID: 7942EF72.</p></li>
<li><p>在 RNGReporter 的主界面，选择 <strong>4th Gen Tools</strong> 中的
<strong>TIDManipulation ("Pandora's Box")</strong>. <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure3.png"
alt="Figure3" /></p></li>
<li><p>在红框所示的地方，填入刚才记下的PID，Minimum
Delay填入5000(如果是乱Pt，建议填5300+)，勾上 <em>Infinite Serach</em>.
如果你想要一个自己满意的表ID，那么可以勾上 <em>Search for Trainer
ID</em>，在<em>Desired Trainer</em>框中填入目标表ID（这样耗时会较久）.
<img data-src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure4.png"
alt="Figure4" /></p></li>
<li><p>点击<em>Find Compatible
Seeds</em>按钮，就可以生成满足条件的ID，SID了.
因为会无限生成，所以在有一定数量的结果之后，请点Cancel.
之后从结果列表里挑一个自己满意的 ID，SID
作为目标，将目标ID对应的SEED复制下来. 这里以图上蓝色高亮的ID 20802，SID
51056为例. <img data-src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure5.png"
alt="Figure5" /></p></li>
<li><p>在 RNGReporter 的主界面，选择 <strong>4th Gen Tools</strong> 中的
<strong>Seed To Time</strong>. <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure6.jpg"
alt="Figure6" /></p></li>
<li><p>在SEED(HAX)框内填入刚才记下的seed，在Second内填入自己觉得方便的描述.
这里以HgSs作例子，所以选择HgSs，其余设置和图上保持一致. <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure7.png"
alt="Figure7" /></p></li>
<li><p>点击
<strong>Generate</strong>，在结果图里任选一组目标时间，作为我们实际操作的选择.</p></li>
</ol>
<h2 id="校准偏差与乱数id">校准偏差与乱数ID</h2>
<ol type="1">
<li>使用 Eontimer 击中seed，这里请查看<a
href="#如何使用Eontimer计时器">如何使用Eontimer</a>.
<ul>
<li>如果是HgSs请在上图所示的界面等待计时器到0进入游戏. <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure8.png"
alt="Figure8" /></li>
<li>如果是DPPt，请在上图所以的界面等待计时器到0时按 <strong>A</strong>
键. <img data-src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure9.png"
alt="Figure9" /> 操作细节请注意:
取名字的时候，每次都按相同的操作取名字，以免造成帧数不必要的变化.</li>
</ul></li>
<li>进入游戏之后，查看自己的表ID，这个ID多半不是我们的目标，此时需要确定偏差.</li>
<li>将得到的表ID填入下图的红色框内，seed对应的月日年时分也依次填入.
MinMax delay填入自己估计的偏差. 例如目标是4987，那Min
Max可以分别填入4900 5100. <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure10.png"
alt="Figure10" /></li>
<li>点击 <strong>Find</strong> 按钮，看到自己实际击中的delay.
如果没有结果. 可以将Min Max的范围扩大再搜索.
如果依然没有，请检查年月日时分秒和eontimer的设置是否正确.</li>
<li>得到我们实际击中的delay之后，即可使用 Eontimer
调整偏差，继续尝试，直到得到目标ID.</li>
</ol>
<h1 id="如何使用eontimer计时器">如何使用Eontimer计时器</h1>
<p>Eontimer是一个非常好用的计时器，功能涵盖三四五代，这里我们只需要用到四代的功能.</p>
<ol type="1">
<li>打开软件，选择 4 选项卡. 除了红色框内的：如果是
HgSs，参数如图上所示就ok. 如果是PT，请将490改为600，其他不变.
这样就完成了初步设置. <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure11.png"
alt="Figure11" /></li>
<li>我们从RNG的Seed To Time 工具里得到的时间是这样的. <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure12.png" alt="Figure12" />
想要击中对应的目标seed. 将对应的秒数填入红色框内 Target
Second的位置(这里是47)，将对应的delay填入红色框内TargetDelay的位置(这里是4987).
然后设置游戏机的时间到目标时间(这里是2013年4月23日，13点57分).
注意图上的 Minutes Before Target 后面红色的数字.
这代表需要提前设置的分钟数. 这里的分钟数为1，机器时间设置需要提前一分钟.
即为2013年4月23日，13点56分.
如果是0的话，就不需提前，按目标时间设置就好.</li>
<li>设置好之后，同时在机器时间设置界面按下 <strong>A</strong>键，以及
Eontimer 的 <strong>start</strong>按钮.
这时Eontimer即会开始计时，在第一个计时到0的时候，在机器的主界面按
<strong>A</strong> 进入游戏（如果是 DSi 或者 3DS
系列，可以提前进入游戏后在归0时软重置，不然校准误差时需要多往后搜索一些）.
在第二个计时到0的时候，在读档确认界面（即选择存档进入游戏的界面）按下
<strong>A</strong> 键，进入游戏.</li>
<li>进入游戏之后，我们可以通过各种方法来验证自己实际击中的delay.
将实际击中的delay填入Delay Hit
框内，然后点选Update，Eontimer会自动调整计时. 当然.
如果你击中的delay离目标delay已经很近（+-6之内），那么基本不需要Update，保持一致的操作，反复尝试即可.</li>
<li>如果击中的delay和我们的目标delay奇偶不同，那么在Seed To
Time工具内，改一下种子的年份(+-1)，用新生成的种子作为目标就可以了.
如果是在乱ID的时候，也可以不改年份，在取名界面多改变一次大小写.
（据说对于DS系统，插入GBA卡带也可以改变奇偶，有待测试）</li>
</ol>
<p>大部分时候Eontimer的使用都如上面描述，不过还是有几个特别的地方：
在乱ID的时候，由于没有读档界面，在第二个计时器到0的时候，请在乱ID篇给出的界面按A.
(友情提示，乱ID前记得删除存档)</p>
<p>另外是秒数的设置. 几乎所有的情况，和目标秒数保持一致就ok.
唯一的例外是<strong>在HgSs(仅限HgSs)里乱ID的时候，Eontimer的秒数设置比目标秒数减3.例如目标秒数是47，eontimer里就填入44.</strong></p>
<h1 id="宝可梦乱数">宝可梦乱数</h1>
<p>在前文讲seed的时候提到过，seed生成了一个长长长长的随机数序列.
但是，如何用这些随机数来生成我们实际得到的宝可梦的各项参数：例如个体，性格，特性，性别，是否闪光之类的；均是由method来决定的.
所以，即便是一串相同的随机数，在不同的method下得到的宝可梦是不同的(即便是同一编号的宝可梦).
最简单的例子就是绿宝石内定点的变隐龙和野生的变隐龙，即便在相同的随机数序列下，抓到的定点和野生的变隐龙也是不同的.
所以乱宝可梦，首先要知道它对应的Method.</p>
<h2 id="确定乱数目标">确定乱数目标</h2>
<p><strong><em>如果选择了野外相遇的宝可梦，请在队伍中准备一只习得了<a
href="https://wiki.52poke.com/wiki/%E7%94%9C%E7%94%9C%E9%A6%99%E6%B0%94%EF%BC%88%E6%8B%9B%E5%BC%8F%EF%BC%89#.E5.8F.AF.E4.BB.A5.E5.AD.A6.E4.BC.9A.E8.AF.A5.E6.8B.9B.E5.BC.8F.E7.9A.84.E5.AE.9D.E5.8F.AF.E6.A2.A6">甜甜香气</a>的宝可梦.</em></strong>
确定乱数目标后，选择相应的 <em>Method</em>. 如果是乱数蛋，请点击<a
href="#蛋乱数">这里</a>.</p>
<h3 id="method-1"><em>Method 1</em></h3>
<ul>
<li>初始御三家，赠送的前代御三家</li>
<li>赠送的波可比的蛋，小卢卡的蛋</li>
<li>赠送的伊布，3D龙，巴尔郎，迷你龙</li>
<li>各类化石复活的宝可梦，游戏中心兑换的宝可梦</li>
<li>各类游走神兽：雷公，炎帝，水都，美梦，游走蘑菇，三鸟（水都和三鸟只有游走的才是
<em>Method1</em>）</li>
<li>阿尔宙斯祈祷剧情赠送的DPPt三神</li>
</ul>
点击下面的谜拟Q来查看英文描述：
<details>
<summary>
<img no-lazy data-src="/images/mimikyu.png" alt="Method 1 请点击丘丘" align=left>
</summary>
<p><br> DPP：<br> Starter Pokemon<br> Cynthia's Togepi Egg<br> Fossil
Pokemon from Mining Museum<br> Riolu Egg from Riley<br> Eevee from
Bebe<br> Porygon from Veilstone<br> Cresselia， Mesprit， Articuno，
Zapdos， and Moltres<br><br></p>
<p>HgSs：<br> Kanto/Hoenn/Johto Starters<br> Togepi Egg<br> Bill's
Eevee<br> Raikou， Entei， and Latios/Latias roamer; the Latios/Latias
from the Enigma Stone event is NOT Method 1<br> Tyrogue from Mt.
Mortar<br> ExtremeSpeed Dratini received from Dragon's Den<br>
Goldenrod/Celadon Game Corner Prize Pokemon<br> Fossil Pokemon Pewter
City Museum<br> Sinjoh Ruins Dragon event where you need
Arceus<br><br></p>
<p>Note: Any Pokemon received from a trade or as a gift that has a fixed
nickname and OT (Kenya the Spearow， Gaspar the Haunter， etc.) will
have set IVs and nature so RNG manipulation techniques will never work
on them.</p>
</details>
<p><br><br></p>
<h3 id="method-jk"><em>Method J/K</em></h3>
<p>Method J/K(DPPt对应 J，HgSs对应
K)的宝可梦可以被同步率、魅惑身躯影响（之后的选项中需要更改
<strong>Requied Lead</strong> 项）.
而游戏中几乎所有的野生怪兽、定点神兽都对应Method J/K.
（愤怒湖的红色暴鲤龙是Chained Shiny Method，不要尝试用Method
K去乱它）</p>
<p>如果乱数野生宝可梦，你还需要选择 <em>Encounter Slot</em>
项，点击顶部菜单项 <strong>4th Gen Tools</strong> 选择对应游戏版本的
<em>Encounter Table</em>，来查看你想要的宝可梦属于什么 <em>Encounter
Slot</em>.（可能需要科学上网）</p>
<h3 id="wondercard-ivs"><em>Wondercard IVs</em></h3>
<ul>
<li>在商店领取的Wondercards宝可梦 <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/WonderCards.png"
alt="WonderCards" /></li>
</ul>
<p>对于 DPPt，您需要保存在 Pastoria City Mart，因为那里随机移动的 NPC
数量最少. 对于 HgSs，请保存在 Fuchsia 或 Cerulean City's Mart
中，因为这两个位置都没有随机移动的 NPC. 在当前没有 NPC
移动时进行保存也很重要. 此外，在 DPPt
中乱数时，请确保在进入游戏的那一刻调出菜单，以防止 NPC 移动.
与其他方法不同的是，无法在不作弊的情况下保证获得确定的性格，多尝试几次吧.</p>
<h2 id="乱数宝可梦">乱数宝可梦</h2>
<ol type="1">
<li><p>打开 RNGReporter，选择 <strong>Time Finder --&gt; 4th Generation
Time Finder</strong>.</p></li>
<li><p>Year Min Max Delay Min Max Frame如果仍然不理解，请按图上的填入.
个体性格按自己需要的填写. <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure13.png"
alt="Figure13" /></p></li>
<li><p>点击 Generate，得到目标 Seed，我们选择帧数较小的一个.</p></li>
<li><p>用seed To time 工具得到种子对应的时间和delay，设置好 Eontimer.
（如果有游走宝可梦可以打开map来方便确定delay）</p></li>
<li><p>将游戏进行到所需位置存档.</p></li>
<li><p>用Eontimer计时器辅助进入游戏之后，<a
href="#初始帧与判断delay">判断实际击中的delay</a>.</p></li>
<li><p>找到实际delay之后，调整eontimer的设置，反复尝试，直到击中目标delay.</p></li>
<li><p>击中目标delay之后，<a href="#增加帧数">推进至目标帧</a>.</p></li>
<li><p>触发，得到宝可梦.</p></li>
</ol>
<blockquote>
<p>需要注意的一点是，在野外乱数时，很可能受到随机NPC的干扰，这里就需要乱数的各位自行调整偏差.
可以根据第一次击中帧数的偏移帧来调整，也可以通过打电话看回复的方法来调整，这里就留给大家去尝试吧.
这里能给大家的一点经验就是，在同一个地方不同的时间存档，帧数的偏移很可能会不一样，因为存档的同时也记录下了NPC的位置，所以调整帧数之后不要重新存档.</p>
</blockquote>
<blockquote>
<p>最后，几乎所有的Method1 宝可梦起始帧数都为1.
例外主要是同时判定多只宝可梦的情况.
比如燃烧塔同时判定雷公炎帝(1、6，欧版反之)，白金和大木博士对话同时判定关东三鸟.
三鸟先后顺序是火焰鸟、闪电鸟、急冻鸟，帧数分别为1、6、11.
比较好的方法是，先乱其中一只鸟，把目标的那只捕获后，打死另外两只，再和博士对话.
这样剩下的两只释放时，先后关系依然如上，帧数分别对应1、6.
不建议在和宝石钢天王对话时乱游走水都，因为那地方NPC多，帧数难以控制，所以游走水都还是很使用打联盟的方法乱吧.</p>
</blockquote>
<h2 id="初始帧与判断delay">初始帧与判断delay</h2>
<h3 id="hgss">HgSs</h3>
<h4 id="通过打电话来确认帧">通过打电话来确认帧</h4>
<p>在某些情况下，我们只有使用打电话的方法来确认delay.</p>
<ol type="1">
<li><p>在35号路获得杂耍艺人 麦克的电话： <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Irwin1.jpg" alt="Irwin1" />
<img data-src="/images/body/Pokemon-RNG-Abuse-Gen4/Irwin2.png"
alt="Irwin2" /> Irwin可能的回复有三种： <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/E.png" alt="E" /> <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/K.png" alt="K" /> <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/P.png" alt="P" /> 分别记为
<strong>E</strong>，<strong>K</strong>，<strong>P</strong>.</p></li>
<li><p>进入游戏之后，快速转到打电话页面，给Irwin打电话，记录下每次打电话的结果.
注意，每打一个电话会增加1帧，如我打了8个电话，回复序列是P P K P P K E
E，则前进了8帧.</p></li>
<li><p>在 seed to time 界面. 选中目标时间和delay.
点击界面下半部的generate. <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure14.png"
alt="Figure14" /></p></li>
<li><p>可以看到，结果列表里出现了目标delay附近的delay对应的电话序列.
用刚才得到的电话序列去列表中对照，如果完全吻合，即可基本确认，我们实际击中的delay是多少.
刚才我们的8个电话的回复对应的是delay 1061.
因为1061和目标奇偶不同，所以需要改一下年份，重复前面的过程.
具体参照eontimer的部分.</p>
<blockquote>
<p>如果距离目标delay差距较大，界面的Delay+-(图上是+-10)，例如改成+-50，结果列表里即会出现距离目标delay+-50范围类的结果.
继续查找就行.</p>
</blockquote></li>
<li><p>如果结果范围太大. 可以使用界面上的 SearchCalls 按钮. <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure15.jpg" alt="Figure15" />
将自己的电话回复填入，直到 PossibleResults
是1的时候，点击确认即可找到delay.</p></li>
</ol>
<h4 id="通过游走神兽的位置来确认帧">通过游走神兽的位置来确认帧</h4>
<p>在RNG的Seed To Time界面打开 Map 按钮.
可以看到，游戏内地图上每一个游走神兽可能出现的位置都用数字编号标出.
进入游戏之后查看游走神兽的位置，即可知道自己当前击中的seed. <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Map.png" alt="Map" /> <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure16.png" alt="Figure16" />
在地图上存在游走神兽的时候(R雷公E炎帝L水都)，查找seed的时候需要勾上对应的选项.
然后在delay范围的列表里，可以看到每个seed(delay)对应的游走神兽分布.
进入游戏之后，快速打开地图. 查看游走神兽的位置，与给出的位置对照.
如果发现游走神兽的位置是 R 33 E 30 L
17，那么就基本可以确定击中了目标seed. 当然如果出现的位置是 R30 E 35 L18
那么基本就可以确定击中的delay是8487.
同样，如果delay的范围较大，可以使用searchroamers的功能来查找.</p>
<p>最后需要注意的是，地图上有游走神兽的时候，读档开始游戏时就会额外的消耗帧.
绝大部分情况下，都是1只消费一帧.
所以，地图上有N只游走神兽时，起始帧数即为N+1，乱数时候请牢记.</p>
<blockquote>
<p>在极少数情况下，会出现某只游走神兽消费两帧的情况.
这个时候，即便击中了seed，游走神兽的位置也会和软件显示的位置不符合.
如果发现反复击中目标delay前后，但是老是击不中目标.
这时候可以用非目标的那个位置打电话验证一下. (我还没遇到过这种情况)</p>
</blockquote>
<h3 id="dppt">DPPt</h3>
<h4
id="使用口袋手表的硬币插件来确认帧">使用口袋手表的硬币插件来确认帧</h4>
<p>在选择DPPT的选项时，生成的结果列表里会有seed(delay)对应的抛硬币结果.
在Search Flips 选项卡里，可以看到 T H 的含义. <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure17.png" alt="Figure17" />
<img data-src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure18.jpg"
alt="Figure18" /> 进入游戏之后，将抛硬币得到的结果输入，直到Possible
Results变为1，确认之后就能找到结果了.
与HgSs的不同点在于，抛硬币不像打电话一样会增加帧数.
另外，在PT中，进入游戏时的日记会增加帧数(看一页增加2帧).
所以在PT里乱的时候，到目标处，存档读档再存档，去掉日记的干扰为最佳.</p>
<p><strong>白金的<a
href="https://wiki.52poke.com/wiki/%E5%AF%B6%E5%8F%AF%E9%8C%B6#.E6.8E.B7.E7.A1.AC.E5.B8.81">抛硬币插件</a>要拿到攀岩之后才能获得.
</strong></p>
<blockquote>
<p>注意，对于无法利用上述方法的场合，可以通过导出存档后查看个体并通过RNGReporter的工具<strong>4th
Gen Tools --&gt; Find Seed by IVs</strong>来反查seed/delay.
此外，也可以参考别人写的呆呆兽初始与迷人之躯教程中列表的方法，但会很耗时间.
相关文章可点击<a
href="/download/GEN4-Slowpoke-RNG.rar">这里</a>下载.</p>
</blockquote>
<h3 id="初始御三家的确认帧">初始御三家的确认帧</h3>
<p>在目标前存档并<strong>备份</strong>，领取后导出存档，根据<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part3/#确定初始seed组并选择备用初始seed">宝可梦火红叶绿实机乱数（不包含
ID 或
Egg）中【确定初始seed组并选择备用初始seed】章节的7~9步</a>的方法进行反查得到初始seed。</p>
<blockquote>
<p>注意，pt的初始会有游走npc消耗帧数，请尽快操作，并记下消耗帧。</p>
</blockquote>
<h2 id="增加帧数">增加帧数</h2>
<p>HgSs里，已经讲过打电话的方法，每一个电话增加1帧. 但是这非常不方便.
还有一个HgSs和PT通用的更好的方法：聒噪鸟.
在给聒噪鸟录好音的情况下，查看一次聒噪鸟的状态增加1帧(不需要听到叫声).
身上准备好两只聒噪鸟，来回切换，即可快速方便的增加帧数.</p>
<p>另外就是HgSs的广播也能增加帧数.
比较有用的就是博士的口袋广播，听一次会增加14~18帧.
在目标帧数成百上千的时候比较有用.
我个人没有尝试过，具体请参见外网资料.</p>
<p>存档一次也可以增加一帧，可以适用于初始乱数。</p>
<h1 id="蛋乱数">蛋乱数</h1>
<p>想要乱数蛋，首先还是要弄清蛋相关的乱数的机制.
在游戏里，每走255步就会判定是否出蛋，并且同时判定蛋的性格值，性格，特性，性别，是否闪光.
一旦确定，除非从老爷爷那里收掉或者拒绝掉这个蛋，否则不会更改；这里用来判定的PID，并非是前文所说的那些，而是用的一个叫做Egg
PID的东西；Egg
PID所用到的随机数是由我们所熟知的随机数序列的种子，经过另一个随机数算法得来的.
从老爷爷拿蛋的时候会根据当前的PID(这个PID即为我们在乱定点/游走/野生时候所说的PID)来决定</p>
<figure>
<img data-src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure19.jpg"
alt="Figure19" />
<figcaption aria-hidden="true">Figure19</figcaption>
</figure>
<ol type="1">
<li>打开4th Gen Time Finder，进入Shiny Egg选项卡.</li>
<li>按自己的需求选上对应的性格，特性，性别，是否闪光.
如果是异国婚姻，记得勾上左边的 International Parents.
都弄好之后generate.</li>
<li>强烈建议选Frame为1的作为目标，这样我们可以省去增加Egg
Pid的步骤.</li>
<li>选中目标之后，将宝可梦存入，记下先存入的为Parent A，后存入的为Parent
B. 不要带不变石or项圈什么的. 都弄好之后到屋外存档.</li>
<li>之后的操作和前文乱数类似，将我们的目标Seed用seed to
time工具换算成时间，用eontimer辅助进入击中seed.</li>
<li>用游走神兽确认击中之后，在老爷爷面前来回跑动直到出蛋.</li>
<li>出蛋之后在老爷爷面前存档，拿蛋，验证一下是否是我们的目标.
如果闪光，性格，特性，性别不正确，回到步骤5 <img
src="/images/body/Pokemon-RNG-Abuse-Gen4/Figure20.jpg"
alt="Figure20" /></li>
<li>用 EggIVs
选项卡，ParentA/B里分别填入对应的个体，右边选上自己的目标个体.
都填好之后generate.</li>
<li>目标结果会非常多，随便选一个帧数在10以上的吧(因为需要电话确认帧位置，所以不建议选太小的).
蓝色高亮的是我们这次例子的目标. 右边还贴心的列出了直到目标前的电话回复.
这里是(E E E) K P E P P P K E P K. 注意如果地图上有三只游走神兽的话， EE
E这三帧会被消耗掉. 再加上周围有NPC的原因，我们打的第一个电话可能是 K
也可能是 P E P.
所以多打几个电话，确认我们帧的位置，不过记住，打完最后的K之后，就可以退出菜单和老爷爷对话拿蛋了.
例如，我打的前三个电话是 P P P，那么我还需要打 K E P K
4个电话，就可以和老爷爷拿蛋了.</li>
</ol>
<h1 id="礼物特别篇----玛娜菲的蛋">礼物特别篇----玛娜菲的蛋</h1>
<p>从Ranger联动过来的玛娜菲的蛋不同于普通的礼物，是<strong>method
1</strong>生成的.
系统为了‘防止’玩家获得闪光的玛娜菲，在生成蛋的PID的时候，会用当前玩家的ID/SID判定是否闪光，如果闪光，就用下一个PID，直到不闪光为止.
然而，蛋里的宝可梦是否闪光，是孵出来的那一刻判定的，这就给了我们钻空子的机会.
假设我有A，B两张四代卡. 我在A卡里乱一只PID能和B的
ID/SID判定闪光的玛娜菲，传到B卡里孵化，那么就可以成功获得闪光的玛娜菲了！</p>
<p>具体的操作方法，就留一个小小的尾巴，让各位自行尝试吧.
不过有一点建议，因为通信会强制存档，所以乱闪光玛娜菲我们只有一次机会.
建议在HgSs里乱玛娜菲(<strong>因为没有随机NPC</strong>)，然后再传到其他卡带里孵化，如果对乱数熟练掌握的话，成功率几乎是100%.</p>
<h1 id="reference">Reference</h1>
<ul>
<li><a
href="https://tieba.baidu.com/p/6552613197?pid=130747309042&amp;cid=0#130747309042">【转载】四代乱数教程及工具</a></li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cuc21vZ29uLmNvbS9pbmdhbWUvcm5nLw==">Smogon RNG
教程<i class="fa fa-external-link-alt"></i></span></li>
</ul>
]]></content>
      <categories>
        <category>Pokemon</category>
      </categories>
      <tags>
        <tag>Pokemon</tag>
        <tag>Pokemon-Gen4</tag>
        <tag>Pokemon-RNG-Abuse</tag>
      </tags>
  </entry>
  <entry>
    <title>间谍伞日记</title>
    <url>/Game/Undercover-Brella-Diary/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Invalid Password. Check And Try Again! (♯｀∧´)" data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="ee1d2eeb4aae9d53e5241d3b782e2073b909260145eedd012aa2bc99b685d959">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Game</category>
      </categories>
      <tags>
        <tag>Game</tag>
        <tag>Splatoon</tag>
      </tags>
  </entry>
  <entry>
    <title>战斗金字塔刷闪教程</title>
    <url>/Pokemon/Strategies/In-Game/Battle-Pyramid-Shiny/</url>
    <content><![CDATA[<p>对战金字塔中会出现很多平时抓不到的（闪光）宝可梦，但却没有办法抓，是不是很不甘心呢？这篇攻略为你带来了捕捉方法！（<strong>当然很难也有副作用</strong>）</p>
<p>本篇文章为个人译制，可能有些许地方措辞不当，请多包涵！</p>
<p>封面 [ID:91220788].</p>
<span id="more"></span>
<p>这篇在2021-06-10日完成，最近翻出来稍微修正了一些，顺便再发一遍好了.
原篇请见<a
href="https://www.bilibili.com/read/cv11658440">我的b站专栏</a>.</p>
<p>感谢老金的小校对、XXC的怂恿、卧看微尘的模拟器协助与各位群友的支持！</p>
<h1 id="acknowledgement">Acknowledgement</h1>
<ul>
<li>原作者：olig</li>
<li>技术基础：Metarkrai</li>
<li>翻译：willkyu</li>
<li>补充、后期测试与加工：willkyu</li>
<li>校对：willkyu、老金</li>
</ul>
<p>授权图： <img
src="/images/body/Battle-Pyramid-Shiny/Authorization.webp"
alt="Authorization" /></p>
<p><br></p>
<h1 id="战斗金字塔刷闪教程">战斗金字塔刷闪教程</h1>
<p>————或者说是一个让你得到日思夜想的FLoYT的教程</p>
<blockquote>
<p>译者注：FLoYT是First Live on YouTube的缩写<br>
已将作者上传的内容包括原文与存档放在了百度网盘，需要请自取. <br>
百度网盘：<span class="exturl" data-url="aHR0cHM6Ly9wYW4uYmFpZHUuY29tL3MvMXZwTEM4Vi12Q3Q1dVFoY0lYXzB5VlE=">https://pan.baidu.com/s/1vpLC8V-vCt5uQhcIX_0yVQ<i class="fa fa-external-link-alt"></i></span>，提取密码：will</p>
</blockquote>
<p><img data-src="/images/body/Battle-Pyramid-Shiny/Head.png" /></p>
<p><br></p>
<h2 id="简介">简介</h2>
<p>我整理了一个在宝可梦绿宝石的战斗金字塔中捕捉闪光宝可梦的简化教程，这种方法利用了榴石果漏洞（然后连锁二次崩溃（double
corruption）），但这个漏洞没有那么一无是处.
不过，这确实要花点时间，所以请坚持下去.
你只需要一张绿宝石卡带和一台Nintendo DS (Lite
或者初代饭盒)，但如果你想准备得更充分一些，我建议再准备一张烧录卡.</p>
<p>我并不是这方面的专家，但在我成功实现这个漏洞后，我想我应该做一个教程.
有比我更了解的人提供了更深入的指南，但是我发现的相关的 Pastebin
都有些难懂，并且真正有帮助的视频是法语的. 如果你确实想看看这些 Pastebin
和视频来参考的话，我把链接放在了下面. 不过我建议只看最下面的视频，因为
YouTube 上的其他视频都不完整的.</p>
<blockquote>
<p>译者注：Pastebin是国外一个存储、分享代码或文字的网站.</p>
</blockquote>
<ul>
<li><a
href="https://bulbapedia.bulbagarden.net/wiki/Battle_Pyramid">战斗金字塔有什么</a></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9wYXN0ZWJpbi5jb20vdS9NZXRhcmtyYWk=">Metarkrai 的 Pastebin
hub<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9wYXN0ZWJpbi5jb20vWWFaYU1RNEc=">Metarkrai 关于榴石果漏洞的
Pastebin<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9wYXN0ZWJpbi5jb20vUjVwcFI5MXg=">Metarkrai
关于战斗金字塔刷闪的 Pastebin<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly95b3V0dS5iZS9fWTZnZmMzeEJ2Yw==">Metarkrai
的战斗金字塔刷闪视频<i class="fa fa-external-link-alt"></i></span>（强烈推荐，尽管仅作参考）</li>
</ul>
<blockquote>
<p>译者注：第一个链接可以参考神百的对战金字塔词条.</p>
</blockquote>
<p>在这里十分感谢 <strong>Metarkrai M</strong> 和
<strong>Speed0373</strong>
——这篇教程背后的两位天才，后者也是位很棒的shiny hunter，请关注<a
href="https://www.youtube.com/user/IIDarkMII">他的YouTube</a></p>
<p><strong>【请注意】Double
Corruption可能会不经意间导致一些问题，我建议尝试任何事情前备份好你的存档！</strong></p>
<blockquote>
<p>译者注：这个漏洞会产生大量坏蛋，暂时还没有很好的清除坏蛋的方法，请自行斟酌.
<br> 此外，由于每个人接受程度不同，文章中出现了如使用各类漏洞，<br>
或是借助烧录卡备份存档等做法，请根据自身情况来决定. <br>
又注：可能绿宝石对战塔的复制bug可以覆盖坏蛋，有待测试</p>
</blockquote>
<p><br></p>
<h2 id="前期准备">前期准备</h2>
<p>在尝试这个漏洞并进行战斗金字塔挑战时，我在每一轮之前进行了多次存档备份，并且将这些备份存档上传到了我的Google
Dive（谷歌云盘）.
因此，如果你不想做这些准备工作，只想刷闪，我十分欢迎你下载我的存档并导入到自己的卡带里进行游戏，当然，这会使你之后刷的闪光宝可梦不是自id.
但如果你想要在之后的场次中刷闪，这会帮你节省下两周左右的准备时间.
如果你使用了这些存档，你可以直接跳到本攻略的 <strong>Step
6：G</strong>.</p>
<p>尽管我正在寻找特定的场次，但我计划上传所有场次的存档.</p>
<blockquote>
<p>译者注：截止至翻译时，作者已上传了18轮的存档，虽然作者分享了自己的存档，<br>
但我个人还是不建议使用他人的存档刷闪. 当然，这看个人的想法，因人而异<br>
作者的谷歌云盘：<a
href="https://drive.google.com/drive/folders/15RNkGdAzbalwlzwijt1E8SnnMX9lHM8i?usp=sharing"
class="uri">https://drive.google.com/drive/folders/15RNkGdAzbalwlzwijt1E8SnnMX9lHM8i?usp=sharing</a></p>
</blockquote>
<p><br></p>
<h3 id="一些准备">一些准备</h3>
<ol type="1">
<li>需要的道具：
<ul>
<li>大师球x4+</li>
<li>烟雾球</li>
<li>榴石果 x2 <img data-src="/images/body/Battle-Pyramid-Shiny/Figure1.png"
alt="Figure1" /></li>
<li>大量喷雾</li>
<li>营养饮料（HP增强剂、攻击增强剂等） <img
src="/images/body/Battle-Pyramid-Shiny/Figure2.png"
alt="Figure2" /></li>
<li>强制锻炼器（竞争背心） <img
src="/images/body/Battle-Pyramid-Shiny/Figure3.png"
alt="Figure3" /></li>
<li>白色玻璃哨</li>
<li>至少500零花钱</li>
</ul></li>
<li>推荐的道具：
<ul>
<li>向尾喵的尾巴（只是防止你忘记续喷雾）</li>
<li>放进你金字塔包包里的额外的精灵球</li>
<li>讲究围巾 /
讲究头带和剩饭——让你通过金字塔更容易一些，尽管这些可以在金字塔里捡到</li>
</ul></li>
</ol>
<blockquote>
<p>译者注：讲究围巾首次出现于第四世代，可能原作者弄错了.</p>
</blockquote>
<ol start="3" type="1">
<li>需要的宝可梦：
<ul>
<li>游戏内与npc交换的橡实果</li>
<li>游戏内与npc交换的正点拍拍</li>
<li>会甜甜香气的宝可梦（10号道路的走路草自带甜甜香气）</li>
<li>同行的队伍来实现榴石果漏洞</li>
<li>一只濒死的宝可梦</li>
</ul></li>
</ol>
<p><br></p>
<h3 id="确定目标">确定目标</h3>
<p>战斗金字塔有很多不错的刷闪目标使得这个漏洞有了他的价值，下面的两个链接包含了每轮可以遇到的野生宝可梦种类与概率.
我把两个链接都列出来了，因为尽管Smogon更详细，但Bulbapedia（种子百科）更加直观，我建议两个结合起来看.</p>
<ul>
<li><a
href="https://bulbapedia.bulbagarden.net/wiki/List_of_wild_Pok%C3%A9mon_in_the_Battle_Pyramid"
class="uri">https://bulbapedia.bulbagarden.net/wiki/List_of_wild_Pok%C3%A9mon_in_the_Battle_Pyramid</a><br></li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cuc21vZ29uLmNvbS9pbmdhbWUvYnQvYmF0dGxlX3B5cmFtaWQ=">https://www.smogon.com/ingame/bt/battle_pyramid<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><br></p>
<h3 id="比较强力的队伍">比较强力的队伍</h3>
<p>这在漏洞实现前后都可以进行准备.
尽管你将会把烟雾球、讲究围巾等道具放入你的对战金字塔包包里，我仍然建议考虑组建一个强有力的队伍，特别是你还要游玩之后的场次的话.
我的队伍如下：</p>
<ul>
<li>巨金怪（固执；252 物攻，252 速度，4 HP） <img
src="/images/body/Battle-Pyramid-Shiny/PM1.png" alt="PM1" />
<ul>
<li>燕返</li>
<li>大爆炸</li>
<li>彗星拳</li>
<li>地震</li>
</ul></li>
<li>赫拉克罗斯（怕寂寞；252 物攻，252 速度，4 HP） <img
src="/images/body/Battle-Pyramid-Shiny/PM2.png" alt="PM2" />
<ul>
<li>劈瓦</li>
<li>超级角击</li>
<li>地震</li>
<li>岩石封锁 / 岩崩（场次 4+）</li>
</ul></li>
<li>拉帝亚斯（悠闲；252 特攻，252 HP，4 物防） <img
src="/images/body/Battle-Pyramid-Shiny/PM3.png" alt="PM3" />
<ul>
<li>冥想</li>
<li>精神强念</li>
<li>冲浪</li>
<li>自我再生 / 十万伏特（场次 6+）</li>
</ul></li>
</ul>
<p>这里的个体并没有最优（比如巨金怪和赫拉克罗斯的速度很拉胯），但我在不作弊的情况下尽可能的让个体最大化（比如巨金怪和赫拉克罗斯有非常好的物攻个体）.</p>
<p>如果你不想花时间来组建一个强有力的队伍，你可以随意导入我的存档并将这些宝可梦传入你的存档.</p>
<p>如果你想要组建一个自己的强有力的队伍但不知道从何下手，请看下面的链接，里面有一些关于战斗金字塔的攻略：
<a
href="https://www.smogon.com/forums/threads/emerald-battle-pyramid-rmt.3488817/"
class="uri">https://www.smogon.com/forums/threads/emerald-battle-pyramid-rmt.3488817/</a><br>
<a
href="https://gamefaqs.gamespot.com/boards/921905-pokemon-emerald-version/52746591"
class="uri">https://gamefaqs.gamespot.com/boards/921905-pokemon-emerald-version/52746591</a><br>
<a
href="https://www.reddit.com/r/pokemon/comments/68t0uf/i_finally_got_all_7_gold_symbols_in_the_emerald/"
class="uri">https://www.reddit.com/r/pokemon/comments/68t0uf/i_finally_got_all_7_gold_symbols_in_the_emerald/</a><br>
<a
href="https://www.reddit.com/r/pokemon/comments/30npi5/emerald_battle_frontier_team/"
class="uri">https://www.reddit.com/r/pokemon/comments/30npi5/emerald_battle_frontier_team/</a><br>
<a
href="https://www.reddit.com/r/pokemon/comments/48mntm/pok%C3%A9mon_emerald_battle_frontier_guide_how_to_get/"
class="uri">https://www.reddit.com/r/pokemon/comments/48mntm/pok%C3%A9mon_emerald_battle_frontier_guide_how_to_get/</a></p>
<p><br></p>
<h3 id="烧录卡">烧录卡</h3>
<p>烧录卡确实是有些争议的，但如果你仅仅用其备份/导入你的存档的话，我不认为这有什么.
你需要一张烧录卡，一个SD卡读卡器，一台电脑和一台 Nintendo DS（Lite
或者初代饭盒）. 关于如何备份你的存档可以参见视频：<a
href="https://youtu.be/fWCDzpzAhsk"
class="uri">https://youtu.be/fWCDzpzAhsk</a>.</p>
<blockquote>
<p>译者注：贴吧等也有很多教程教你如何备份存档，活用搜索引擎.</p>
</blockquote>
<p><br></p>
<h2 id="step-1利用榴石果漏洞">Step 1：利用榴石果漏洞</h2>
<p>我不打算详细介绍这一步骤，因为Metarkrai找到了这个问题的关键点，而且比我能解释得更好（当然这个漏洞已经很出名了）.
如果你想要达成双重崩溃的话，我接下来讲的一些点你必须要做到.</p>
<p><br></p>
<h3 id="正电拍拍和橡实果的要求">正电拍拍和橡实果的要求：</h3>
<figure>
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure4.png"
alt="Figure4" />
<figcaption aria-hidden="true">Figure4</figcaption>
</figure>
<p>茵郁市与NPC交换来的正电拍拍： - 需要6个 - 只习得技能叫声 -
没有打努力/只打了很少的努力</p>
<p>卡那兹市与NPC交换来的橡实果： - 需要6只 -
习得四个技能，其中最后一个技能基于你的游戏语言： 闪光（美版或德版）/
无（法版）（原文是---，不确定是否是不带技能）/ 觉醒力量（西班牙版）/
自然之力（意大利版）/ 碎岩（日版） - 努力值基于你的游戏语言：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">语言</th>
<th style="text-align: center;">物攻努力值</th>
<th style="text-align: center;">HP努力值</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">法版</td>
<td style="text-align: center;">41</td>
<td style="text-align: center;">200</td>
</tr>
<tr class="even">
<td style="text-align: center;">美版</td>
<td style="text-align: center;">41</td>
<td style="text-align: center;">192</td>
</tr>
<tr class="odd">
<td style="text-align: center;">西班牙版</td>
<td style="text-align: center;">148</td>
<td style="text-align: center;">140</td>
</tr>
<tr class="even">
<td style="text-align: center;">德版</td>
<td style="text-align: center;">41</td>
<td style="text-align: center;">201</td>
</tr>
<tr class="odd">
<td style="text-align: center;">日版</td>
<td style="text-align: center;">67</td>
<td style="text-align: center;">96</td>
</tr>
<tr class="even">
<td style="text-align: center;">意大利版</td>
<td style="text-align: center;">148</td>
<td style="text-align: center;">129</td>
</tr>
</tbody>
</table>
<blockquote>
<p>营养饮料 / 强制锻炼器 / 宝可病毒都可以帮助获得努力值</p>
</blockquote>
<p>这个漏洞在各个版本的绿宝石上都能触发，但我现在还不清楚欧版英文的所需要的努力值.
我猜测和美版是一样的，但是我不确定. 如果你知道更多信息，请<a
href="#结语">联系我</a>！</p>
<p><br></p>
<p>你需要一个正常蛋或好蛋（Good Egg, 下简称 GE），剩余的全是坏蛋（Bad
Egg, 下简称 BE）. 如果你找到了
GE，别碰它或移动它，这样你完成了第一步并可以保存了.
如果你没找到，重启游戏并重新操作直到你找到（如果你找到了复数个
GE，也需要重来）.</p>
<blockquote>
<p>译者补：作者没有将这一步具体步骤放出，请参阅以下补充的步骤.</p>
</blockquote>
<p><br></p>
<h3 id="榴石果漏洞译者补">榴石果漏洞（译者补）</h3>
<p>让有一定HP努力值的宝可梦的当前HP处于1点，再喂给该宝可梦一个榴石果（作用：降低HP努力提升亲密度），使其的HP下降两点以上，会使得该宝可梦的HP变成一个正常游戏中不可能出现的数字.</p>
<blockquote>
<p>举例来说，有一只80级的宝可梦有8点HP基础点数（努力值），HP是1/100.
对它使用榴石果后，它的HP基础点数变为0，实数值下降两点，这时它的HP变成了-1/98.
但因为游戏在这里使用的数据存储方式是无符号整数存储，HP会变成一个很大的数字，在这例子里就是65535，然后会显示为?35.</p>
</blockquote>
<p><br></p>
<h4 id="事先准备">事先准备</h4>
<p>一只级别足够高，有一些HP努力值的宝可梦，用以触发榴石果漏洞.
下面的叙述中简称A.</p>
<p>两箱子完全相同的某编号PM，以一定间隔置于1、2号两个箱子（作者使用了游戏中与npc交换得到的正电拍拍与橡实果，具体间隔参考上页图片）.
这样多数量的完全相同的宝可梦可以使用绿宝石战斗边疆的复制漏洞获得（当然也可以多开档传到同一张卡上）.
此外，箱子1、2中尽可能多地放入不重要的宝可梦，以提高GE出现率.
<strong>当然，箱子1、2中请不要放重要的宝可梦.</strong></p>
<p><br></p>
<h4 id="步骤">步骤</h4>
<ol type="1">
<li><p>将A置于队首，并控制它只剩1点HP.
带上若干只处于濒死状态的PM，最后再带上一只B. <img
src="/images/body/Battle-Pyramid-Shiny/Figure5.png"
alt="Figure5" /></p></li>
<li><p>喂给A一个榴石果(Pomeg Berry)，触发漏洞. <img
src="/images/body/Battle-Pyramid-Shiny/Figure6.png" alt="Figure6" />
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure7.png"
alt="Figure7" /> <img
src="/images/body/Battle-Pyramid-Shiny/Figure8.png"
alt="Figure8" /></p></li>
<li><p>触发与野生宝可梦的战斗，由A交换到B，然后逃跑.
（为了顺利逃跑，建议在PM等级较低的地方进行本步骤） <img
src="/images/body/Battle-Pyramid-Shiny/Figure9.png" alt="Figure9" />
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure10.png"
alt="Figure10" /> <img
src="/images/body/Battle-Pyramid-Shiny/Figure11.png"
alt="Figure11" /></p></li>
<li><p>将B存回电脑的任意一个箱子.</p></li>
<li><p>对A使用任意能够回复HP的道具，以高级伤药(Hyper Potion)为例. <img
src="/images/body/Battle-Pyramid-Shiny/Figure12.png" alt="Figure12" />
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure13.png"
alt="Figure13" /></p></li>
<li><p>再次去野外触发遇敌. <img
src="/images/body/Battle-Pyramid-Shiny/Figure14.png"
alt="Figure14" /></p></li>
<li><p>打开宝可梦菜单，查看A的状态.</p>
<p><img data-src="/images/body/Battle-Pyramid-Shiny/Figure15.png"
alt="Figure15" /> <img
src="/images/body/Battle-Pyramid-Shiny/Figure16.png"
alt="Figure16" /></p>
<blockquote>
<p>译者注：这里测试时使用的宝可梦是非法的，请不要在意</p>
</blockquote></li>
<li><p>按下方向键，直到光标正好指到“取消”（CANCEL）选项.
然后按住上方向键，直到出现下图所示的情形.
然后选择<strong>逃跑</strong>来退出战斗. <img
src="/images/body/Battle-Pyramid-Shiny/Figure17.png" alt="Figure17" />
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure18.png"
alt="Figure18" /> <img
src="/images/body/Battle-Pyramid-Shiny/Figure19.png"
alt="Figure19" /></p></li>
<li><p>如果足够幸运，你可以在1，2号箱子里的众多BE中找到一个GE，如果不够幸运，请读档重新尝试.
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure20.png"
alt="Figure20" /></p></li>
</ol>
<p><br></p>
<h3
id="绿宝石战斗边疆的复制漏洞译者补">绿宝石战斗边疆的复制漏洞（译者补）</h3>
<ol type="1">
<li>来到对战开拓区的对战塔.</li>
<li>来到电脑旁边，带上至少一只宝可梦并在电脑前存档.</li>
<li>取出要复制的宝可梦
<strong>（切忌把存档前身上带的PM换到电脑里，否则复制后那只被存到电脑里的宝可梦就会永久消失）</strong>，不要保存.</li>
<li>来到最右边的服务员前对话（实机会注意到一个明显的停顿），和她说话会有3次机会选是或否，在第三次选是否前关机或者SL.
再打开你就会发现电脑里和身上都有你想要复制的那只宝可梦.</li>
</ol>
<blockquote>
<p>注意：所有类似的柜台只有对战塔的柜台有此漏洞.</p>
</blockquote>
<p><br></p>
<h2 id="step-2二次崩溃double-corruption">Step 2：二次崩溃（Double
Corruption）</h2>
<p>a）一旦你获得了一个
GE，将这个箱子清空，留下GE和一个正电拍拍（记住！别碰
GE）坏蛋和剩下的宝可梦可以放到除了箱子1和箱子2以外的任何箱子.</p>
<p>b）将留下的那只正电拍拍放在正常的蛋 / 好蛋的左侧，并退出箱子.</p>
<figure>
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure21.png"
alt="Figure21" />
<figcaption aria-hidden="true">Figure21</figcaption>
</figure>
<p>c）保存.</p>
<p>d）再重复一遍榴石果漏洞——完全相同的方法（这会需要比第一次更多的时间，因为箱子里只有一只宝可梦来崩溃）.</p>
<p>e）最后，完成榴石果漏洞，查看PC，你会看到下面的图：</p>
<figure>
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure22.png"
alt="Figure22" />
<figcaption aria-hidden="true">Figure22</figcaption>
</figure>
<p>【这是一个在日版上成功的例子，性别与等级会根据你所玩的游戏的语言而不同】</p>
<p><img data-src="/images/body/Battle-Pyramid-Shiny/Figure23.png"
alt="Figure23" /> <img
src="/images/body/Battle-Pyramid-Shiny/Figure24.png" alt="Figure24" />
【两个失败的例子——你需要得到成功例子中的那个问号（Question Mark, 下简称
QM）——SL重来吧】</p>
<p>f）千万别拿起GE或者QM！</p>
<p>g）QM可以让你在任何地方触发及时榴石果漏洞（Instant Pomeg Glitch,
IPG），这就是我们所要的.</p>
<p>h）保存.</p>
<blockquote>
<p>译者注：经过测试，QM不能通过联机传给另外的存档，会导致另外一台游戏重启/卡死.</p>
</blockquote>
<p><br></p>
<h2 id="step-3去凯那市做好准备">Step 3：去凯那市做好准备</h2>
<p>a）按下SELECT键将PC盒子里的小手手切换成橙色（用来移动宝可梦）.</p>
<p>b）这能让你移动QM和GE
——<strong>记住只用橙色的小手手移动QM！否则你的游戏会卡住！</strong></p>
<figure>
<img data-src="/images/body/Battle-Pyramid-Shiny/Hand.png" alt="Hand" />
<figcaption aria-hidden="true">Hand</figcaption>
</figure>
<p>c）将QM和GE移到箱子1、箱子2以外的箱子里——拿起QM的方法：将橙色的手置于QM的右侧，按住A移向QM【翻译存疑，测试时发现正常拿起即可】.
如果你搞糟了或者盒子变得怪怪的，退出箱子重来一遍，这问题不大.</p>
<p>d）如果你拿起了看不到的东西，别怕 ，那是隐形的BE，而且很有用.
把它们放到你能记得住的地方.</p>
<p>e）我建议花点时间利用对战开拓区的复制漏洞多复制几个QM，因为它真的蛮有用.</p>
<p>f）这些做完后，飞去凯那市，然后去电脑前.</p>
<p>g）保存.</p>
<p>h）把QM拿出来放到队伍首位</p>
<p>i）把另外一只宝可梦拿出来放到队伍第二个位置
——<strong>你会失去它，所以斟酌选择哪只宝可梦.</strong></p>
<figure>
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure25.png"
alt="Figure25" />
<figcaption aria-hidden="true">Figure25</figcaption>
</figure>
<p>j）去宝可梦发烧友俱乐部找到记者</p>
<p><img data-src="/images/body/Battle-Pyramid-Shiny/Figure26.png"
alt="Figure26" /> <img
src="/images/body/Battle-Pyramid-Shiny/Figure27.png"
alt="Figure27" /></p>
<p>k）与她对话，然后QM会叮～【译者：?】</p>
<p>l）尽可能快地脱离对话，检查你的同行宝可梦，应该会像这样：</p>
<p><img data-src="/images/body/Battle-Pyramid-Shiny/Figure28.png"
alt="Figure28" /> <img
src="/images/body/Battle-Pyramid-Shiny/Figure29.png"
alt="Figure29" /></p>
<p>【重要：这里的显示会根据你游玩游戏的语言而不同.
日版游戏中，第二只宝可梦仍然存在，如左手边的图片.
其他版本则会显示为一个BE，如右手边的图片. 只要首位是空的，那就没问题.
】</p>
<p>m）如果不像这样，SL重试叭.</p>
<p>n）如果像这样，<strong>千万别查看详情（SUMMARY），请退出菜单</strong>.</p>
<p>o）从这里走到凯那市港口（译者注：原文是库斯诺吉造船厂）然后坐船去水静市.</p>
<p>p）到达水静市后，使用喷雾并走去狩猎地带.</p>
<p>q）保存.</p>
<p><br></p>
<h2 id="step-4ipg-time">Step 4：IPG Time</h2>
<p>a）进入狩猎地带然后走大约13步（<strong>你要尽可能地节省步数</strong>，因为狩猎地带的时间是基于你的步数的）或者至少让门口的那个NPC（门卫）在视野外.</p>
<figure>
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure30.png"
alt="Figure30" />
<figcaption aria-hidden="true">Figure30</figcaption>
</figure>
<p>b）打开宝可梦菜单，按住上键15秒——这很重要，我建议准备一个计时器.</p>
<figure>
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure31.png"
alt="Figure31" />
<figcaption aria-hidden="true">Figure31</figcaption>
</figure>
<p>【你会看到你的屏幕颜色变了（主要是红色和蓝色），别担心，按住15秒就好】</p>
<p>c）这部分的漏洞每个人耗时会不同，我尝试了4次就成功了，但实际上概率是1/32～3/32，所以耐心一些.</p>
<p>d）如果门卫没消失，SL并从Step 4：a）开始.</p>
<p>e）如果他消失了，打开你的背包.
如果你的招式学习器和树果消失了，SL并从<strong>Step
4：a）</strong>开始</p>
<p>f）如果你的招式学习器和树果没消失，但门卫消失了，那么你成功了！</p>
<figure>
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure32.png"
alt="Figure32" />
<figcaption aria-hidden="true">Figure32</figcaption>
</figure>
<p>g）从门卫消失的门那里进入狩猎地带的大厅.</p>
<p>h）当你路过的时候，工作人员会问你是否要玩狩猎地带，选否.</p>
<p>i）这会使你仍处于狩猎模式.</p>
<p>j）使用喷雾，并走（<strong>不准飞！</strong>）回水静市
——<strong>注意你的步数！</strong></p>
<figure>
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure33.png"
alt="Figure33" />
<figcaption aria-hidden="true">Figure33</figcaption>
</figure>
<p>k）坐船去对战开拓区.</p>
<p>l）走去战斗金字塔 ——<strong>再次强调，注意你的步数！</strong></p>
<figure>
<img data-src="/images/body/Battle-Pyramid-Shiny/Figure34.png"
alt="Figure34" />
<figcaption aria-hidden="true">Figure34</figcaption>
</figure>
<p>m）到达战斗金字塔后，取出三只宝可梦. 确保其中一只会甜甜香气.
（如果屏幕开始变得有些奇怪，而且你看到了漂浮着的蛋，无视这些，继续取出宝可梦）</p>
<p>n）进入战斗金字塔，选择50级或开放等级（选谁步骤都一样的），并选择刚刚取出的三只宝可梦.</p>
<p><br></p>
<h2 id="step-5该把道具骗进去了">Step 5：该把道具骗进去了</h2>
<p>a）当你打开菜单，应该会发现是狩猎地带的菜单.</p>
<p>b）如果你打开背包，你会发现是你平时的包包而不是战斗金字塔的包包，<strong>但别这么做，否则很有可能会卡死</strong>.</p>
<p>c）打开宝可梦菜单，选择“给予物品”，这会打开金字塔包包.</p>
<p>d）给两只不会甜甜香气的宝可梦随便两个金字塔包包里的物品.</p>
<p>e）然后使用甜甜香气碰三只宝可梦.</p>
<p>f）用狩猎球抓住这三只——这会填满你的队伍.</p>
<p>g）从菜单打开你平时的包包，并将第一个物品给你会甜甜香气的宝可梦.
然后你的其他五只宝可梦也是*——每次给完物品就选择关闭包包.</p>
<blockquote>
<p>作者注：如果你对此处有疑问，我推荐从<a
href="https://youtu.be/_Y6gfc3xBvc?t=1110">Metarkrai的视频</a>的18:30处开始看，这是法语视频但可以作为参考.
<br>
你如果正常按流程做下来，你的金字塔包包会有那些东西的，所以如果你有疑惑也不要紧.</p>
</blockquote>
<p>h）再给你的甜甜香气宝可梦一次物品. （应该是和c）一样的方法）</p>
<p>i）如果你尝试关闭背包，你会在金字塔包包和宝可梦菜单之间循环【？】</p>
<p>j）使用甜甜香气来跳出循环.</p>
<p>k）逃跑.</p>
<p>l）打开宝可梦菜单，将宝可梦身上的道具拿下来.</p>
<p>m）这会将物品放入你的金字塔包包.</p>
<p>n）重复上述步骤直至你把所有你想放进金字塔包包的东西都放进去.</p>
<p>o）不幸的是，你同种物品只能放入最多7个，再多的系统会自动移到原来的包包里.
（例如，你放了一轮7个大师球，你就不能再放了）</p>
<blockquote>
<p>译者注：Metarkrai对于这个原因的解释请参见原文</p>
</blockquote>
<p>p）结束前<strong>至少要放4个大师球</strong>进去.</p>
<p>我在前面列出了一些推荐放进去的物品，当然，你可以任意选择.
不过我不推荐放超过五种物品.
因为金字塔包包容量为10，而你之后还要通过金字塔，金字塔中的治疗物品又很重要.
所以留点空位叭.</p>
<p>q）当你对放进去的物品种类及数目满意之后，打开菜单选择“放弃”.</p>
<p>r）这会将你传送回狩猎地带.</p>
<p>s）走出去.</p>
<p>t）这时你金字塔包包里那些东西都在了，可以保存了.</p>
<p><br></p>
<h2 id="step-6开始刷闪">Step 6：开始刷闪！</h2>
<p>到这里你其实已经准备好了你的对战金字塔之旅. 不过注意以下几点：</p>
<ul>
<li>对战金字塔不同等级规则的包包是不同的，你放进50级规则就在50级规则的金字塔包包里，开放等级就在开放等级的金字塔包包里.</li>
<li>你每完成一轮就或者你选择休息，物品还会留在金字塔包包里.</li>
<li>你放弃或者输了，物品就会消失.</li>
<li>如果你玩的别的语言版本的游戏，记住<strong>在最后和向导说话前把你队伍中宝可梦身上的道具拿下来</strong>，否则你可能失去他们（我经常犯这个错误），然后不得不从第一轮重新来.</li>
</ul>
<p>这里我强烈推荐使用烧录卡备份存档.
当你在金字塔中输了，你不仅会失去你的物品，你还会丢失进度从第一轮重新开始.
尽管当你不用烧录卡到达了你想要刷闪的轮次，你仍要保持你的DS /
Gameboy一直开着.
因为就算你选择了休息（REST）能够保存当前进度和包包内物品，但你在一开始捕捉的三只宝可梦会丢失（下面会解释）.
如果你再用大师球抓新的宝可梦，大师球最终会用完，导致你的队伍不是满员.
这使得之前的准备毫无意义.
烧录卡还可以使得你能在每一轮结束备份你的存档，如果你输了，可以直接导回之前的存档，而不是从第一轮重新开始.
而且，你可以在你想要刷闪的轮次存档（在金字塔中途也可以备份存档），使得你不必每次都要从开始准备道具.</p>
<p>a）回到战斗金字塔并取出你要带的宝可梦.</p>
<p>b）选择之前你做了准备的等级规则（50级与开放等级）.</p>
<p>c）进去后你会发现你之前放进去的道具都在.</p>
<p>d）给你的首位宝可梦带上烟珠，其他宝可梦带上别的有用的道具.</p>
<p>e）一直玩到你想要刷闪的轮次.</p>
<p>f）备份存档. （如果你没有烧录卡或者不愿意，无视这一步）</p>
<p>g）进入你要刷闪的轮次.</p>
<p>h）选择“休息”（REST）并备份存档. （再一次，可以无视这一步）</p>
<p>i）先抓三只宝可梦——这会填满你的队伍，这样你之后抓的宝可梦都会被送去PC而不是同行.
<strong>注意，当你完成一轮 / 中途输掉 / 放弃 / 休息
都会使之后捕捉的三只宝可梦消失.</strong></p>
<p>j）注意，每当你开始刷闪，你都要导回存档重新抓三只宝可梦，这有点难受，但如果你有烧录卡备份存档的话就无所谓了.
记住要保存！如果向导强制你保存，这不会保存你后来捉到并传到箱子里的宝可梦！所以请手动存档，这样你的箱子里新的宝可梦才会被保存.</p>
<p><br></p>
<h2 id="结语">结语</h2>
<p>如果你需要任何帮助，我强烈推荐你看看Metarkrai的Pastebins和视频，因为里面会有所有你需要的信息.
不过需要的话，我也很乐意帮忙.
如果你发现了任何错误，请通过我的推特或者YouTube联系我！十分感谢！
YouTube：<span class="exturl" data-url="aHR0cHM6Ly95b3V0dWJlLmNvbS9jL29saWcx">https://youtube.com/c/olig1<i class="fa fa-external-link-alt"></i></span> 推特：<a
href="https://twitter.com/olig405"
class="uri">https://twitter.com/olig405</a></p>
<blockquote>
<p>译者注：也非常欢迎<a href="/about/">与我联系</a></p>
</blockquote>
<p><img data-src="/images/body/Battle-Pyramid-Shiny/Tail.png" /></p>
]]></content>
      <categories>
        <category>Pokemon</category>
      </categories>
      <tags>
        <tag>Pokemon</tag>
        <tag>Pomeg Glitch</tag>
        <tag>Double Corruption</tag>
      </tags>
  </entry>
  <entry>
    <title>宝可梦火红叶绿实机乱数（不包含 ID 或 Egg）</title>
    <url>/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part3/</url>
    <content><![CDATA[<p>这是宝可梦火红叶绿的实机乱数教程. 不包含 ID 与 Egg 的乱数教程.
如有纰漏，请<a href="/about/">与我联系</a>，万分感谢！</p>
<p>封面 [ID:94783450].</p>
<span id="more"></span>
<p><strong>注意，本教程仅支持：火红叶绿.</strong></p>
<p>如果你在找有电的红蓝宝石实机乱数教程，请点击<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part2/">这里</a>.
如果你在找绿宝石及没电红蓝宝石的红蓝宝石实机乱数教程，请点击<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part1/">这里</a>.</p>
<blockquote>
<p>成果展示: <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part3/Result.png"
alt="Result" /></p>
</blockquote>
<h1 id="准备工作">准备工作</h1>
<p>在开始之前，你要知道火叶乱数的难度很高，可能会花费你大几小时的时间.
请自行斟酌.</p>
<p>如果你想要乱数闪光宝可梦，你需要知道你的<a
href="https://wiki.52poke.com/wiki/ID_No.#.E9.87.8CID_No.">SID</a>.</p>
<blockquote>
<p>如果你想要乱数的是已经创建好的存档，这可能会需要你导出存档并使用
<em>PKHex</em>
等软件查看你的存档（不涉及修改与导入），请根据自身接受程度使用.（本教程默认读者使用<em>NDS</em>烧录卡进行存档提取来方便查看个体）</p>
</blockquote>
<blockquote>
<p>由于我没有怎么研究过乱数ID，所以如果你想要乱数ID，请参考：<a
href="https://www.smogon.com/ingame/rng/rs_nonbredrng#idsid">Smogon ID
乱数教程</a>.<br> 之后如果自己研究了一遍就会上传Blog.</p>
</blockquote>
<blockquote>
<p>不会导出存档？看看这篇博客：<a
href="/Pokemon/Strategies/In-Game/How-To-Back-Up-Your-Savefiles/">如何备份你的存档</a>.</p>
</blockquote>
<h2 id="硬件准备">硬件准备</h2>
<ul>
<li>能够游玩第三世代宝可梦卡带的<em>NDS</em>系列机器（初代 <em>NDS</em>
或 <em>NDS lite</em>，以下统称 <em>NDS</em>）.</li>
<li>电脑.</li>
<li><em>NDS</em>烧录卡与读卡器.</li>
</ul>
<blockquote>
<p>本教程默认读者使用<em>NDS</em>烧录卡进行存档提取来方便查看个体，如若抗拒，请参考
<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part1/">宝可梦绿宝石及没有电的红蓝宝石实机乱数（不包含
ID 或 Egg）</a> 中提及的方法（使用神奇糖果）.</p>
</blockquote>
<h2 id="下载乱数所需工具">下载乱数所需工具：</h2>
<ul>
<li>计时器<a
href="https://github.com/dylmeadows/EonTimer/releases">EonTimer</a>
如果因为国内 GitHub 下载速度原因不好下载，可以点击<a
href="/download/EonTimer.rar">这里</a>进行下载.</li>
<li>乱数工具<a
href="https://www.dropbox.com/sh/68qqg26op3uaymc/AAC8QFFKYxAqQjG80abgcHZ1a?dl=0">3genSearch</a>
国内需要科学上网，因原作者禁止二次发布所以这里不提供直接下载，可以通过各搜索引擎找到别人的分享.</li>
<li>乱数工具<a
href="https://github.com/Admiral-Fish/RNGReporter/releases">RNGReporter</a>
如果因为国内 GitHub 下载速度原因不好下载，可以点击<a
href="/download/RNGReporter.zip">这里</a>进行下载.</li>
<li>存档编辑软件<a
href="https://github.com/kwsch/PKHeX/releases">PKHex</a>
将使用其查看宝可梦的个体，不会涉及到存档修改. 如果因为国内 GitHub
下载速度原因不好下载，可以点击<a
href="/download/PKHeX(190705).zip">这里</a>进行下载（版本：19.07.05）.</li>
<li>seed查找工具<a
href="https://www.smogon.com/forums/threads/rng-manipulation-in-firered-leafgreen-wild-pok%C3%A9mon-supported-in-rng-reporter-9-93.62357/">FRLGSeedFinder</a>
如果选用3genSearch可以不用此工具. 也可以点击<a
href="/download/FRLGSeedFinder.zip">这里</a>进行下载.</li>
</ul>
<blockquote>
<p>两个乱数工具选择任意一个都可以，本教程使用的是 <em>RNGReporter</em>.
3genSearch的使用与之类似，还请读者自行探索.</p>
</blockquote>
<h2 id="了解乱数机制">了解乱数机制</h2>
<p>请参考<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part1/#了解乱数机制">宝可梦绿宝石及没有电的红蓝宝石实机乱数（不包含
ID 或 Egg）</a> 中的相应部分. 这里不同的是，火红叶绿（以下简称
<strong><em>FRLG</em></strong>）的初始 seed
极难控制，它根据进入游戏到标题画面出现 <em>PRESS START</em>
的那段时间有三次按键判定，然后根据时间、按键等因素决定初始 seed
组，最后从中选择一个初始 seed（可能有些偏差，但大体上是这个意思）.
我们需要通过等待（不进行按键操作）至游戏自动到达 <em>PRESS START</em>
界面后再按键操作，这样会跳过前两次按键判定，使得我们更容易控制初始 seed.
此外，当你在 <em>PRESS START</em> 界面按下按键 <strong>A</strong> 或
<strong>START</strong> 后，不仅初始 seed
决定了，游戏也将开始推进帧数.</p>
<h2 id="确定乱数目标">确定乱数目标</h2>
<p>请参考<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part1/#确定乱数目标">宝可梦绿宝石及没有电的红蓝宝石实机乱数（不包含
ID 或 Egg）</a> 中的相应部分. 这里我以 <em>Method 1</em>
的游戏厅宝可梦为例，甜甜香气等的 Method 没有测试，如果你测试了，还请<a
href="/about/">与我联系</a>，十分感谢.</p>
<h1 id="开始乱数">开始乱数</h1>
<h2
id="确定初始seed组并选择备用初始seed">确定初始seed组并选择备用初始seed</h2>
<ol type="1">
<li>打开 <em>EonTimer</em>
，点击红色框来选择第三世代，在蓝色框中填入游戏等待时间.
（大于等于35000，1000每秒. 即如果填入37000，计时器会在第37秒归零.
不建议过长，游戏会自动重启.） 其他部分不需要修改. <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part3/Figure1.png"
alt="Figure1" /></li>
<li>点击 <strong><em>Start</em></strong>
按钮的同时开始游戏(gba系列和设置过的nds是直接开机，未设置过的nds系列是在主页面点击GBA游戏图标).</li>
<li>在倒计时归 0 的同时按下 <strong>A</strong> 或 <strong>START</strong>
键. （这时应该进入 游戏选择存档进入界面）</li>
<li>进入游戏，任意获得一只宝可梦后存档并关机（越快越好），这里建议在游戏厅内兑换凯西.</li>
<li>重复步骤2~4，重复的次数建议在30次左右.</li>
<li>使用 NDS烧录卡 提取游戏存档后使用 PKHex 打开.</li>
<li>选择一只你获得的宝可梦，右击选择 <em>查看</em> 并选择左侧选项卡的
<em>数值</em>. <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part3/Figure2.png"
alt="Figure2" /></li>
<li>打开乱数工具<em>RNGReport</em>，选择顶部 <strong>4th Gen
Tools</strong> 菜单栏，选择第一项 <em>Calculate PID from IVs</em>.</li>
<li>输入个体性格与你的ID，点击<em>Find</em>，选择<strong>PID</strong>对应的一栏.
<img data-src="/images/body/Pokemon-RNG-Abuse-Gen3-Part3/Figure3.png"
alt="Figure3" /></li>
<li>将得到的seed输入工具<em>FRLGSeedFinder</em>中，得到初始seed（4位16进制数）.
<img data-src="/images/body/Pokemon-RNG-Abuse-Gen3-Part3/Figure4.png"
alt="Figure4" /></li>
<li>将得到的seed记录下来.</li>
<li>重复步骤7~11，直到获取所有你在步骤5中得到的宝可梦的初始seed.</li>
<li>这样你就得到了步骤1中确定的游戏等待时间所对应的初始seed组.</li>
<li>从中选择出现频率最高的几个初始seed作为备用初始 seed.
（如果第n高与第n+1高的seed出现频率差别较大，那么就选择到第n个）</li>
</ol>
<blockquote>
<p>我在测试时记录的草稿，见<a href="#Appendix">附录</a>.</p>
</blockquote>
<h2 id="搜索目标宝可梦">搜索目标宝可梦</h2>
<p>回到乱数工具首页，选择/填入图中红框中内容： <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part3/Figure5.png"
alt="Figure5" /></p>
<ol type="1">
<li><p><em>Method</em> 选择之前确定的 <em>Method</em>.</p></li>
<li><p>根据你想要的宝可梦个体、性格、性别等填入信息，如果想要闪光请填入你的
<strong>ID</strong> 与 <strong>SID</strong>，并勾选 <em>Shiny Only</em>.
如果你使用甜甜香气，你还需要选择 <em>Encounter Slot</em>
项，点击顶部菜单项 <strong>3th Gen Tools</strong> 选择对应游戏版本的
<em>Encounter Table</em>，来查看你想要的宝可梦属于什么 <em>Encounter
Slot</em>.（可能需要科学上网） 你也可以借助 <em>3genSearch</em>
工具来查看.</p></li>
<li><p>输入之前得到的初期 seed.</p></li>
<li><p><em>Start Frame</em>为开始帧，<em>Max
Results</em>为显示的结果数，即你的搜索范围是<em>Start Frame</em> ~
<em>Start Frame</em> + <em>Max
Results</em>.（强烈建议选择两分钟以内的，即7200帧以内）</p></li>
<li><p>点击<em>Generate</em>，得到结果.</p></li>
<li><p>重复步骤1~5，将所有备用初始 seed 全部检索完后选择最合适的 seed 与
Frame 作为目标初始 seed 与目标帧.（这里以 seed: AAA2，Frame:
1499为例）</p></li>
<li><p>注意，<em>RNGReporter</em>的起始Frame与<em>FRLGSeedFinder</em>不同，请-1后当作结果（即这里目标帧不是1499，而是1498）</p>
<blockquote>
<p>没有想要的宝可梦或者闪帧太靠后了怎么办？<br> 回到 <a
href="#确定初始seed组并选择备用初始seed">确定初始seed组并选择备用初始seed</a>步骤，并在第一步选择一个不同的游戏等待时间（或者赌一下初始
seed 组中备用初始 seed 以外的 seed）.</p>
</blockquote></li>
<li><p>将目标帧填入 <em>EonTimer</em> 中的 <strong>Target Frame</strong>
栏.</p></li>
</ol>
<h2 id="校准误差">校准误差</h2>
<p><strong><em>如果你的目标宝可梦不是野外宝可梦（如定点宝可梦），那么要在步骤1结束后，将存档备份</em></strong></p>
<ol type="1">
<li><p>在游戏中你应该存档的位置存档（如果你准备在洞穴或是能出现宝可梦的建筑中使用甜甜香气，请往深处走一些距离，否则甜甜香气可能会失效），存档完成后关机.</p></li>
<li><p>点击计时器 <strong><em>Start</em></strong>
按钮的同时开始游戏(设置过的nds是直接开机，未设置过的nds系列是在主页面点击GBA游戏图标).</p></li>
<li><p>在计时器的第一次倒计时归零的瞬间按下机器的
<strong><em>A</em></strong> 或 <strong><em>Start</em></strong>
键，然后快速到达目标帧的确定位置（如：在选择宝可梦使用甜甜香气的界面）.</p></li>
<li><p>在计时器的第二次倒计时归零的瞬间按下机器的
<strong><em>A</em></strong>
键，然后等待进入战斗界面后捕捉这只宝可梦，保存并关闭游戏.
（游戏厅等是直接获取）</p></li>
<li><p>执行<a
href="#确定初始seed组并选择备用初始seed">确定初始seed组并选择备用初始seed</a>中的步骤6~10，你在得到的
seed 前还会得到该 seed 前的一串数字，那是你击中的帧数，记为
<em>击中帧</em>.
（如果seed不是你的初始seed也没关系，这很正常，我们这一步只为了校准误差）</p></li>
<li><p>回到计时器，计算<em>目标帧</em>减去<em>击中帧</em>的值，将其加上<em>目标帧</em>的值得到新的目标帧，将其替换计时器的
<strong>Target Frame</strong> 栏.</p>
<blockquote>
<p>例如 目标帧 是1498，击中帧是1398，1498 - 1398 = 100，那么将 Target
Frame 中的值更新为 1498 + 100 = 1598.</p>
</blockquote></li>
</ol>
<p>误差校准完成.</p>
<blockquote>
<p>注意，如果你更换了目标，即目标帧有较大变动或者宝可梦获得方式改变（如Method不同
或 由游戏厅切换为卡比兽），请重新进行误差校准！</p>
</blockquote>
<h2 id="乱数">乱数</h2>
<p><strong><em>如果你的目标宝可梦不是野外宝可梦（如定点宝可梦），那么要先将备份存档恢复</em></strong>
和校准误差的3、4步类似： 1. 在计时器的第一次倒计时归零的瞬间按下机器的
<strong><em>A</em></strong> 或 <strong><em>Start</em></strong>
键，然后快速到达目标帧的确定位置（如：在选择宝可梦使用甜甜香气的界面）.
2. 在计时器的第二次倒计时归零的瞬间按下机器的
<strong><em>A</em></strong>
键，然后等待进入战斗界面（游戏厅等是直接获取）. 3.
如果得到的不是<em>目标帧</em>，不要保存，关闭游戏重复步骤1~2. 4.
尝试较多次数仍失败的话，可以选择再次进行误差校准.</p>
<blockquote>
<p>因为手工操作的误差与火叶机制的特殊性，建议尝试大几十次，再考虑重新校准误差.</p>
</blockquote>
<ol start="5" type="1">
<li>乱数成功，得到目标！</li>
</ol>
<h1 id="写在后面">写在后面</h1>
<ul>
<li><p>还有一种比较麻烦的方法，在这里描述一下，十分费时费力，就不展开说了：</p>
<ul>
<li>准备大量的神奇糖果.</li>
<li>使用玩家自制的软件 <a
href="https://www.smogon.com/forums/threads/fr-lg-rng-timer.3554964/">FR/LG
RNG Timer</a>. 也可以点击<a
href="/download/FRLG_RNG_Timer.jar">这里</a>进行下载.</li>
<li>进入游戏的同时开始计时器.</li>
<li>捕捉一只宝可梦并通过糖果确定个体.</li>
<li>使用个体查出初始seed.</li>
<li>查找该seed下满意的宝可梦，将目标帧数输入 FR/LG RNG Timer 点击
Submit.</li>
<li>游戏推进到等待生成帧.</li>
<li>倒计时结束触发生成帧.</li>
<li>捕捉并通过糖果确认个体.</li>
<li>利用个体查找击中帧数，记录校准值.</li>
<li>利用校准值再来一次.</li>
</ul></li>
</ul>
<p><strong><em>十分不建议使用这种方法，在FRLG中，经常出现跳过奇数帧或偶数帧的情况，触发条件暂时还未知（不操作不影响），所以这个方法极难成功.</em></strong></p>
<h1 id="reference">Reference</h1>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cuc21vZ29uLmNvbS9pbmdhbWUvcm5nLw==">Smogon RNG
教程<i class="fa fa-external-link-alt"></i></span></li>
<li><a
href="https://www.smogon.com/forums/threads/rng-manipulation-in-firered-leafgreen-wild-pok%C3%A9mon-supported-in-rng-reporter-9-93.62357/">RNG
Manipulation in FireRed/LeafGreen: Wild Pokémon Supported in RNG
Reporter 9.93</a></li>
<li><a
href="https://www.smogon.com/forums/threads/fr-lg-rng-timer.3554964/">Programming
- FR/LG RNG Timer</a></li>
</ul>
<h1 id="appendix">Appendix</h1>
<ul>
<li>Draft <img data-src="/images/body/Pokemon-RNG-Abuse-Gen3-Part3/Draft.png"
alt="Draft" /></li>
</ul>
]]></content>
      <categories>
        <category>Pokemon</category>
      </categories>
      <tags>
        <tag>Pokemon</tag>
        <tag>Pokemon-RNG-Abuse</tag>
        <tag>Pokemon-Gen3</tag>
      </tags>
  </entry>
  <entry>
    <title>willkyu的宝可梦计划</title>
    <url>/Pokemon/PokeSchedule/</url>
    <content><![CDATA[<p>使用 <em>CheckBox</em> 记录宝可梦各世代的目标以及完成情况.
你可以将这篇当作<strong>各版本要素整理</strong>.
如果还有什么有意思的要素欢迎<a href="/about/">与我联系</a>.</p>
<p>封面 [ID:94230956].</p>
<span id="more"></span>
<blockquote>
<p>未完成. 之后将细化正作部分与补充旁支部分.</p>
</blockquote>
<h1 id="总览">总览</h1>
<h2 id="第三世代">第三世代</h2>
<h3 id="宝可梦红宝石">宝可梦红宝石</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
喜欢的ID: 02233</li>
<li><input type="checkbox" disabled="" checked="" />
通关联盟</li>
<li><input type="checkbox" disabled="" checked="" />
50级对战塔50+连胜: 当前63，最高63</li>
<li><input type="checkbox" disabled="" />
100级对战塔50+连胜</li>
<li><input type="checkbox" disabled="" checked="" />
研究华丽大赛</li>
<li><input type="checkbox" disabled="" />
研究制作宝可方块</li>
<li><input type="checkbox" disabled="" />
盒子皮肤全收集</li>
<li><input type="checkbox" disabled="" />
完成丰缘图鉴</li>
<li><input type="checkbox" disabled="" />
完成全国图鉴</li>
<li><input type="checkbox" disabled="" />
装饰秘密基地</li>
<li><input type="checkbox" disabled="" />
满级训练师卡片</li>
<li><input type="checkbox" disabled="" />
游戏时间999:59</li>
</ul>
<hr />
<h3 id="宝可梦蓝宝石">宝可梦蓝宝石</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<h3 id="宝可梦火红">宝可梦火红</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<h3 id="宝可梦叶绿">宝可梦叶绿</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
喜欢的ID: 07411</li>
<li><input type="checkbox" disabled="" checked="" />
通关联盟</li>
<li><input type="checkbox" disabled="" />
给宝可梦拍照</li>
<li><input type="checkbox" disabled="" />
盒子皮肤全收集</li>
<li><input type="checkbox" disabled="" />
完成关都全图鉴</li>
<li><input type="checkbox" disabled="" />
完成全国图鉴</li>
<li><input type="checkbox" disabled="" />
游玩小游戏</li>
<li><input type="checkbox" disabled="" />
游玩训练家之塔</li>
<li><input type="checkbox" disabled="" />
满级训练师卡片</li>
<li><input type="checkbox" disabled="" />
游戏时间999:59</li>
</ul>
<hr />
<h3 id="宝可梦绿宝石">宝可梦绿宝石</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<hr />
<hr />
<h2 id="第四世代">第四世代</h2>
<h3 id="宝可梦珍珠">宝可梦珍珠</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<h3 id="宝可梦钻石">宝可梦钻石</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
喜欢的ID</li>
<li><input type="checkbox" disabled="" />
通关联盟</li>
<li><input type="checkbox" disabled="" />
研究华丽大赛</li>
<li><input type="checkbox" disabled="" />
研究连锁机制</li>
<li><input type="checkbox" disabled="" />
研究地下世界</li>
<li><input type="checkbox" disabled="" />
研究宝芬</li>
<li><input type="checkbox" disabled="" />
集齐饰品</li>
<li><input type="checkbox" disabled="" />
盒子皮肤全收集</li>
<li><input type="checkbox" disabled="" />
绘制签名，更换联机形象</li>
<li><input type="checkbox" disabled="" />
对战塔100+连胜</li>
<li><input type="checkbox" disabled="" />
完成神奥图鉴</li>
<li><input type="checkbox" disabled="" />
完成全国图鉴</li>
<li><input type="checkbox" disabled="" />
满级训练家卡片</li>
<li><input type="checkbox" disabled="" />
游戏时间999:59</li>
</ul>
<hr />
<h3 id="宝可梦白金">宝可梦白金</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<h3 id="宝可梦心金">宝可梦心金</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
喜欢的ID</li>
<li><input type="checkbox" disabled="" />
给宝可梦拍照（别忘了火箭队的衣服）</li>
<li><input type="checkbox" disabled="" />
通关城都联盟</li>
<li><input type="checkbox" disabled="" />
通关关都联盟</li>
<li><input type="checkbox" disabled="" />
收集闪耀的叶片</li>
<li><input type="checkbox" disabled="" />
通关宝可全能竞技赛</li>
<li><input type="checkbox" disabled="" />
绘制签名，更换联机形象</li>
<li><input type="checkbox" disabled="" />
盒子皮肤全收集</li>
<li><input type="checkbox" disabled="" />
计步器路线全收集</li>
<li><input type="checkbox" disabled="" />
对战塔100+连胜</li>
<li><input type="checkbox" disabled="" />
完成城都图鉴</li>
<li><input type="checkbox" disabled="" />
完成全国图鉴</li>
<li><input type="checkbox" disabled="" />
游玩对战开拓区</li>
<li><input type="checkbox" disabled="" />
游玩训练家之屋</li>
<li><input type="checkbox" disabled="" />
游玩格斗道场</li>
<li><input type="checkbox" disabled="" />
收集所有宝可装置号码</li>
<li><input type="checkbox" disabled="" />
满级训练家卡片</li>
<li><input type="checkbox" disabled="" />
游戏时间999:59</li>
</ul>
<hr />
<h3 id="宝可梦魂银">宝可梦魂银</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<hr />
<hr />
<h2 id="第五世代">第五世代</h2>
<h3 id="宝可梦黑">宝可梦黑</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
喜欢的ID</li>
<li><input type="checkbox" disabled="" checked="" />
通关联盟</li>
<li><input type="checkbox" disabled="" />
C装置皮肤全收集</li>
<li><input type="checkbox" disabled="" />
盒子皮肤全收集</li>
<li><input type="checkbox" disabled="" />
完成合众图鉴</li>
<li><input type="checkbox" disabled="" />
完成全国图鉴</li>
<li><input type="checkbox" disabled="" />
绘制签名，更换联机形象</li>
<li><input type="checkbox" disabled="" />
达到试炼屋<strong>大师</strong>等级</li>
<li><input type="checkbox" disabled="" />
研究释出之力</li>
<li><input type="checkbox" disabled="" />
研究宝可梦音乐剧</li>
<li><input type="checkbox" disabled="" />
获得所有宝可梦装扮道具</li>
<li><input type="checkbox" disabled="" />
研究连入</li>
<li><input type="checkbox" disabled="" />
满级训练家卡片</li>
<li><input type="checkbox" disabled="" />
游戏时间999:59</li>
</ul>
<hr />
<h3 id="宝可梦白">宝可梦白</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<h3 id="宝可梦黑2">宝可梦黑2</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<h3 id="宝可梦白2">宝可梦白2</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
喜欢的ID</li>
<li><input type="checkbox" disabled="" checked="" />
通关联盟</li>
<li><input type="checkbox" disabled="" />
C装置皮肤全收集</li>
<li><input type="checkbox" disabled="" />
盒子皮肤全收集</li>
<li><input type="checkbox" disabled="" checked="" />
完成合众图鉴</li>
<li><input type="checkbox" disabled="" checked="" />
完成全国图鉴</li>
<li><input type="checkbox" disabled="" />
绘制签名，更换联机形象</li>
<li><input type="checkbox" disabled="" />
达到试炼屋大师等级</li>
<li><input type="checkbox" disabled="" />
获得所有宝可梦装扮道具</li>
<li><input type="checkbox" disabled="" />
宝可梦好莱坞</li>
<li><input type="checkbox" disabled="" checked="" />
通关白色树洞</li>
<li><input type="checkbox" disabled="" />
奖牌全收集</li>
<li><input type="checkbox" disabled="" />
游玩PWT，收集PWT活动赠送锦标赛</li>
<li><input type="checkbox" disabled="" />
对战地铁连胜8+轮</li>
<li><input type="checkbox" disabled="" />
经营乔英大道</li>
<li><input type="checkbox" disabled="" />
满级训练家卡片</li>
<li><input type="checkbox" disabled="" />
游戏时间999:59</li>
</ul>
<hr />
<hr />
<hr />
<h2 id="第六世代">第六世代</h2>
<h3 id="宝可梦x">宝可梦X</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
喜欢的ID</li>
<li><input type="checkbox" disabled="" checked="" />
通关联盟</li>
<li><input type="checkbox" disabled="" />
盒子皮肤全收集</li>
<li><input type="checkbox" disabled="" />
完成卡洛斯中央图鉴</li>
<li><input type="checkbox" disabled="" />
完成卡洛斯海岸图鉴</li>
<li><input type="checkbox" disabled="" />
完成卡洛斯山岳图鉴</li>
<li><input type="checkbox" disabled="" />
完成全国图鉴</li>
<li><input type="checkbox" disabled="" />
集齐所有宝可梦种类的后花园</li>
<li><input type="checkbox" disabled="" />
达到对战城堡称号<strong>大公 / 女大公</strong></li>
<li><input type="checkbox" disabled="" />
达到试炼屋<strong>大师</strong>等级</li>
<li><input type="checkbox" disabled="" />
游玩对战屋</li>
<li><input type="checkbox" disabled="" />
游玩反转对战服务</li>
<li><input type="checkbox" disabled="" />
满级训练家卡片</li>
<li><input type="checkbox" disabled="" />
游戏时间999:59</li>
</ul>
<hr />
<h3 id="宝可梦y">宝可梦Y</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<h3 id="宝可梦欧米伽红宝石">宝可梦欧米伽红宝石</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
喜欢的ID: 40411</li>
<li><input type="checkbox" disabled="" />
通关联盟</li>
<li><input type="checkbox" disabled="" />
研究华丽大赛</li>
<li><input type="checkbox" disabled="" />
研究制作宝可方块</li>
<li><input type="checkbox" disabled="" />
达到试炼屋<strong>大师</strong>等级</li>
<li><input type="checkbox" disabled="" />
游玩对战屋</li>
<li><input type="checkbox" disabled="" />
游玩反转对战服务</li>
<li><input type="checkbox" disabled="" />
盒子皮肤全收集</li>
<li><input type="checkbox" disabled="" />
完成丰缘图鉴</li>
<li><input type="checkbox" disabled="" />
完成全国图鉴</li>
<li><input type="checkbox" disabled="" />
装饰秘密基地</li>
<li><input type="checkbox" disabled="" />
满级训练师卡片</li>
<li><input type="checkbox" disabled="" />
游戏时间999:59</li>
</ul>
<hr />
<h3 id="宝可梦阿尔法蓝宝石">宝可梦阿尔法蓝宝石</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<hr />
<hr />
<h2 id="第七世代">第七世代</h2>
<h3 id="宝可梦日">宝可梦日</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
喜欢的ID</li>
<li><input type="checkbox" disabled="" />
完成诸岛巡礼</li>
<li><input type="checkbox" disabled="" />
图章全收集</li>
<li><input type="checkbox" disabled="" />
将宝可梦搜寻镜升级到Ver.5</li>
<li><input type="checkbox" disabled="" />
完成美乐美乐图鉴</li>
<li><input type="checkbox" disabled="" />
完成阿卡拉图鉴</li>
<li><input type="checkbox" disabled="" />
完成乌拉乌拉图鉴</li>
<li><input type="checkbox" disabled="" />
完成波尼图鉴</li>
<li><input type="checkbox" disabled="" />
完成阿罗拉地区图鉴</li>
<li><input type="checkbox" disabled="" />
对战树50+连胜</li>
<li><input type="checkbox" disabled="" />
游玩皇家巨蛋</li>
<li><input type="checkbox" disabled="" />
将圆庆广场升级到Level 100+</li>
<li><input type="checkbox" disabled="" />
游戏时间999:59</li>
</ul>
<h3 id="宝可梦月">宝可梦月</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<h3 id="宝可梦究极之日">宝可梦究极之日</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<h3 id="宝可梦究极之月">宝可梦究极之月</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<h3 id="宝可梦lets-go皮卡丘lets-go伊布">宝可梦Let's Go！皮卡丘／Let's
Go！伊布</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
不玩</li>
</ul>
<hr />
<hr />
<hr />
<h2 id="第八世代">第八世代</h2>
<h3 id="宝可梦剑">宝可梦剑</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
通关联盟</li>
<li><input type="checkbox" disabled="" checked="" />
完成伽勒尔图鉴</li>
<li><input type="checkbox" disabled="" />
完成铠岛图鉴</li>
<li><input type="checkbox" disabled="" />
完成王冠雪原图鉴</li>
<li><input type="checkbox" disabled="" />
对战塔33+场连胜</li>
<li><input type="checkbox" disabled="" />
级别对战大师球级</li>
</ul>
<hr />
<h3 id="宝可梦盾">宝可梦盾</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
开始游戏</li>
</ul>
<hr />
<h3 id="晶灿钻石明亮珍珠">晶灿钻石／明亮珍珠</h3>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
不玩</li>
</ul>
]]></content>
      <categories>
        <category>Pokemon</category>
      </categories>
      <tags>
        <tag>Pokemon</tag>
        <tag>Schedule</tag>
      </tags>
  </entry>
  <entry>
    <title>博客个性化笔记----基于Ocean</title>
    <url>/Learning/Blog/Blog-Personalization/</url>
    <content><![CDATA[<p>记录博客在使用 <a
href="https://github.com/zhwangart/hexo-theme-ocean">Oceon</a>
主题时进行的各项改动， 根据<a
href="/Archive/The-First-Blog/">置顶◇代办◇与更新记录</a>记录的更新顺序排序.</p>
<p>封面 [ID:89138905].</p>
<span id="more"></span>
<div class="note warning"><p>注意，本博客已更换为 <a
href="https://theme-next.js.org/">NexT主题</a>.</p>
</div>
<h1 id="更新首页视频">更新首页视频</h1>
<p>在<code>/themes/ocean/source/images/ocean</code>中替换相关视频.
如果想替换文件名，打开<code>/themes/ocean/layout/_partial/ocean.ejs</code>，修改对应代码：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;div class=&quot;video-media&quot;&gt;</span><br><span class="line">  &lt;video playsinline=&quot;&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot; data-autoplay=&quot;&quot; poster=&quot;&lt;%- theme.ocean.path %&gt;ocean.png&quot;</span><br><span class="line">    x5-video-player-type=&quot;h5&quot;&gt;</span><br><span class="line">    &lt;source src=&quot;&lt;%- theme.ocean.path %&gt;ocean.mp4&quot; type=&quot;video/mp4&quot;&gt;</span><br><span class="line">    &lt;source src=&quot;&lt;%- theme.ocean.path %&gt;ocean.ogv&quot; type=&quot;video/ogg&quot;&gt;</span><br><span class="line">    &lt;source src=&quot;&lt;%- theme.ocean.path %&gt;ocean.webm&quot; type=&quot;video/webm&quot;&gt;</span><br><span class="line">    &lt;p&gt;Your user agent does not support the HTML5 Video element.&lt;/p&gt;</span><br><span class="line">  &lt;/video&gt;</span><br><span class="line">  &lt;div class=&quot;video-overlay&quot;&gt;&lt;/div&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure> 将其中的文件名改为自己的文件名即可.</p>
<h1 id="开启gallery功能">开启Gallery功能</h1>
<p>按照<a
href="https://zhwangart.com/2018/11/30/Ocean/#%E7%9B%B8%E5%86%8C">官方文档相关部分</a>进行设置.</p>
<p>添加照片:</p>
<p>打开<code>/source/gallery/index.md</code>，修改<strong>Front-matter</strong>部分：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: Gallery</span><br><span class="line">author: YourName</span><br><span class="line">albums: [</span><br><span class="line">        [&quot;address of image1&quot;,&quot;description&quot;],</span><br><span class="line">        [&quot;address of image2&quot;,&quot;description&quot;],</span><br><span class="line">        [&quot;address of image3&quot;,&quot;description&quot;],</span><br><span class="line">        ]</span><br><span class="line">#date: Date</span><br><span class="line">#type: gallery</span><br><span class="line">#layout: &quot;gallery&quot;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<p>如果操作完后无法正常显示照片，参考官方文档中的<a
href="https://zhwangart.com/2019/07/02/Ocean-Issues/#2-9-%E7%9B%B8%E5%86%8C%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD%E6%85%A2">改进图片加速方法</a>.</p>
<h1 id="新增favorites页面">新增Favorites页面</h1>
<ul>
<li><p>创建一个 <em>page</em> 命名 <em>favorites</em>：
<code>$ hexo new page favorites</code></p></li>
<li><p>在 <code>/themes/_config.yml</code> 文件新增一个菜单：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">收藏: /favorites</span><br></pre></td></tr></table></figure></p></li>
</ul>
<p>-修改 <code>/themes/ocean/source/css/_partialnavbar.styl</code>
文件中应该是第 35 行，<em>favorites</em>
，展示收藏图标，注意顺序，如果对菜单顺序不理解，看<a
href="https://zhwangart.com/2019/07/02/Ocean-Issues/#2">这里</a>. 编辑
favorites 页面，格式如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 样机 Mockups</span><br><span class="line"></span><br><span class="line">&lt;div class=&quot;card-quote&quot;&gt;</span><br><span class="line"></span><br><span class="line">&gt; ![Graphics](/images/logos/lstoreLogo.svg)</span><br><span class="line">&gt; ## Graphics</span><br><span class="line">&gt; 高质量的样机素材</span><br><span class="line">&gt; [https://www.ls.graphics](https://www.ls.graphics)</span><br><span class="line"></span><br><span class="line">&gt; ![sketchsheets](/images/logos/sketchLogo.svg)</span><br><span class="line">&gt; ## Sketchsheets</span><br><span class="line">&gt; Sketch 稿件的样机素材</span><br><span class="line">&gt; [https://sketchsheets.com](https://sketchsheets.com)</span><br><span class="line"></span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure></p>
<h1 id="更新icon">更新icon</h1>
<p>修改 <code>/themes/_config.yml</code> 文件，大约第10行:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Miscellaneous</span><br><span class="line">favicon: /filename.ico          #这里</span><br><span class="line">brand: /images/filename.png     #这里</span><br><span class="line"></span><br><span class="line"># Ocean Video</span><br><span class="line"># Because I put videos in multiple formats on the same path, I just labeled the path here.</span><br><span class="line">ocean:</span><br><span class="line">  overlay: true</span><br><span class="line">  path: /images/ocean/</span><br><span class="line">  brand: /images/filename.png   #这里</span><br></pre></td></tr></table></figure>
<p>分别将对应图片/图标放在<code>/themes/ocean/source</code>、<code>/themes/ocean/source</code>、<code>/themes/ocean/source/images</code>中.</p>
<h1 id="更新404页面.">更新404页面.</h1>
<p>直接更换<code>/themes/ocean/source/404.html</code>即可.
如果只想更换改主题404页面的图片，替换
<code>/themes/ocean/source/images/forrestgump.png</code>图片即可.</p>
<h1 id="背景添加动态线条效果">背景添加动态线条效果</h1>
<p>在<code>/Hexo/themes/ocean/layout/layout.ejs</code>文件中添加如下代码：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;!--动态线条背景--&gt;</span><br><span class="line">&lt;script type=&quot;text/javascript&quot;</span><br><span class="line">color=&quot;220,220,220&quot; opacity=&#x27;0.7&#x27; zIndex=&quot;-2&quot; count=&quot;200&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;&gt;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure></p>
<p>其中： color：表示线条颜色，三个数字分别为(R,G,B)，默认：（0,0,0）
opacity：表示线条透明度（0~1），默认：0.5 -
count：表示线条的总数量，默认：150
zIndex：表示背景的z-index属性，css属性用于控制所在层的位置，默认：-1</p>
<ul>
<li><p>如果想要实现随机线条颜色效果，将上述代码中的链接内的代码拷贝至本地，将其中添加随机生成颜色代码后引用.
然后将color参数删除. 下面是我修改的随机颜色代码.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function l() &#123;</span><br><span class="line">      var randomColor = Math.floor(Math.random() * 256) + &#x27;, &#x27; + Math.floor(Math.random() * 256) + &#x27;, &#x27; +Math.floor(Math.random() * 256)</span><br><span class="line">      var i = j(&quot;script&quot;),</span><br><span class="line">          w = i.length,</span><br><span class="line">          v = i[w - 1];</span><br><span class="line">      return &#123;</span><br><span class="line">          l: w,</span><br><span class="line">          z: o(v, &quot;zIndex&quot;, - 1),</span><br><span class="line">          o: o(v, &quot;opacity&quot;, 0.5),</span><br><span class="line">          c: o(v, &quot;color&quot;, randomColor),</span><br><span class="line">          n: o(v, &quot;count&quot;, 99)</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="添加点击特效">添加点击特效</h1>
<p>参考文章<a
href="https://blog.csdn.net/qq_43562785/article/details/109511585">纯Javascript实现鼠标点击特效（烟花特效）</a>.</p>
<p>在<code>/Hexo/themes/ocean/layout/layout.ejs</code>文件中添加如下代码：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;!-- 页面点击特效--&gt;</span><br><span class="line">&lt;script type=&quot;text/javascript&quot; src=&quot;/js/click.js&quot;&gt;&lt;/script&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
在目录<code>/themes/ocean/source/js</code>中新建文件<code>click.js</code>，填入参考文章中的代码.</p>
<ul>
<li>如果想要自定义颜色，修改代码中数组<code>const colours = ["色值1", "色值2", "色值3", "色值4", "色值5"];</code>中色值即可.</li>
</ul>
<h1 id="添加博客隐藏功能">添加博客隐藏功能</h1>
<p>参考<a
href="https://github.com/prinsss/hexo-hide-posts/blob/master/README_ZH.md">hexo-hide-posts官方文档</a></p>
<h1
id="修复category页面无法正确显示标题的错误">修复Category页面无法正确显示标题的错误</h1>
<p>研究完才发现有人已经pr过了，详见<a
href="https://github.com/zhwangart/hexo-theme-ocean/pull/35/files">修复主题关于catefories和tags页显示网页标题为underfine问题</a>.</p>
<h1 id="加入博客评论功能">加入博客评论功能</h1>
<p>详见<a
href="https://zhwangart.com/2018/11/30/Ocean/#%E8%AF%84%E8%AE%BA">Ocean官方文档相关部分</a>.
此博客仅使用了Gitalk.</p>
<h1 id="实现图片懒加载">实现图片懒加载</h1>
<p>使用Hexo插件<a
href="https://github.com/Troy-Yang/hexo-lazyload-image">hexo-lazyload-image</a>实现.
- 运行代码<code>$ npm install hexo-lazyload-image --save</code> - 在
<code>/themes/_config.yml</code> 文件末尾加上以下代码： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">lazyload:</span><br><span class="line">enable: true</span><br><span class="line">onlypost: false # optional</span><br><span class="line">loadingImg: # optional eg ./images/loading.gif 这里填写你的懒加载图片地址，请提前将其放在博客图片库中.</span><br><span class="line">isSPA: false # optional</span><br><span class="line">preloadRatio: 3 # optional, default is 1</span><br></pre></td></tr></table></figure> -
配置相关参数： - onlypost If true, only the images from post or page
will support lazy-load. If false, the whole images of your site will use
lazy-load, including the images dist from your theme, but not including
the background images from CSS style.</p>
<ul>
<li><p>loadingImg If you keep the value nothing (by default), then it
will use the default loading image. If you want to customize the image,
then you need to copy your loading image to your current theme image
folder and then change this path to find it.</p></li>
<li><p>isSPA For performance considering, isSPA is added. If your theme
is a SPA page, please set it as true to make the lazy loading works, If
true, searching for each image during scrolling to support SPA page, If
false (default value), the performance would be the best.</p></li>
<li><p>preloadRatio This option is for a better experience and default
value is 1. This ratio means to pre-load the images where is within how
many ratios than current screen size, even these images are not in
current view point.</p></li>
<li><p>取消不需要的图片懒加载 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;img no-lazy src=&quot;abc.png&quot; /&gt;</span><br></pre></td></tr></table></figure> 以 Ocean 主题为例，
修改<code>/themes/ocean/layout/_partial/ocean.ejs</code>中所有<code>&lt;img&gt;</code>标签,
修改<code>/themes/ocean/layout/_partial/sidebar.ejs</code>中所有<code>&lt;img&gt;</code>标签.</p></li>
</ul>
<h1 id="增加博客加密功能">增加博客加密功能</h1>
<p>参考<a
href="https://github.com/D0n9X1n/hexo-blog-encrypt/blob/master/ReadMe.zh.md">hexo-blog-encrypt官方文档</a>.
按钮样式修改在<code>/node_modules/hexo-blog-encrypt/lib/hbe.style.css</code>中.</p>
<h1 id="end">END</h1>
<p>如果你有什么别的更好的个性化方案，请<a
href="/about/">与我联系</a>，一同进步！</p>
]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>Blog</tag>
        <tag>Practical-Tips</tag>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
        <tag>Ocean</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch笔记10----激活函数与常见Loss</title>
    <url>/Learning/Notes/PyTorch/PyTorch10/</url>
    <content><![CDATA[<p>梯度下降，激活函数，与常见Loss</p>
<span id="more"></span>
<h1 id="梯度下降">梯度下降</h1>
<p>新值 = 当前值 - 学习率 * 梯度</p>
<ul>
<li>可能会收敛到局部极小值</li>
<li>学习率不能太大</li>
<li>逃离局部最小值：添加一个动量（惯性）</li>
<li>使用sigmoid函数当x很大的时候导数趋向于0，数据会得不到更新，这种现象叫做梯度弥散</li>
</ul>
<h1 id="一些激活函数">一些激活函数</h1>
<h2 id="sigmoid">Sigmoid</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">z = torch.linspace(-100, 100, 10)</span><br><span class="line">z   #tensor([-100.0000, -77.7778, -55.5556, -33.3333, -11.1111, 11.1111, 33.3333, 55.5556, 77.7778, 100.0000])</span><br><span class="line">torch.sigmoid(z)</span><br><span class="line">#tensor([0.0000e+00, 1.6655e-34, 7.4564e-25, 3.3382e-15, 1.4945e-05, 9.9999e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00])</span><br></pre></td></tr></table></figure>
<h2 id="tanh">tanh</h2>
<p><code>tanh(x) = 2sigmoid(2x) - 1</code> 类似sigmoid，值域(-1, 1)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.linspace(-1, 1, 10)</span><br><span class="line">torch.tanh(a)</span><br></pre></td></tr></table></figure>
<h2 id="relu-rectified-linear-unit">ReLU (Rectified Linear Unit)</h2>
<ul>
<li>使用很多，奠基石</li>
<li>减少了梯度弥散和梯度爆炸的出现</li>
<li>使用<code>torch.relu(a)</code>或<code>F.relu(a)</code>（<code>import torch.nn.functional as F</code>）</li>
</ul>
<h2 id="softmaxsoft-version-of-max">Softmax（soft version of max）</h2>
<p>输入y: [y1, y2, ..., yn] ，输出p: [p1, p2, ..., pn]且sum(p) = 1
<code>S(yi) = exp(yi) / sum(exp(y))</code> 如y:[2.0, 1.0, 0.1] ---&gt;
p: [0.7, 0.2, 0.1] 会让大的更大，小的压缩在一个更密集的空间
梯度<code>dpi_daj</code>： - i = j: <code>dpi_dai = pi * (1 - pi)</code>
&gt; 0 - i != j:<code>dpi_daj = - pj * pi</code> &lt; 0</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.rand(3)</span><br><span class="line">a.requires_grad_()</span><br><span class="line"></span><br><span class="line">p = F.softmax(a, dim = 0)</span><br><span class="line">#每次求导会将梯度信息清除</span><br><span class="line">#应该在第一次函数内加入retain_graph = True参数</span><br><span class="line"></span><br><span class="line">p = F.softmax(a, dim = 0)</span><br><span class="line">torch.autograd.grad(p[1], [a], retain_graph = True)</span><br><span class="line">#tensor([-0.0828, 0.2274, -0.1447]) 索引1为正</span><br><span class="line">torch.autograd.grad(p[2], [a])</span><br><span class="line">#tensor([-0.0979, -0.1447, 0.2425]) 索引2为正</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">p.backward()</span><br><span class="line">--------ERROR--------</span><br><span class="line">#p是向量，这样.backward()会报错</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="loss及其梯度">Loss及其梯度</h1>
<h2 id="均方差msemean-squared-error">均方差MSE（Mean Squared
Error）</h2>
<p><code>loss = sum((y - y_pred) ** 2)</code> 不是L2-norm
<code>L2-norm = sqrt(sum((y - y+pred) ** 2))</code> 可以使用norm()函数
<code>loss = norm.norm(y - y_pred, 2).pow(2)</code>
梯度：<code>dloss_dx = 2 * sum(y - y_pred) * dy_pred_dx</code></p>
<p>使用PyTorch求导 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x = torch.ones(1)</span><br><span class="line">w = torch.full([1], 2)</span><br><span class="line">mse = F.mse_loss(x * w, torch.ones(1))  #第一个参数为predict值，第二个参数为label</span><br><span class="line">#tensor(1.)</span><br><span class="line"></span><br><span class="line">torch.autograd.grad(mse, [w])</span><br><span class="line">#第一个参数y，第二个参数[x1, x2, ...]</span><br><span class="line">#tensor定义时默认不需要求导信息，所以w无法求导 </span><br><span class="line">--------ERROR--------</span><br><span class="line"></span><br><span class="line">#对w进行更新或者在定义w时加入参数requires_grad = True</span><br><span class="line">w.requires_grad_()</span><br><span class="line">    #tensor([2.], requires_grad = True)</span><br><span class="line">    #这时求梯度仍然会报错，因为PyTorch是动态图（做一步计算一步图），要先更新一下mse</span><br><span class="line">mse = F.mse_loss(x * w, torch.ones(1))</span><br><span class="line"></span><br><span class="line">torch.autograd.grad(mse, [w])   #tensor([2.])                                                                                                                 </span><br><span class="line"></span><br><span class="line">mse.backward()</span><br><span class="line">mse.grad            #tensor([2.])</span><br></pre></td></tr></table></figure></p>
<h1 id="cross-entropy-loss">Cross Entropy Loss</h1>
<p>之后介绍</p>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch笔记09----高阶OP</title>
    <url>/Learning/Notes/PyTorch/PyTorch09/</url>
    <content><![CDATA[<p>记录了PyTorch中两个高阶操作：<code>Where</code>与<code>Gather</code></p>
<span id="more"></span>
<h2 id="where">Where</h2>
<p><code>torch.where(condition, x, y)</code></p>
<p>满足condition的 返回x，否则返回y</p>
<p>x、y、condition的shape相同</p>
<p>condition矩阵: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensor([[1, 0],</span><br><span class="line">        [0, 1]])</span><br></pre></td></tr></table></figure>
那么A的地方取x对应元素，B的地方取y对应元素</p>
<h2 id="example">example</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cond        #tensor([[0.6769, 0.7271],</span><br><span class="line">                     [0.8884, 0.4163]])</span><br><span class="line">a           #tensor([[0., 0.],</span><br><span class="line">                     [0., 0.]])  </span><br><span class="line">b           #tensor([[1., 1.],</span><br><span class="line">                     [1., 1.]])</span><br><span class="line">                     </span><br><span class="line">torch.where(cond &gt; 0.5, a, b)</span><br><span class="line">#tensor([[0., 0.],</span><br><span class="line">         [0., 1.]])</span><br></pre></td></tr></table></figure>
<h2 id="gather">Gather</h2>
<p><code>torch.gather(input, dim, index, out = None)</code> &gt;
index是表，dim是查表的维度，index是需要查的index</p>
<p>查表操作，如：表[x1, x2, x3]，那么我们gather需要查的index：[0, 1, 0,
2]得到[x1, x2, x1, x3]</p>
<p>四条数据输入神经网络得到一个输出：[4, 10]
取出每条数据概率最大的index:[[1], [2], [0], [9]]
使用gather查表得到对应的元素</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">prob = torch.rand(4, 10)</span><br><span class="line">idx = prob.topk(dim = 1, k = 3)[1]</span><br><span class="line">idx</span><br><span class="line">#tensor([[7, 4, 9],</span><br><span class="line">         [8, 1, 3],</span><br><span class="line">         [2, 8, 4],</span><br><span class="line">         [8, 6, 0]])</span><br><span class="line">label = torch.arange(10) + 100</span><br><span class="line">label</span><br><span class="line">#tensor([100, 101, ..., 109])</span><br><span class="line"></span><br><span class="line">torch.gather(label.expand(4, 10), dim = 1, index = idx.long())</span><br><span class="line">#tensor([[107, 104, 109],</span><br><span class="line">         [108, 101, 103],</span><br><span class="line">         [102, 108, 104],</span><br><span class="line">         [108, 106, 100]])</span><br><span class="line">#.long()转化为LongTensor类型，不加也可以得到相同结果</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch笔记08----统计属性</title>
    <url>/Learning/Notes/PyTorch/PyTorch08/</url>
    <content><![CDATA[<p>记录了PyTorch一些常见统计属性.</p>
<span id="more"></span>
<p>常见统计属性： - norm 范数 - mean sum - prod 累乘 - min max argmin
argmax 最小/大值的位置 - kthvalue topk</p>
<h1 id="norm">norm</h1>
<p><em>不是normalize正则化</em> <em>矩阵范数与向量范数有区别的</em></p>
<p>norm-p p范数 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.full([8], 1)</span><br><span class="line">b = a.review(2, 4)</span><br><span class="line">c = a.review(2, 2, 2)</span><br><span class="line"></span><br><span class="line">a.norm(1), b.norm(1), c.norm(1)</span><br><span class="line">#tensor(8.), tensor(8.), tensor(8.)</span><br><span class="line"></span><br><span class="line">a.norm(2), b.norm(2), c.norm(2)</span><br><span class="line">#tensor(2.8284), tensor(2.8284), tensor(2.8284)</span><br><span class="line"></span><br><span class="line">b.norm(1, dim = 0)</span><br><span class="line">#tensor([4., 4.])</span><br><span class="line"></span><br><span class="line">c.norm(1, dim = 0)</span><br><span class="line">#tensor([[2, 2],</span><br><span class="line">         [2, 2]])</span><br></pre></td></tr></table></figure></p>
<h1 id="mean-sum-min-max-prod-argmax-argmin">mean / sum / min / max /
prod / argmax / argmin</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.arange(8).view(2, 4).float()</span><br><span class="line">#tensor([[0, 1, 2, 3],</span><br><span class="line">         [4, 5, 6, 7]])</span><br><span class="line">         </span><br><span class="line">a.min(), a.max(), a.mean(), a.prod(), a.sum()</span><br><span class="line">#tensor(0.), tensor(7.), tensor(3.5000), tensor(0.), tensor(28.)</span><br><span class="line"></span><br><span class="line">a.max(dim = 1)</span><br><span class="line">#tensor([3., 7.]), tensor([3, 3])</span><br><span class="line"></span><br><span class="line">a.argmax(), a.argmin()</span><br><span class="line">#tensor(7), tensor(0) 会将tesor打平后求max、min索引</span><br><span class="line"></span><br><span class="line">a.argmax(dim = 1)</span><br><span class="line">#tensor([3, 3])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="dim-keepdim">dim / keepdim</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.rand(4, 10)</span><br><span class="line">a.max(dim = 1)</span><br><span class="line">#tensor([0.8362, 1.7015, 1.1297, 0.6386]), tensor([3, 8, 6, 4])</span><br><span class="line"></span><br><span class="line">a.max(dim = 1, keepdim = True)  #dim与原tensor保持一致</span><br><span class="line">#tensor([[0.8362],</span><br><span class="line">         [1.7015],</span><br><span class="line">         [1.1297],</span><br><span class="line">         [0.6386]]), tensor([[3],</span><br><span class="line">                             [8],</span><br><span class="line">                             [6],</span><br><span class="line">                             [4]])</span><br><span class="line">                             </span><br><span class="line">a.argmax(dim = 1, keepdim = True)</span><br><span class="line">#tensor([[3],</span><br><span class="line">         [8],</span><br><span class="line">         [6],</span><br><span class="line">         [4]])</span><br></pre></td></tr></table></figure>
<h1 id="top-k-k-th">top-k / k-th</h1>
<ul>
<li>top-k 返回最大的k个数和其索引</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.randn(4, 10)</span><br><span class="line">a.topk(3, dim = 1)</span><br><span class="line">#tensor([[0.8362, 0.3913, -0.1830],</span><br><span class="line">         [1.7832, 1.4828,  1.2393],</span><br><span class="line">         [0.6392, 0.3824,  0.2227],</span><br><span class="line">         [0.9928, 0.1215, -0.3927]]), tensor([[3, 8, 9],</span><br><span class="line">         [8, 6, 5],</span><br><span class="line">         [2, 3, 6],</span><br><span class="line">         [5, 7, 9]])</span><br><span class="line"> </span><br><span class="line">a.topk(3, dim = 1, largest = false)    #返回最小的k个</span><br></pre></td></tr></table></figure>
<ul>
<li>kthvalue</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a.kthvalue(8, dim = 1)</span><br><span class="line">#tensor([-0.1830, 1.2393, 0.2227, -0.3927]), tensor([9, 5, 6, 9])</span><br><span class="line">#返回第8小的元素及其索引（在这里是第3大）</span><br><span class="line">a.kthvalue(8)       #结果同上</span><br></pre></td></tr></table></figure>
<h1 id="compare">compare</h1>
<blockquote>
<p>&gt;, &gt;=, &lt;, &lt;=, !=, == <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a &gt; 0</span><br><span class="line">#tensor([[0, 0, 0, 1, ...],</span><br><span class="line">         [0, 0, 0, 0, ...],</span><br><span class="line">         [0, 1, 1, 0, ...],</span><br><span class="line">         [0, 0, 0, 0, ...]])</span><br><span class="line">torch.gt(a, 0)  #结果同上</span><br><span class="line"></span><br><span class="line">b = rand(2, 2)</span><br><span class="line">torch.eq(b, b)</span><br><span class="line">#tensor([[1, 1],</span><br><span class="line">         [1, 1]])</span><br><span class="line">torch.equal(b, b)</span><br><span class="line">#True</span><br></pre></td></tr></table></figure></p>
</blockquote>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch笔记07----基本运算</title>
    <url>/Learning/Notes/PyTorch/PyTorch07/</url>
    <content><![CDATA[<p>PyTorch的一些基本运算</p>
<span id="more"></span>
<ul>
<li>add / minus / multiply / divide</li>
<li>matmul</li>
<li>pow</li>
<li>sqrt / rsqrt</li>
<li>round</li>
</ul>
<h1 id="basic">basic</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.rand(3, 4)</span><br><span class="line">b = torch.rand(4)</span><br><span class="line"></span><br><span class="line">torch.all(torch.eq(a + b, torch.add(a, b))) #tensor(True)</span><br><span class="line"></span><br><span class="line">torch.all(torch.eq(a - b, torch.sub(a, b))) #tensor(True)</span><br><span class="line"></span><br><span class="line">torch.all(torch.eq(a * b, torch.mul(a, b))) #tensor(True)</span><br><span class="line"></span><br><span class="line">torch.all(torch.eq(a / b, torch.div(a, b))) #tensor(True)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>//</code>是整除</p>
</blockquote>
<h1 id="matmul-矩阵乘法">matmul 矩阵乘法</h1>
<ul>
<li><code>torch.mm</code> only for 2d，因此不推荐</li>
<li><code>torch.matmul</code> 或 <code>@</code></li>
</ul>
<blockquote>
<p><code>*</code>是相同位置元素相乘，<code>.matmul</code>是矩阵乘法</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a                   #tensor([[3., 3.],</span><br><span class="line">                             [3., 3.]])</span><br><span class="line">b = torch.ones(2, 2)</span><br><span class="line"></span><br><span class="line">torch.mm(a, b)      #tensor([[6., 6.],</span><br><span class="line">                             [6., 6.]])</span><br><span class="line">                             </span><br><span class="line">torch.matmul(a, b)</span><br><span class="line">a @ b</span><br><span class="line">#结果相同     </span><br></pre></td></tr></table></figure>
<h2 id="example">example</h2>
<p>神经网络线性层的相加 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.rand(4, 784)</span><br><span class="line">x = torch.rand(4, 784)</span><br><span class="line"></span><br><span class="line">w = torch.rand(512, 784)    #降维，把784降到512</span><br><span class="line"># 默认是[channel-out, channel-in]</span><br><span class="line"></span><br><span class="line">(x @ w.t()).shape           #tensor.Size([4, 512])</span><br><span class="line">#如果w是高维的，使用transpose交换</span><br></pre></td></tr></table></figure></p>
<h2 id="tensor-matmul">tensor matmul</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.rand(4, 3, 28, 64)</span><br><span class="line">b = torch.rand(4, 3, 64, 32)</span><br><span class="line"></span><br><span class="line">torch.mm(a, b).shape</span><br><span class="line">--------ERROR--------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">torch.matmul(a, b).shape        #tensor.Size([4, 3, 28, 32]) 只用最后两维运算，前面的不变</span><br><span class="line"></span><br><span class="line">b = torch.rand(4, 1, 64, 32)</span><br><span class="line">torch.matmul(a, b).shape        #tensor.Size([4, 3, 28, 32]) 使用了broadcast机制</span><br><span class="line"></span><br><span class="line">b = torch.rand(2, 64, 32)</span><br><span class="line">torch.matmul(a, b).shape</span><br><span class="line">--------ERROR--------</span><br></pre></td></tr></table></figure>
<h1 id="power-sqrt-rsqrt">power / sqrt / rsqrt</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.full([2, 2], 3)</span><br><span class="line">a.power(2)      #tensor([[9., 9.],</span><br><span class="line">                         [9., 9.]])</span><br><span class="line">a ** 2          #结果相同</span><br><span class="line"></span><br><span class="line">aa = a ** 2</span><br><span class="line">aa.sqrt()       #tensor([[3., 3.],</span><br><span class="line">                         [3., 3.]])</span><br><span class="line">aa.rsqrt()      #tensor([[0.3333, 0.3333],</span><br><span class="line">                         [0.3333, 0.3333]])</span><br><span class="line">#是sqrt的倒数</span><br><span class="line"></span><br><span class="line">a ** 0.5        #同sqrt()</span><br><span class="line">```                         </span><br><span class="line"></span><br><span class="line"># exp / log</span><br></pre></td></tr></table></figure>
<p>a = torch.exp(torch.ones(2, 2)) a #tensor([[2.7183, 2.7183], [2.7183,
2.7183]])</p>
<p>torch.log(a) #tensor([[1., 1.], [1., 1.]])
#默认以e为底，还可使用log2()、log10() <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"># approximation 近似值</span><br><span class="line">- `.floor()` / `.ceil()` 向下取整与向上取整</span><br><span class="line">- `.round()` 四舍五入</span><br><span class="line">- `.trunc()` / `.frac()` 整数部分与小数部分</span><br><span class="line"></span><br><span class="line"># clamp 裁剪</span><br><span class="line">- gradient clipping 梯度裁剪（梯度弥散、梯度爆炸）</span><br><span class="line">&gt; 时不时要打印梯度的模`w.grad.norm(2)`</span><br><span class="line"></span><br></pre></td></tr></table></figure> grad = torch.rand(2,
3) * 15 grad #tensor([[14.8737, 10.1571, 4.4872], [11.3591, 8.9101,
14.0524]])</p>
<p>grad.max() #tensor(14.8737) grad.median() #tensor(10.1571) 中间值</p>
<p>grad.clamp(10) #将grad中的小于10的部分变为10 #tensor([[14.8737,
10.1571, 10.0000], [11.3591, 10.0000, 14.0524]])</p>
<p>grad.clamp(0, 10) #将grad中的数据设置为0～10直接，超出算10，小于算0
#tensor([[10.0000, 10.0000, 4.4872], [10.0000, 8.9101, 10.0000]])
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">梯度裁剪：</span><br></pre></td></tr></table></figure> for w in [] #wlist clamp(w.grad, 10) ```</p>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch笔记06----拼接与拆分</title>
    <url>/Learning/Notes/PyTorch/PyTorch06/</url>
    <content><![CDATA[<p>Tensor的拼接与拆分操作</p>
<span id="more"></span>
<ul>
<li>Cat</li>
<li>Stack</li>
<li>Split</li>
<li>Chunk</li>
</ul>
<h1 id="cat">cat</h1>
<p>Statisics about scores - [class1-4, students, scores] - [class5-9,
students, scores]</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.rand(4, 32, 8)</span><br><span class="line">b = torch.rand(5, 32, 8)</span><br><span class="line"></span><br><span class="line">torch.cat([a, b], dim = 0).shape</span><br><span class="line">#torch.Size([9, 32, 8])</span><br><span class="line">#第一个参数是一个list，包含了所有需要拼接的Tensor</span><br><span class="line">#第二个参数dim决定了合并的维度</span><br><span class="line">#其他维度要一样</span><br><span class="line">c = torch.rand(3, 32, 1)</span><br><span class="line">torch.cat([a, c], dim = 0).shape</span><br><span class="line">--------ERROR--------</span><br></pre></td></tr></table></figure>
<h1 id="stack">stack</h1>
<p>create new dim <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.rand(32, 8)</span><br><span class="line">b = torch.rand(32, 8)</span><br><span class="line"></span><br><span class="line">torch.stack([a, b], dim = 0).shape</span><br><span class="line">#torch.Size([2, 32, 8])</span><br><span class="line">torch.stack([a, b], dim = 1).shape</span><br><span class="line">#torch.Size([32, 2, 8])</span><br></pre></td></tr></table></figure> 例如一个老师统计了一个班的成绩:
[students, scores]，另一个老师也是，那么使用stack得到[2, students,
scores]，而不是把students那一维度拼接起来</p>
<p><strong>stack必须维度一致</strong> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.rand(30, 8)</span><br><span class="line">b = torch.rand(32, 8)</span><br><span class="line">torch.stack([a, b], dim = 0)</span><br><span class="line">--------ERROR--------</span><br></pre></td></tr></table></figure></p>
<h1 id="split-by-len">split: by len</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">b = torch.rand(32, 8)</span><br><span class="line">a.shape     #torch.Size([32, 8])</span><br><span class="line">c = torch.stack([a, b], dim = 0)</span><br><span class="line">c.shape     #torch.Size([2, 32, 8])</span><br><span class="line"></span><br><span class="line">aa, bb = c.split(1, dim = 0)    #第一个参数是长度</span><br><span class="line">aa.shape, bb.shape</span><br><span class="line">#torch.Size([1, 32, 8]), torch.Size([1, 32, 8])</span><br><span class="line"></span><br><span class="line">aa, bb = c.split([1, 1], dim = 0)   #第一个参数是长度的list</span><br><span class="line">#结果同上</span><br><span class="line"></span><br><span class="line">aa, bb = c.split(2, dim = 0)</span><br><span class="line">-------ERROR--------</span><br></pre></td></tr></table></figure>
<h1 id="chunk-by-num">chunk: by num</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">b = torch.rand(32, 8)</span><br><span class="line">a.shape     #torch.Size([32, 8])</span><br><span class="line">c = torch.stack([a, b], dim = 0)</span><br><span class="line">c.shape     #torch.Size([2, 32, 8])</span><br><span class="line"></span><br><span class="line">aa, bb = c.chunk(2, dim = 0)    #平均分成2块</span><br><span class="line">aa.shape, bb.shape</span><br><span class="line">#torch.Size([1, 32, 8]), torch.Size([1, 32, 8])</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch笔记05----Broadcast自动扩展</title>
    <url>/Learning/Notes/PyTorch/PyTorch05/</url>
    <content><![CDATA[<p>PyTorch的自动扩展</p>
<span id="more"></span>
<ul>
<li>Expand，可以维度扩展</li>
<li>without copying data，扩展时不用拷贝数据，能节省空间</li>
</ul>
<h1 id="key-idea">Key idea</h1>
<ul>
<li>Insert 1 dim ahead</li>
<li>Expand dims with size 1 to same size</li>
</ul>
<p>Feature maps: [4, 32, 14, 14] Bias: [32] --&gt; [32, 1, 1] --&gt; [1,
32, 1, 1] --&gt; [4, 32, 14, 14]</p>
<p>Broadcast示意图： <img data-src="/images/body/PyTorch/PyTorch05.png"
alt="Figure1" /></p>
<h1 id="why-broadcasting">Why broadcasting</h1>
<ol type="1">
<li>for actual demanding
<ul>
<li>[class, student, scores]</li>
<li>Add bias for every students: +5 score</li>
<li>[4, 32, 8] + [5.0] (标量)</li>
<li><code>bias.unsqueeze(0).unsqueeze(0).expand_as(A)</code></li>
</ul></li>
<li>memory consumption 节省内存消耗</li>
</ol>
<h1 id="is-it-broadcasting-able">Is it broadcasting-able?</h1>
<h2
id="match-from-last-dim-从最后一维匹配一般最后一维是物理意义上的小维度">Match
from <strong>Last</strong> dim
从最后一维匹配（一般最后一维是物理意义上的小维度）</h2>
<ul>
<li>If current dim = 1, expand to same</li>
<li>If either has no dim, insert one dim and expand to same</li>
<li>otherwise, NOT broadcasting-able</li>
</ul>
<blockquote>
<p>例如[8, 32, 8]（8个班，每班32个学生，每个学生修八门课即八个成绩）bias
= [5]是 [1]的shape，对八门课都要加，对每个班每个学生都适用 --&gt; [1, 1,
1] ---&gt; [32, 32, 8]</p>
</blockquote>
<blockquote>
<p>如果仅对某一门课的成绩添加bias，那么bias = [0, 0, 5, ..., 0]是
[8]的shape，每个班每个学生都适用 --&gt; [1, 1, 8] --&gt; [32, 32, 8]</p>
</blockquote>
<blockquote>
<p>A: [4, 32, 8], bias: [4] NOT broadcasting-able</p>
</blockquote>
<h1 id="situation">Situation</h1>
<h2 id="situation-1">Situation 1</h2>
<p>A: [4, 32, 14, 14] B: [1, 32, 1, 1] --&gt; [4, 32, 14, 14]</p>
<h2 id="situation-2">Situation 2</h2>
<p>A: [4, 32, 14, 14] B: [14, 14] --&gt; [1, 1, 14, 14] --&gt; [4, 32,
14, 14]</p>
<h2 id="situation-3">Situation 3</h2>
<p>A: [4, 32, 14, 14] B: [2, 32, 14, 14] NOT broadcasting-able</p>
<h1 id="how-to-understand-this-behavior">How to understand this
behavior?</h1>
<h2 id="when-it-has-no-dim">When it has no dim</h2>
<ul>
<li>treat it as all own the same</li>
<li>[class, student, scores] + [scores]</li>
</ul>
<h2 id="when-it-has-dim-of-size-1">When it has dim of size 1</h2>
<ul>
<li>treat it shared by all</li>
<li>[class, student, scores] + [student, 1]（a学生所有课程 +
0，b学生所有课程 + 1 ...这种情况）</li>
</ul>
<p><strong><em>match from LAST dim</em></strong></p>
<p>+ [1, 1, 1, 1] 等价 + [1]</p>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>如何自制宝可梦Gen4与Gen5的配信器</title>
    <url>/Pokemon/Strategies/In-Game/WCD-Distribution-Patch/</url>
    <content><![CDATA[<p>这是宝可梦自制四五代配信器的教程. 如有纰漏，请<a
href="/about/">与我联系</a>，万分感谢！</p>
<p>封面 [ID:84354949].</p>
<span id="more"></span>
<p><strong>注意，本教程仅支持<a
href="https://wiki.52poke.com/wiki/%E7%AC%AC%E5%9B%9B%E4%B8%96%E4%BB%A3">宝可梦第四世代</a>正作游戏与<a
href="https://wiki.52poke.com/wiki/%E7%AC%AC%E4%BA%94%E4%B8%96%E4%BB%A3">宝可梦第五世代</a>正作游戏.</strong></p>
<p>如果你在找<a
href="https://wiki.52poke.com/wiki/%E7%AC%AC%E4%B8%89%E4%B8%96%E4%BB%A3">宝可梦第三世代</a>的船票配信方法，请点击<a
href="https://github.com/mrhappyasthma/NDSEventTool.nds">这里</a>.</p>
<h1 id="准备工作">准备工作</h1>
<p><strong>请确保你了解一些计算机基础知识</strong></p>
<h2 id="硬件准备">硬件准备</h2>
<ul>
<li>能够游玩第四、五世代宝可梦卡带的<em>NDS</em>、<em>3DS</em>系列机器<strong>两台</strong>（以下简称
<em>DS</em> 系列掌机）.</li>
<li>电脑.</li>
<li><em>NDS</em>烧录卡与读卡器.</li>
</ul>
<h2 id="下载配信所需工具">下载配信所需工具：</h2>
<ul>
<li><p>四代<a
href="https://gbatemp.net/threads/wcdpatcher.129568/">WCDPatcher</a>
上面帖子里的下载地址失效了，可以点击<a
href="https://projectpokemon.org/home/files/file/1808-pok%C3%A9mon-wcd-patcher/">这里</a>下载.</p></li>
<li><p><a
href="https://projectpokemon.org/home/files/category/2-event-gallery/">你想要的配信的Mystery
Gift and Wonder Card files</a></p></li>
<li><p>或者点击<a
href="/download/WCD-Distribution-Patch.rar">这里</a>下载由b站用户<a
href="https://space.bilibili.com/3691432">翾樾non</a>整理的自制配信器所需的所有文件.
&gt;
很遗憾我没有找到他这里第五世代的<code>LTDCE.exe</code>文件的发布网站，但找到了另外一个第五世代配信器制作软件<a
href="https://github.com/PlasticJustice/PKMG5DC">PKMG5DC</a>，感兴趣的话可以自行研究一下</p></li>
</ul>
<blockquote>
<p>b站用户<a
href="https://space.bilibili.com/3691432">翾樾non</a>有发布很详细的<a
href="https://www.bilibili.com/video/BV1QW411D78Q?share_source=copy_web">视频教学</a>，请先观看该视频.</p>
</blockquote>
<h1 id="制作配信器">制作配信器</h1>
<p>如果你下载的是压缩包，请先解压. &gt; 接下来的教程将会以下载<a
href="https://space.bilibili.com/3691432">翾樾non</a>提供的压缩包为例.</p>
<h2 id="第四世代">第四世代</h2>
<figure>
<img data-src="/images/body/WCD-Distribution-Patch/Figure1.png"
alt="Figure1" />
<figcaption aria-hidden="true">Figure1</figcaption>
</figure>
<ul>
<li><p>打开<em>Gen4</em>文件夹中的<code>WCDPatcher.exe</code>.
点击红色框.</p></li>
<li><p>在弹出的<em>Select the Distribution
ROM</em>窗口中选择同一目录下的<code>NTR-AARE-USA - GameStop Deoxys.nds</code>文件并点击<em>打开</em>.</p></li>
<li><p>点击<code>WCDPatcher.exe</code>上的蓝色框.</p></li>
<li><p>在弹出的<em>Select the Wondercard
ROM</em>窗口中，打开文件夹<code>Gen4\PPorg_GenIV_WCs\PPorg_GenIV_WCs\</code>并寻找你所需要的配信文件并点击<em>打开</em>.
如<code>Gen4\PPorg_GenIV_WCs\PPorg_GenIV_WCs\Darkrai - Movie 2007\</code>文件夹下的<code>007 Movie Darkrai ENG-USA [PPorg].pcd</code>文件.</p>
<blockquote>
<p>注意，每个配信对应的文件夹中的文件分游戏语音（地区）版本，请选择你接收的游戏对应的版本</p>
</blockquote></li>
<li><p>点击<code>WCDPatcher.exe</code>上的紫色框，并选择对应地区语言版本.</p></li>
<li><p>点击<code>WCDPatcher.exe</code>上的黄色框.</p></li>
<li><p>在弹出的<em>Select the New ROM
Location</em>窗口中，打开到你想要保存的位置，在文件名处随意命名，点击<em>保存</em>.</p></li>
<li><p>得到<code>.nds</code>文件.</p></li>
</ul>
<h2 id="第五世代">第五世代</h2>
<figure>
<img data-src="/images/body/WCD-Distribution-Patch/Figure2.png"
alt="Figure2" />
<figcaption aria-hidden="true">Figure2</figcaption>
</figure>
<ul>
<li>打开<em>Gen5</em>文件夹中的<code>LTDCE.exe</code>. 点击<strong>Open
ROM</strong>.</li>
<li>在弹出的<em>Open Nintendo DS
ROM</em>窗口中选择同一目录下的<code>2046 Liberty Pass ENG .nds</code>文件并点击<em>打开</em>.</li>
<li>点击<code>LTDCE.exe</code>上的红色框.</li>
<li>在弹出的<em>Open Pokemon Mystery Gift
File</em>窗口中，打开文件夹<code>Gen5\PPorg_GenV_WCs\PPorg_GenV_WCs</code>并根据你的游戏语言版本进入对应文件夹，寻找你所需要的配信文件并点击<em>打开</em>.
如<code>Gen5\PPorg_GenV_WCs\PPorg_GenV_WCs\English</code>文件夹下的<code>028 Dark Explorer Darkrai ENG [PPorg].pgf</code>文件.</li>
<li>点击<code>LTDCE.exe</code>上的绿色框，并选择对应地区语言版本.</li>
<li>点击<code>LTDCE.exe</code>上的蓝色框.</li>
<li>在弹出的<em>Save Nintendo DS
ROM</em>窗口中，打开到你想要保存的位置，在文件名处随意命名，点击<em>保存</em>.</li>
<li>得到<code>.nds</code>文件.</li>
</ul>
<h1 id="进行配信">进行配信</h1>
<ul>
<li>将上一步得到的<code>.nds</code>文件放入烧录卡中，使用一台
<em>DS</em> 系列掌机打开该nds文件.</li>
<li>另一台 <em>DS</em> 系列掌机运行游戏，按照正常配信步骤配信即可.
参考<a
href="https://wiki.52poke.com/wiki/%E7%A5%9E%E7%A7%98%E7%A4%BC%E7%89%A9#.E7.AC.AC.E5.9B.9B.E4.B8.96.E4.BB.A3">神百--神秘礼物</a>界面.</li>
</ul>
<blockquote>
<p>注意，这一步请确保 <em>DS</em> 系列掌机的WiFi开关打开（New 3DS、New
2DS、2DS、DSi系列需要在设置中打开，3DS需要打开侧边开关，DS、DS
Lite系列不用管）</p>
</blockquote>
]]></content>
      <categories>
        <category>Pokemon</category>
      </categories>
      <tags>
        <tag>Pokemon</tag>
        <tag>Pokemon-Distribution</tag>
        <tag>Pokemon-Gen4</tag>
        <tag>Pokemon-Gen5</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch笔记04----Tensor维度变换</title>
    <url>/Learning/Notes/PyTorch/PyTorch04/</url>
    <content><![CDATA[<p>PyTorch的一些Tensor维度变换方式</p>
<span id="more"></span>
<h1 id="view-reshape">View / Reshape</h1>
<blockquote>
<p>通用，要有物理意义，否则是污染数据 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.rand(4, 1, 28, 28)</span><br><span class="line">a.shape         #torch.Size([4, 1, 28, 28])</span><br><span class="line"></span><br><span class="line">a.view(4, 28 * 28).shape        #torch.Size([4, 784])</span><br><span class="line">#特别适合全连接层</span><br><span class="line"></span><br><span class="line">b = a.view(4, 784)      #会丢失原来的维度信息</span><br><span class="line">b.view(4, 28, 28, 1)    #造成了数据污染</span><br></pre></td></tr></table></figure></p>
</blockquote>
<ul>
<li>Flewible but prone to corrupt 如果view的size不同，会报错
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a.view(4, 783)</span><br><span class="line">--------Error--------</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="squeeze-unsqueeze">Squeeze / Unsqueeze</h1>
<h2 id="unsqueeze">Unsqueeze</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a.shape         #torch.Size([4, 1, 28, 28])</span><br><span class="line"></span><br><span class="line">a.unsqueeze(0).shape    #torch.Size([1, 4, 1, 28, 28]) 在位置0处增加一维</span><br><span class="line"></span><br><span class="line">a.unsqueeze(-1).shape   #torch.Size([4, 1, 28, 28, 1])</span><br><span class="line"></span><br><span class="line">a.unsqueeze(5).shape</span><br><span class="line">---------Error--------</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.tensor([1.2, 2.3])</span><br><span class="line">a.unsqueeze(-1)</span><br><span class="line">#tensor([[1.2000],</span><br><span class="line">         [2.3000]])</span><br><span class="line">#shape由[2]变为[2,1]</span><br><span class="line"></span><br><span class="line">a.unsqueeze(0)</span><br><span class="line">#tensor([[1.2000, 2.3000]])</span><br><span class="line">#shape由[2]变为[1,2]</span><br></pre></td></tr></table></figure>
<ul>
<li>Example &gt; 将shape为[32]的bias增加到shape为[4， 32， 14，
14]的FeatureMap的channel中</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">b = torch.rand(32)</span><br><span class="line">f = torch.rand(4, 32, 14, 14)</span><br><span class="line"></span><br><span class="line">b = b.unsqueeze(1).unsqueeze(2).unsqueeze(0)</span><br><span class="line">#注意第二次的unsqueeze参数是按第一次操作过后的索引</span><br><span class="line"></span><br><span class="line">b.shape     #torch.Size([1, 32, 1, 1])</span><br></pre></td></tr></table></figure>
<h2 id="squeeze">Squeeze</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">b.shape             #torch.Size([1, 32, 1, 1])</span><br><span class="line">b.squeeze().shape   #torch.Size([32]) 不传递参数时将能挤压的全部挤压</span><br><span class="line">b.squeeze(0).shape  #torch.Size([32, 1, 1])</span><br><span class="line"></span><br><span class="line">b.squeeze(1).shape  #torch.Size([1, 32, 1, 1]) 维度不是1，所以不能挤压，但不会报错</span><br></pre></td></tr></table></figure>
<h1 id="expand-repeat">Expand / Repeat</h1>
<p>维度扩展
之前的<code>b: [1, 32, 1, 1]``f: [4, 32, 14, 14]</code>仍不能相加，需要分别将第0、2、3维度扩展4、14、14倍</p>
<ul>
<li>Expand：broadcasting. 只改变理解方式，不改变数据</li>
<li>Repeat：memory copied. 增加数据，都拷贝一遍.</li>
</ul>
<blockquote>
<p>推荐Expand，省略复制数据，只在操作必要时复制.
运行速度快且节约内存.</p>
</blockquote>
<h2 id="expand">Expand</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.rand(4, 32, 14, 14)</span><br><span class="line">b.shape         #torch.Size(1, 32, 1, 1)</span><br><span class="line">b.expand(4, 32, 14, 14).shape       #torch.Size(4, 32, 14, 14)</span><br><span class="line">#前提：前后dim一致（这里都为4），1扩展到N，M扩展到M</span><br><span class="line"></span><br><span class="line">b.expand(-1, 32, -1, -1).shape       #torch.Size(1, 32, 1, 1) -1保持不变</span><br><span class="line"></span><br><span class="line">b.expand(-1, 32, -1, -4).shape       #torch.Size(1, 32, 1, -4)  是个bug，无意义</span><br></pre></td></tr></table></figure>
<h2 id="repeat">Repeat</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">b.shape         #torch.Size(1, 32, 1, 1)</span><br><span class="line">b.repeat(4, 32, 1, 1).shape     #torch.Size(4, 1024, 1, 1) repeat的参数是对应维度复制的次数</span><br><span class="line"></span><br><span class="line">b.repeat(4, 1, 14, 14).shape     #torch.Size(4, 32, 14, 14)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>会使得你无法使用原来的数据，占用内存变多会重新申请一片空间</p>
</blockquote>
<h1 id="t-矩阵转置">T 矩阵转置</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.randn(3, 4)</span><br><span class="line">a.t().shape     #torch.Size([4, 3])</span><br><span class="line">#仅支持2D，1D、3D...都不支持</span><br></pre></td></tr></table></figure>
<h1 id="transpose-交换维度">Transpose 交换维度</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a.shape = [4, 3, 32, 32]</span><br><span class="line">a1 = a.transpose(1, 3).view(4, 3*32*32).view(4, 3, 32, 32)</span><br><span class="line">-------------ERROR------------</span><br><span class="line">#transpose操作之后会使得元素不连续，所以在view之前要加上contiguous操作</span><br><span class="line"></span><br><span class="line">a1 = a.transpose(1, 3).contiguous().view(4, 3*32*32).view(4, 3, 32, 32) #污染数据</span><br><span class="line">a1.shape        #torch.Size([4, 3, 32, 32])</span><br><span class="line"></span><br><span class="line">a2 = a.transpose(1, 3).contiguous().view(4, 3*32*32).view(4, 32, 32, 3).transpose(1, 3) #与a等价，注意第二个view与a1不同</span><br><span class="line">a2.shape                        #torch.Size([4, 3, 32, 32])</span><br><span class="line"></span><br><span class="line">#验证，用eq函数比较各个数据是否一致，返回[4, 3, 32, 32]的张量，all函数判断其所有元素是否都为True</span><br><span class="line">torch.all(torch.eq(a, a1))      #tensor(False)</span><br><span class="line"></span><br><span class="line">torch.all(torch.eq(a, a2))      #tensor(True)</span><br></pre></td></tr></table></figure>
<h1 id="permute">Permute</h1>
<p>transpose只能两两交换 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">b = torch.rand(4, 3, 28, 32)</span><br><span class="line">b.tanspose(1, 3).transpose(1, 2).shape</span><br><span class="line">#torch.Size([4, 28, 32, 3])</span><br><span class="line"></span><br><span class="line">b.permute(0, 2, 3, 1).shape</span><br><span class="line">#torch.Size([4, 28, 32, 3])</span><br><span class="line">#permute的参数为排列后的索引</span><br></pre></td></tr></table></figure> &gt;
permute函数也会打乱内存顺序，需要时也要用到contifuous函数，也就是重新生成一片内存再复制过来.</p>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch笔记03----索引与切片</title>
    <url>/Learning/Notes/PyTorch/PyTorch03/</url>
    <content><![CDATA[<p>PyTorch中的索引与切片.</p>
<span id="more"></span>
<h1 id="indexing">Indexing</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.rand(4, 3, 28, 28)</span><br><span class="line"></span><br><span class="line">a[0].shape      #torch.Size([3, 28, 28])</span><br><span class="line">a[0, 0].shape   #torch.Size([28, 28])</span><br><span class="line">a[0, 0, 2, 4]   #tensor(0.8082)</span><br></pre></td></tr></table></figure>
<h1 id="select-first-last-n">select first / last N</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a.shape         #torch.Size([4, 3, 28, 28])</span><br><span class="line">a[:2].shape     #torch.Size([2, 3, 28, 28]) 左闭右开</span><br><span class="line">a[:2, :1, :,:]  #torch.Size([2, 1, 28, 28])</span><br><span class="line">a[:2, 1:, :,:]  #torch.Size([2, 2, 28, 28])</span><br><span class="line">a[:2, -1:, :,:] #torch.Size([2, 1, 28, 28])</span><br></pre></td></tr></table></figure>
<h1 id="select-by-steps">select by steps</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a[:, :, 0:28:2, 0:28:2].shape</span><br><span class="line">#torch.Size([4, 3, 14, 14]) 后两个维度每两个取一个，2是step</span><br><span class="line">a[:, :, ::2, ::2].shape     #与上面的等价</span><br></pre></td></tr></table></figure>
<blockquote>
<p>同Python切片</p>
</blockquote>
<h2 id="select-by-specific-index">select by specific index</h2>
<ul>
<li>index_select()
第一个参数表示操作的维度，第二个参数直接给索引号（必须是Tensor）
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a.index_select(0, torch.Tensor([0, 2])).shape</span><br><span class="line">#torch.Size([2, 3, 28, 28])</span><br><span class="line">a.index_select(1, torch.Tensor([1, 2])).shape</span><br><span class="line">#torch.Size([4, 2, 28, 28])</span><br><span class="line"></span><br><span class="line">a.index_select(2, torch.arange(8)).shape</span><br><span class="line">#torch.Size([4, 3, 8, 28])</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="select-by-...">select by <code>...</code></h2>
<blockquote>
<p><code>...</code>代表任意维度，贪心匹配（？） <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a[...].shape            #等价于a[:, :, :, :].shape</span><br><span class="line">a[0, ...].shape         #等价于a[0].shape</span><br><span class="line">a[0,...,::2].shape      #torch.Size([1, 3, 28, 14])</span><br><span class="line">a[:, 1, ...].shape      #torch.Size([4, 1, 28, 28])</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="select-by-mask">select by mask</h2>
<blockquote>
<p>使用掩码选择，会打平数据，用的不多</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x = torch.randn(3, 4)</span><br><span class="line">#tensor([[-1.3911, -0.7871, -1.6558, -0.2542],</span><br><span class="line">         [-0.9011,  0.5404, -0.6612,  0.3917],</span><br><span class="line">         [-0.3854,  0.2968,  0.6040,  1.5771]])</span><br><span class="line">         </span><br><span class="line">mask = x.ge(0.5)        #大于等于0.5的记为1</span><br><span class="line">#tensor([[0, 0, 0, 0],</span><br><span class="line">         [0, 1, 0, 0],</span><br><span class="line">         [0, 0, 1, 1]], dtype = torch.uint8)</span><br><span class="line">         </span><br><span class="line">torch.masked_select(x, mask)</span><br><span class="line">#tensor([0.5404, 0.6040, 1.5771])</span><br><span class="line">torch.masked_select(x, mask).shape</span><br><span class="line">#torch.Size([3]) 与原shape无关</span><br></pre></td></tr></table></figure>
<h2 id="select-by-flatten-index">select by flatten index</h2>
<ul>
<li>take函数也会打平数据，用的不多</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">src = torch.tensor([[4, 3, 5],</span><br><span class="line">                    [6, 7, 8]])</span><br><span class="line">torch.take(src, torch.tensor([0, 2, 5]))</span><br><span class="line">#tensor([4, 5, 8])</span><br><span class="line">#[2, 3]先打平成[6]，再选index为0，2，5的数据</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch笔记02----创建Tensor</title>
    <url>/Learning/Notes/PyTorch/PyTorch02/</url>
    <content><![CDATA[<p>PyTorch各种创建Tensor方式</p>
<span id="more"></span>
<h1 id="import-from-numpy">import from numpy</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = np.array([2, 3.3])</span><br><span class="line">torch.from_numpy(a) #tensor([2.000, 3.300], dtype = torch.float64)</span><br><span class="line"></span><br><span class="line">a = np.ones([2, 3])</span><br><span class="line">torch.from_numpy(a) #tensor([[1., 1., 1.],</span><br><span class="line">                             [1., 1., 1.]], dtype = torch.float64)</span><br></pre></td></tr></table></figure>
<h1 id="import-from-list">import from list</h1>
<blockquote>
<p>torch承载的参数是现成的数据：numpy或者list
Torch、FloatTensor接收shape作为参数，生成一个没有初始化的类型.
或使用list来接收现有数据（不建议）. <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.tensor([2, 3.2])  #tensor([2.0000, 3.2000])</span><br><span class="line"></span><br><span class="line">torch.FloatTensor([2., 3.2])    #tensor([2.0000, 3.2000])</span><br><span class="line"></span><br><span class="line">torch.tensor([[2., 3.2],[1., 22.3]])</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h1 id="uninitialized">uninitialized</h1>
<ul>
<li>torch.empty(d1, d2)</li>
<li>torch.FloatTensor(d1, d2, d3)</li>
<li>torch.IntTensor(d1, d2, d3)</li>
</ul>
<blockquote>
<p>要把未初始化的数据覆盖掉，如果出现torch.nan或者torch.inf，可能就是使用了未初始化的数据.</p>
</blockquote>
<h1 id="set-default-type">set default type</h1>
<blockquote>
<p>一般使用Tensor默认是FloatTensor</p>
</blockquote>
<p>使用<code>torch.set_default_tensor_type(torch.DoubleTensor)</code>来改变默认类型</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.tensor([1.2, 3]).type #&#x27;torch.FloatTensor&#x27;</span><br><span class="line">torch.set_default_tensor_type(torch.DoubleTensor)</span><br><span class="line">torch.tensor([1.2, 3]).type #&#x27;torch.DoubleTensor&#x27;</span><br></pre></td></tr></table></figure>
<h1 id="randrand_like-randint">rand/rand_like, randint</h1>
<ul>
<li><p>rand 随机使用[0, 1]均匀分布 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.rand(3, 3)    #按均匀分布生成3*3shape的随机张量</span><br></pre></td></tr></table></figure></p></li>
<li><p>rand_like 接受的参数是一个tensor，生成一个和其shape相同的随机张量
&gt; *_like</p></li>
<li><p>randint(min, max, [shape])，左闭右开 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">randint(1, 10, [3, 3])</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h1 id="randn-标准正态分布">randn 标准正态分布</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.randn(3, 3)    #按标准正态分布生成3*3shape的随机张量</span><br></pre></td></tr></table></figure>
<p>如果想自定义均值和方差，使用normal生成一维张量后reshape
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.normal(mean = torch.full([10], 0), std = torch.arange(1, 0, -0.1)) </span><br><span class="line">#torch.full([10], 0)生成一个10*1的全0张量</span><br><span class="line">#均值为0，方差依次递减[1, 0.9, ...]</span><br></pre></td></tr></table></figure></p>
<h1 id="full">full</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.full([2, 3], 7)   #tensor([[7., 7., 7.],</span><br><span class="line">                                 [7., 7., 7.])</span><br><span class="line">torch.full([], 7)   #tensor(7.)</span><br></pre></td></tr></table></figure>
<h1 id="arange-range">arange / range</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.arange(0, 4)   #tensor([0, 1, 2, 3])</span><br><span class="line">torch.arange(0, 4, 2)   #ensor([0, 2])</span><br><span class="line">torch.range(0, 4)   #tensor([0, 1, 2, 3, 4]) 不建议使用range</span><br></pre></td></tr></table></figure>
<h1 id="linspace-logspace">linspace / logspace</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.linspace(0, 10, steps = 4)    #第三个参数是数量</span><br><span class="line">#tensor([0.0000, 3.3333, 6.6666, 10.0000])</span><br><span class="line"></span><br><span class="line">torch.logspace(0, -1, steps = 10)   #相当于linspace生成的这些数作为10的幂</span><br><span class="line">#tensor([1.0000, 0.7743, ..., 0.1000])</span><br></pre></td></tr></table></figure>
<h1 id="ones-zeros-eye">Ones / Zeros / Eye</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.ones(2, 2)</span><br><span class="line">#tensor([[1, 1],</span><br><span class="line">         [1, 1])</span><br><span class="line">         </span><br><span class="line">torch.zeros(2, 2)</span><br><span class="line">#tensor([[0, 0],</span><br><span class="line">         [0, 0])</span><br><span class="line">         </span><br><span class="line">torch.eye(2, 3)</span><br><span class="line">#tensor([[1, 0, 0],</span><br><span class="line">         [0, 1, 0])</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.eye(3)</span><br><span class="line">#tensor([[1, 0, 0],</span><br><span class="line">         [0, 1, 0],</span><br><span class="line">         [0, 0, 1]])</span><br><span class="line"></span><br><span class="line">a = torch.zeros(3, 3)</span><br><span class="line">torch.ones_like(a)</span><br><span class="line">#tensor([[1, 1, 1],</span><br><span class="line">         [1, 1, 1],</span><br><span class="line">         [1, 1, 1]])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>eye最多两个参数</p>
</blockquote>
<h1 id="randperm">randperm</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.randperm(10)</span><br><span class="line">#tensor([1, 5, 4, 2, 0, 6, 3, 9, 7, 8]) 生成随机索引</span><br></pre></td></tr></table></figure>
<ul>
<li>random.shuffle &gt; 为了保持配对 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.rand(2, 3)</span><br><span class="line">b = torch.rand(2, 2)</span><br><span class="line">idx = torch.randperm(2)</span><br><span class="line">idx #tensor([1, 0])</span><br><span class="line"></span><br><span class="line">a[idx]</span><br><span class="line">b[idx]</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch笔记01----基本数据类型</title>
    <url>/Learning/Notes/PyTorch/PyTorch01/</url>
    <content><![CDATA[<p>PyTorch基本数据类型</p>
<span id="more"></span>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">python</th>
<th style="text-align: center;">PyTorch</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Int</td>
<td style="text-align: center;">IntTensor of size()</td>
</tr>
<tr class="even">
<td style="text-align: center;">Float</td>
<td style="text-align: center;">FloatTensor of size()</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Int array</td>
<td style="text-align: center;">IntTensor of size[d1, d2, ...]</td>
</tr>
<tr class="even">
<td style="text-align: center;">Float array</td>
<td style="text-align: center;">FloatTensor of size[d1, d2, ...]</td>
</tr>
<tr class="odd">
<td style="text-align: center;">String</td>
<td style="text-align: center;">--</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Pytorch不是一个完备的语言库，不支持String.</p>
</blockquote>
<h1 id="how-to-denote-string">How to denote string</h1>
<ul>
<li><p>One-hot Encoding [0, 1, 0, 0, ...] 每一维代表一个单词 &gt;
数据量过大时，整个向量会变得特别稀疏. &gt;
不同的单词有相近的意思，如like、love，这种方法无法体现这种相关性.</p></li>
<li><p>Embedding</p>
<ul>
<li>Word2vec</li>
<li>glove</li>
</ul></li>
</ul>
<h1 id="data-type">Data type</h1>
<p>CPU tensor: - torch.FloatTensor - torch.IntTensor - ...</p>
<p>GPU tensor: 在torch与tensor之间加上cuda - torch.cuda.FloatTensor -
torch.cuda.IntTensor - ...</p>
<h1 id="type-check">Type check</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.randn(2, 3)   #使用随机正态分布</span><br><span class="line">a.type()    #&#x27;torch.FloatTensor&#x27;</span><br><span class="line"></span><br><span class="line">type(a)     #&#x27;torch.Tensor&#x27;返回基本的数据类型</span><br><span class="line"></span><br><span class="line">isinstance(a, torch.FloatTensor)    #True</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">isinstance(data, torch.cuda.DoubleTensor)   #False</span><br><span class="line">data = data.cuda()</span><br><span class="line">isinstance(data, torch.cuda.DoubleTensor)   #True</span><br></pre></td></tr></table></figure>
<h1 id="dimension-0-rank-0-标量">Dimension 0 / Rank 0 标量</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.tensor(1.)    #直接生成标量Tensor(1.)</span><br><span class="line">torch.tensor(1.3)   #直接生成标量tensor(1.300)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>经常用于计算<em>Loss</em> --- 维度为0的标量.</p>
</blockquote>
<p>如何确定Dim为0？ <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Loss.shape  #torch.Size([])</span><br><span class="line"></span><br><span class="line">len(Loss.shape) #0</span><br><span class="line"></span><br><span class="line">Loss.dim()  #0</span><br><span class="line"></span><br><span class="line">Loss.size() #torch.Size([])</span><br></pre></td></tr></table></figure></p>
<h1 id="dimension-1-rank-1-向量">Dimension 1 / Rank 1 向量</h1>
<blockquote>
<p>PyTorch里一维多维向量统称tensor张量 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.tensor([1.1])     #tensor([1.1000]) 注意有中括号</span><br><span class="line">torch.tensor([1.1, 2.2])    #tensor([1.1000, 2.2000])</span><br><span class="line"></span><br><span class="line">torch.FloatTensor(1)    #tensor([3.2239e-25]) 指定长度，random初始化</span><br><span class="line">torch.FloatTensor(2)    #tensor([3.2239e-25, 4.5915e-41])</span><br><span class="line"></span><br><span class="line">#还可以通过numpy引入</span><br><span class="line">data = np.ones(2)       #生成一个[1, 1]的向量</span><br><span class="line">data        #array([1., 1.])</span><br><span class="line"></span><br><span class="line">torch.from_numpy(data)  #tensor([1., 1.], dtype=torch.float64)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>Dim 1的张量一般用于Bias（偏置）、Linear
Input（神经网络线性层的输入）（如[28,
28]的图片展开成[748]长度的向量输入）.</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.ones(2)</span><br><span class="line">a.shape     #torch.Size([2])</span><br><span class="line">a.size()    #torch.Size([2])</span><br></pre></td></tr></table></figure>
<h1 id="dimension-2dimension-3......">Dimension 2、Dimension
3、......</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.randn(2,3)</span><br><span class="line">a       #tensor([[-0.4423, 0.5949, 1.1440],</span><br><span class="line">                 [-2.0935, 0.2051, 1.2781]])</span><br><span class="line">                 </span><br><span class="line">a.shape #torch.Size([2,3])</span><br><span class="line">a.size(0)   #2 第一个维度的长度</span><br><span class="line">a.shape[0]  #2</span><br><span class="line">a.size(1)   #3 第二个维度的长度</span><br><span class="line">a.shape[1]  #3</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Dim 2的张量一般用于Linear Input batch（如4张[28,
28]的图片，我们将它们叠在一起，形成[4,
784]，4表示4张照片，784表示一张照片的数据）</p>
</blockquote>
<hr />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = torch.rand(1,2,3)   #使用随机均匀分布</span><br><span class="line">a   #tensor([[[0.0764, 0.2590, 0.9816],</span><br><span class="line">              [0.6798, 0.1568, 0.7919]]])</span><br><span class="line"></span><br><span class="line">a.shape #torch.Size([1, 2, 3])</span><br><span class="line"></span><br><span class="line">a[0]    #tensor([[0.0764, 0.2590, 0.9816],</span><br><span class="line">                 [0.6798, 0.1568, 0.7919]])</span><br><span class="line">            </span><br><span class="line">list(a.shape)   #[1, 2, 3]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Dim 3在RNN Input Batch中使用非常广泛：
一句话有10个单词，每个单词用一个100维的One-hot编码，一次送入20句话，就是[10,
20, 100]</p>
</blockquote>
<blockquote>
<p>Dim 4适合彩色图片： [2, 3, 28, 28]
2张图片，3个通道（RGB，如果是黑白图片则是1），28*28像素的图片</p>
</blockquote>
<pre><code>a = torch.rand(2, 3, 28, 28)

a.dim() #4
a.numel()   #4704 4704 = 2 * 3 * 28 * 28</code></pre>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Learning</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>宝可梦有电的红蓝宝石实机乱数（不包含 ID 或 Egg）</title>
    <url>/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part2/</url>
    <content><![CDATA[<p>这是宝可梦有电红蓝宝石的实机乱数教程. 不包含 ID 与 Egg 的乱数教程.
如有纰漏，请<a href="/about/">与我联系</a>，万分感谢！</p>
<p>封面 [ID:88418874].</p>
<span id="more"></span>
<p><strong>注意，本教程仅支持：有电的红蓝宝石.</strong></p>
<p>如果你在找绿宝石及没电红蓝宝石的红蓝宝石实机乱数教程，请点击<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part1/">这里</a>.</p>
<p>如果你在找火红叶绿的实机乱数，请点击<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part3/">这里</a>.</p>
<blockquote>
<p>实机很难实现，难度很高.</p>
</blockquote>
<blockquote>
<p>成果展示: <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part2/Result.png"
alt="Result" /></p>
</blockquote>
<h1 id="准备工作">准备工作</h1>
<p>如果你想要乱数闪光宝可梦，你需要知道你的<a
href="https://wiki.52poke.com/wiki/ID_No.#.E9.87.8CID_No.">SID</a>.</p>
<blockquote>
<p>如果你想要乱数的是已经创建好的存档，这可能会需要你导出存档并使用
<em>PKHex</em>
等软件查看你的存档（不涉及修改与导入），请根据自身接受程度使用.（本教程默认读者使用<em>NDS</em>烧录卡进行存档提取来方便查看个体）</p>
</blockquote>
<blockquote>
<p>由于我没有怎么研究过乱数ID，所以如果你想要乱数ID，请参考：<a
href="https://www.smogon.com/ingame/rng/rs_nonbredrng#idsid">Smogon ID
乱数教程</a>.<br> 之后如果自己研究了一遍就会上传Blog.</p>
</blockquote>
<blockquote>
<p>不会导出存档？看看这篇博客：<a
href="/Pokemon/Strategies/In-Game/How-To-Back-Up-Your-Savefiles/">如何备份你的存档</a>.</p>
</blockquote>
<h2 id="硬件准备">硬件准备</h2>
<ul>
<li>能够游玩第三世代宝可梦卡带的<em>NDS</em>系列机器（初代 <em>NDS</em>
或 <em>NDS lite</em>，以下统称 <em>NDS</em>）.</li>
<li>电脑.</li>
<li><em>NDS</em>烧录卡与读卡器.</li>
</ul>
<blockquote>
<p>本教程默认读者使用<em>NDS</em>烧录卡进行存档提取来方便查看个体，如若抗拒，请参考
<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part1/">宝可梦绿宝石及没有电的红蓝宝石实机乱数（不包含
ID 或 Egg）</a> 中提及的方法（使用神奇糖果）.</p>
</blockquote>
<h2 id="下载乱数所需工具">下载乱数所需工具：</h2>
<ul>
<li>计时器<a href="/download/CCTimer.rar">CCTimer</a>
因为没有找到该软件的发布页，所以上传至仓库可直接点击下载，如果你知道它的发布页，请与我联系.</li>
<li>乱数工具<a
href="https://www.dropbox.com/sh/68qqg26op3uaymc/AAC8QFFKYxAqQjG80abgcHZ1a?dl=0">3genSearch</a>
国内需要科学上网，因原作者禁止二次发布所以这里不提供直接下载，可以通过各搜索引擎找到别人的分享.</li>
<li>乱数工具<a
href="https://github.com/Admiral-Fish/RNGReporter/releases">RNGReporter</a>
如果因为国内 GitHub 下载速度原因不好下载，可以点击<a
href="/download/RNGReporter.zip">这里</a>进行下载.</li>
<li>时钟修复软件<a
href="https://wiki.52poke.com/wiki/%E6%97%B6%E9%92%9F%E7%94%B5%E8%B7%AF%EF%BC%88%E6%BC%8F%E6%B4%9E%EF%BC%89#.E5.A4.96.E9.83.A8.E9.93.BE.E6.8E.A5">rtcread</a>
将<code>.nds</code>文件放在烧录卡的储存卡中. 也可以点击<a
href="/download/rtcread-ds.rar">这里</a>进行下载.</li>
<li>存档编辑软件<a
href="https://github.com/kwsch/PKHeX/releases">PKHex</a>
将使用其查看宝可梦的个体，不会涉及到存档修改. 如果因为国内 GitHub
下载速度原因不好下载，可以点击<a
href="/download/PKHeX(190705).zip">这里</a>进行下载（版本：19.07.05）.</li>
<li>seed查找工具<a
href="https://www.smogon.com/forums/threads/rng-manipulation-in-firered-leafgreen-wild-pok%C3%A9mon-supported-in-rng-reporter-9-93.62357/">FRLGSeedFinder</a>
如果选用3genSearch可以不用此工具. 也可以点击<a
href="/download/FRLGSeedFinder.zip">这里</a>进行下载.</li>
</ul>
<blockquote>
<p>两个乱数工具选择任意一个都可以，本教程使用的是 <em>3genSearch</em>.
RNGReporter的使用与之类似，还请读者自行探索.</p>
</blockquote>
<h2 id="了解乱数机制">了解乱数机制</h2>
<p>请参考<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part1/#了解乱数机制">宝可梦绿宝石及没有电的红蓝宝石实机乱数（不包含
ID 或 Egg）</a> 中的相应部分.
这里不同的是，我们需要知道有电的红蓝宝石（以下简称
<strong><em>RS</em></strong>）进入游戏的初始 seed. 而
<strong><em>RS</em></strong> 的初始 seed
在每一分钟都是相同的，也就是说，控制进入游戏时 <em>RTC</em>
的时间在同一分钟就可以固定住初始 seed，因此我们使用时钟修复软件
rtcread.</p>
<blockquote>
<p>我在参阅外网资料时有看到，<strong><em>RS</em></strong> 的初始 seed
每分钟推进 1，但实际操作中发现并不是这样. 有时会推进
1，有时会推进或者倒退很多（但不会太多，大约 2~16左右）. 因此 seed
并不会变化太快.</p>
</blockquote>
<h2 id="确定乱数目标">确定乱数目标</h2>
<p>与<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part1/#确定乱数目标">宝可梦绿宝石及没有电的红蓝宝石实机乱数（不包含
ID 或 Egg）</a>相同.
<strong><em>如果选择了野外相遇的宝可梦，请在队伍中准备一只习得了<a
href="https://wiki.52poke.com/wiki/%E7%94%9C%E7%94%9C%E9%A6%99%E6%B0%94%EF%BC%88%E6%8B%9B%E5%BC%8F%EF%BC%89#.E5.8F.AF.E4.BB.A5.E5.AD.A6.E4.BC.9A.E8.AF.A5.E6.8B.9B.E5.BC.8F.E7.9A.84.E5.AE.9D.E5.8F.AF.E6.A2.A6">甜甜香气</a>的宝可梦.</em></strong>
确定乱数目标后，选择相应的 <em>Method</em>. 如果是乱数蛋，请参阅<a
href="https://www.smogon.com/ingame/rng/emerald_rng_part4">这里</a>.</p>
<h3 id="method-1"><em>Method 1</em></h3>
<ul>
<li>御三家（<strong><em>RS</em></strong>、<strong><em>E</em></strong>
一周目与 <strong><em>E</em></strong> 二周目）</li>
<li>定点宝可梦</li>
<li>釜炎镇 NPC 赠送的小果然的蛋</li>
<li><strong><em>RS</em></strong> 通过甜甜香气遭遇的宝可梦</li>
<li><strong><em>RS</em></strong> 通过钓鱼遭遇的宝可梦（除丑丑鱼）</li>
<li><strong><em>RS</em></strong> 通过碎岩遭遇的宝可梦</li>
</ul>
<h3 id="method-2"><em>Method 2</em></h3>
<ul>
<li>草丛/海草/深沙/洞穴/水上/可以遇到宝可梦的建筑中通过移动/转向
遭遇的宝可梦（除了游走宝可梦）</li>
<li><strong><em>E</em></strong> 通过甜甜香气遭遇的宝可梦</li>
<li><strong><em>E</em></strong> 钓鱼钓上来的宝可梦</li>
<li><strong><em>E</em></strong> 通过碎岩遇到的宝可梦</li>
</ul>
<h3 id="method-4"><em>Method 4</em></h3>
<ul>
<li>钓鱼钓上来的丑丑鱼</li>
</ul>
如果是 <em>Method
1</em>中的前三类，点击下面的谜拟Q来查看保存游戏的位置与生成帧的所在时机（
<strong><em>E</em></strong> 与 <strong><em>RS</em></strong>
有些会有区别）：
<details>
<summary>
<img no-lazy data-src="/images/mimikyu.png" alt="Method 2 请点击丘丘" align=left>
</summary>
<br> -- 御三家：在博士的包前保存，在问你“Do you choose this
POKéMON?”时等待生成帧 <br> -- 飘浮泡泡：在反派干部前保存，在研究员说“It
might be an odd way of thanking you, but take this POKéMON.”时等待生成帧
<br> --
游走水都：击败冠军后在出自己的房间门前存档，在让你选择红蓝时等待生成帧
<br> -- 复活化石：在研究员前保存，在他说“The fossil was an ancient
POKéMON. [LILEEP/ANORITH], it was!”时等待生成帧 <br> -- 小果然的蛋：在
NPC 前存档，在她说“Good! I hope you'll walk plenty with this here
EGG!”时等待生成帧 <br> -- 变隐龙：在隐形的变隐龙前存档，在提示“The
startled POKéMON attacked!”时等待生成帧 <br> --
大吾的铁哑铃：在精灵球前存档，在选择是否拿走时等待生成帧 <br> --
胡说树：在其面前存档，在提示“The weird tree attacked!”时等待生成帧 <br>
--
盖欧卡与固拉多：在距离剧情触发前一步存档，在进入战斗前最后一段时等待生成帧
<br> -- 凤王：Save on the first space of the peak of the cliff. Last
input is pressing up on the directional pad to place yourself on the
second space of the cliff. <br> -- 梦幻：Save in the area it appears in.
Last input is a press of the A button to "tag" it. <br> --
其他：在宝可梦/触发物前保存，在进入战斗前最后一段时等待生成帧 <br> <br>
凤王和梦幻的不知道怎么表达比较好，看英文感受一下.
</details>
<p><br><br></p>
<p>如果是 <em>Method 2</em> 或 <em>Method 1</em>
的后三类，在进入战斗前最后一次点击作为生成帧.</p>
<blockquote>
<p>实际生成帧可能会更往后，如甜甜香气，但这段时间是固定的，可以通过多次尝试来更新.</p>
</blockquote>
<h1 id="开始乱数">开始乱数</h1>
<h2 id="确定初始seed">确定初始seed</h2>
<ol type="1">
<li>在<em>NDS</em>上插入 <strong><em>RS</em></strong> 游戏卡带与烧录卡.
<img data-src="/images/body/Pokemon-RNG-Abuse-Gen3-Part2/Figure1.png"
alt="Figure1" /></li>
<li>打开烧录卡，选择时钟修复软件 rtcread 运行. <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part2/Figure2.png"
alt="Figure2" /></li>
<li>按下 <em>start</em> 键，你可以看到当前 <strong><em>RS</em></strong>
卡带的RTC. <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part2/Figure3.png"
alt="Figure3" /></li>
<li>按下 <em>select</em> 键，进入修改RTC时间模式.</li>
<li>选择一个时间，并且让秒数归零，如图选择的是 <strong>2002-10-31
10:42:00</strong>. <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part2/Figure4.png"
alt="Figure4" /></li>
<li>按下 <em>start</em> 键，并尽快关机.</li>
<li>尽快开机进入游戏，任意捕捉一只宝可梦后存档并关机（宝可梦相遇越快越好）.</li>
<li>使用 NDS烧录卡 提取游戏存档后使用 PKHex 打开.</li>
<li>找到你捕捉的宝可梦，右击选择 <em>查看</em> 并选择左侧选项卡的
<em>数值</em>. <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part2/Figure5.png"
alt="Figure5" /></li>
<li>打开乱数工具，选择<em>个体逆算</em>，并根据 PKHex 中的数据填入并点击
<em>计算</em>（游戏版本与地点、相遇方式等也别忘了修改）
再根据PKHex左侧选项卡的 <em>主页面</em> 确定
<em>开始seed</em>（第一列）或
<em>生成seed</em>（第二列）（如果有多个无法区分，都记下，并可能需要再来一次.
此外，其实只要保证<strong>pid</strong>相同即可）. <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part2/Figure6.png"
alt="Figure6" /> <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part2/Figure7.png"
alt="Figure7" /></li>
<li>右击复制该<em>开始seed</em>，选择<em>其他-初期seed检索</em>
，将复制的<em>开始seed</em>填入<em>目标seed</em>，勾选上
<em>初期seed全探索</em>. [F]
处第二个空填入18000左右即可（根据你遇到这只宝可梦的游戏时间决定，一分钟约3600
F），点击 <em>计算</em>. &gt;
图中实例宝可梦并非游戏一开始就遇到的，仅为教程作参考，以实际为准. <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part2/Figure8.png"
alt="Figure8" /></li>
<li>记下F最接近实际相遇时间的<em>初期seed</em>.
这就是该RTC时间下的初始seed</li>
</ol>
<blockquote>
<p>之后的步骤与<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part1/#开始乱数">宝可梦绿宝石及没有电的红蓝宝石实机乱数（不包含
ID 或
Egg）</a>相应部分类似，但每次开始游戏前需要执行一遍步骤2~6，且需尽快开机进入游戏以确保seed不变.</p>
</blockquote>
<h2 id="搜索目标宝可梦">搜索目标宝可梦</h2>
<p>打开乱数工具，选择/填入图中红框中内容： <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part1/Figure1.png"
alt="Figure1" /></p>
<ol type="1">
<li>根据乱数目标选择<em>固定</em>或<em>野生</em>.</li>
<li>如果选择了<em>野生</em>，可以修改绿框中的地点、版本信息.</li>
<li>输入之前得到的初期 seed.</li>
<li>F为搜索帧数的范围，建议800~10000，因为 seed
固定了所以可能很靠后才有你想要的帧.（1秒约60帧，请自行推测是否有耐心）（请根据实际情况调整，如甜甜香气动画较长，所以起始帧会高一些）.</li>
<li><em>Method</em> 选择之前确定的 <em>Method</em>.</li>
<li>检索区域根据自己的需要填写，若勾选
<strong><em>只显示异色</em></strong> ，需要在勾选框上方填入表里ID.</li>
<li>点击黑框<em>计算</em>，得到结果.</li>
</ol>
<blockquote>
<p>没有想要的宝可梦怎么办？<br>
不建议帧数再加了，10w帧约27.8分钟了，可以试着降低一下要求.</p>
</blockquote>
<blockquote>
<p>闪帧太靠后了怎么办？<br> 回到 <a href="#确定初始seed">确定初始
seed</a>步骤，并在第五步选择一个不同的时间（精确到 min）.</p>
</blockquote>
<p>在结果中选择一个满意的结果作为目标帧，将其
<strong><em>F</em></strong>
栏（即为你的<em>目标帧</em>）填入蓝框中（蓝框后面的内容不需要管）.</p>
<h2 id="校准误差">校准误差</h2>
<p><strong><em>如果你的目标宝可梦不是野外宝可梦（如定点宝可梦），那么要在步骤1结束后，将存档备份</em></strong></p>
<ol type="1">
<li><p>在游戏中你应该存档的位置存档（如果你准备在洞穴或是能出现宝可梦的建筑中使用甜甜香气，请往深处走一些距离，否则甜甜香气可能会失效），存档完成后关机.</p></li>
<li><p>打开计时器 <em>CCTimer</em>，选择
<em>Setting</em>，点击红框内容，根据游戏平台选择对应选项. <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part1/Figure2.png"
alt="Figure2" /></p></li>
<li><p>回到 <em>Timer</em>，在蓝框内填入你刚刚的 <em>目标帧</em> 并点击
<strong><em>Add</em></strong> . <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part1/Figure3.png"
alt="Figure3" /></p></li>
<li><p><strong><em>执行一遍<a href="#确定初始seed">确定初始
seed</a>步骤的2~6，且需尽快开机进入游戏以确保seed不变.</em></strong>
点击 <strong><em>Start</em></strong>
按钮的同时开始游戏(设置过的nds是直接开机，未设置过的nds系列是在主页面点击GBA游戏图标).</p></li>
<li><p>在游戏中快速到达目标帧的确定位置（如：在选择宝可梦使用甜甜香气的界面）.</p></li>
<li><p>在 <em>CCTimer</em> 上的倒计时归零的瞬间按下机器的
<strong><em>A</em></strong> 键，然后等待进入战斗界面.</p></li>
<li><p>捕捉这只宝可梦.</p></li>
<li><p>保存并关闭游戏，提取存档，使用读卡器连接到电脑后使用 PKHex
打开存档，查看刚捕捉的宝可梦的数据.</p></li>
<li><p>回到乱数工具，在黄框中填入刚捕捉到的宝可梦数据（如果不是闪光记得不要勾选
<strong><em>只显示异色</em></strong> ），点击 <em>计算</em>.
记下橙色框中的数字（如有多个，选择离<em>目标帧</em>最近的）. <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part1/Figure4.png"
alt="Figure4" /></p></li>
<li><p>回到
<em>CCTimer</em>，计算<em>目标帧</em>减去刚刚橙色框中的数字的值，点击
<strong><em>Clear</em></strong> 按钮清除后输入该值并点击
<strong><em>Add</em></strong> .</p>
<blockquote>
<p>例如 CCTimer 中的值（目标帧）是2156，击中帧是2177，2156 - 2177 =
-21（橙色框中数字为 21），那么将 CCTimer 中的值更新为 2156 - 21 =
2135.</p>
</blockquote></li>
</ol>
<p>误差校准完成.</p>
<blockquote>
<p>注意，如果你更换了目标，即宝可梦获得方式改变（如Method不同 或
由游戏厅切换为固拉多），请重新进行误差校准！</p>
</blockquote>
<h2 id="乱数">乱数</h2>
<p><strong><em>如果你的目标宝可梦不是野外宝可梦（如定点宝可梦），那么要先将备份存档恢复</em></strong>
和校准误差的4、5、6步一致：</p>
<ol type="1">
<li><strong><em>执行一遍<a href="#确定初始seed">确定初始
seed</a>步骤的2~6，且需尽快开机进入游戏以确保seed不变.</em></strong>
点击 <strong><em>Start</em></strong> 按钮的同时开始游戏.</li>
<li>在游戏中快速到达目标帧的确定位置.</li>
<li>在 <em>CCTimer</em> 上的倒计时归零的瞬间按下机器的
<strong><em>A</em></strong> 键，然后等待进入战斗界面.</li>
<li>如果得到的不是<em>目标帧</em>，可以选择再次进行误差校准或者再多尝试几次.</li>
</ol>
<blockquote>
<p>因为手工操作多少会有些误差，建议多尝试几次，若十几二十次失败再考虑重新校准误差.</p>
</blockquote>
<ol start="5" type="1">
<li>乱数成功，得到目标！</li>
</ol>
<h1 id="如果选用-rngreporter">如果选用 RNGReporter</h1>
<p>发现这两个软件在反查初始seed有些不同，下面记录一下RNGReporter反查seed的方法：</p>
<ul>
<li>打开RNGReporter，选择<em>4th Gen Tools</em> 中的 <em>Calculate PID
from IVs</em>. <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part2/Figure9.png"
alt="Figure9" /></li>
<li>输入个体性格与你的ID，点击<em>Find</em>，选择<strong>PID</strong>对应的一栏.
<img data-src="/images/body/Pokemon-RNG-Abuse-Gen3-Part2/Figure10.png"
alt="Figure10" /></li>
<li>这里得到的seed是<em>生成seed</em>，将其输入工具<em>FRLGSeedFinder</em>中（虽然写的FRLG，但是三代通用）.
<img data-src="/images/body/Pokemon-RNG-Abuse-Gen3-Part2/Figure11.png"
alt="Figure11" /></li>
<li>得到初始seed.</li>
</ul>
<h1 id="写在后面">写在后面</h1>
<ul>
<li>在<a href="#确定初始seed">确定初始
seed</a>步骤可以多选择几个RTC时间，捉完宝可梦后保存然后再次重复，导出存档一起确定seed，然后选择最满意的.</li>
<li>还有一种比较麻烦的方法，在这里描述一下，十分费时费力，就不展开说了：
<ul>
<li>准备大量的神奇糖果.</li>
<li>使用玩家自制的软件 <a
href="https://www.smogon.com/forums/threads/fr-lg-rng-timer.3554964/">FR/LG
RNG Timer</a>. 也可以点击<a
href="/download/FRLG_RNG_Timer.jar">这里</a>进行下载.</li>
<li>进入游戏的同时开始计时器.</li>
<li>捕捉一只宝可梦并通过糖果确定个体.</li>
<li>使用个体查出初始seed.</li>
<li>查找该seed下满意的宝可梦，将目标帧数输入 FR/LG RNG Timer 点击
Submit.</li>
<li>游戏推进到等待生成帧.</li>
<li>倒计时结束触发生成帧.</li>
<li>捕捉并通过糖果确认个体.</li>
<li>利用个体查找击中帧数，记录校准值.</li>
<li>利用校准值再来一次.</li>
</ul></li>
</ul>
<h1 id="reference">Reference</h1>
<ul>
<li><a
href="https://taiyaki3gen.hatenablog.com/entry/2020/05/30/162400">3genSearch
作者博客</a></li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cuc21vZ29uLmNvbS9pbmdhbWUvcm5nLw==">Smogon RNG
教程<i class="fa fa-external-link-alt"></i></span></li>
<li><a
href="https://www.smogon.com/forums/threads/rng-manipulation-in-firered-leafgreen-wild-pok%C3%A9mon-supported-in-rng-reporter-9-93.62357/">RNG
Manipulation in FireRed/LeafGreen: Wild Pokémon Supported in RNG
Reporter 9.93</a></li>
<li><a
href="https://www.smogon.com/forums/threads/fr-lg-rng-timer.3554964/">Programming
- FR/LG RNG Timer</a></li>
</ul>
<h1 id="appreciation">Appreciation</h1>
<ul>
<li>感谢<strong>Rai</strong>为我纠正了一些错误.</li>
</ul>
]]></content>
      <categories>
        <category>Pokemon</category>
      </categories>
      <tags>
        <tag>Pokemon</tag>
        <tag>Pokemon-RNG-Abuse</tag>
        <tag>Pokemon-Gen3</tag>
      </tags>
  </entry>
  <entry>
    <title>宝可梦卡带鉴别</title>
    <url>/Pokemon/Strategies/Out-Game/Pokemon-Cartridges-Authenticate/</url>
    <content><![CDATA[<p>从我的b站专栏：<a
href="https://www.bilibili.com/read/cv10463502">宝可梦前代卡带鉴别</a>搬过来的，稍微有些修改.
主要就是宝可梦 <em>GBA</em> 和 <em>NDS</em> 卡带真伪的鉴别.
如果对你有帮助可以去专栏给个三连~</p>
<p>封面 [ID:78728436].</p>
<span id="more"></span>
<hr />
<p>宝可梦前代作为比较保值甚至理财的游戏卡带最近价格一路飞升，而很多入坑的新人却对卡带真假的辨别毫无知识储备.
虽然很多大佬已经写过很多卡带鉴别帖，但有些可能不够有条理（？）决定再写一份.</p>
<p>由于3ds卡带没有假卡（反正我没见过），所以
<strong><em>本博客主要讨论宝可梦三代到四代的主系列游戏卡带、卡盒鉴别方法以及美版中纯美版（北美版）、加拿大美版和亚太美版的区别</em></strong>.</p>
<p>感谢<strong>犬犬</strong>补充与提供部分图片！</p>
<p>感谢<strong>大黄</strong>！为难这个懒b了，我这就爬.</p>
<p>感谢<strong>xxc</strong>提供的部分图片.</p>
<p><del>我就不信这个老金看不懂</del></p>
<p>大部分图片源自网络 侵删</p>
<blockquote>
<p>因为假卡制作成本固定而<strong><em>日版</em></strong>价格偏低，所以日版几乎没有假卡.
有也都是一眼就能看出来的（比如黑色卡壳的宝石什么的）.
所以日版可以大胆放心的买.
但不排除价格飞升后奸商开始把目光转到日版的情况，所以建议也稍微学一下卡带鉴别.</p>
</blockquote>
<h1 id="卡带">卡带</h1>
<h2
id="gba系列红宝石-蓝宝石-火红-叶绿-绿宝石">GBA系列（红宝石 蓝宝石 火红 叶绿 绿宝石）</h2>
<ul>
<li><p>卡壳颜色以及贴纸颜色/字体，可以参照一下下面的对比图，还是比较明显的.
<img data-src="/images/body/Pokemon-Cartridges-Authenticate/Figure1.webp"
alt="Figure1" /> <br><br></p></li>
<li><p>正版卡带贴纸右侧有钢印.
这个方法可以确定这个壳子是正版壳，不排除里面芯片被人为换成假卡芯片的情况，不过有些钢印比较难拍出也有点难看出来.
<img data-src="/images/body/Pokemon-Cartridges-Authenticate/Figure2.webp"
alt="Figure2" /> <br><br></p></li>
<li><p>正版卡带左上方侧面有方形，火叶壳子没那么透不是很清楚. <img
src="/images/body/Pokemon-Cartridges-Authenticate/Figure3.webp"
alt="Figure3" /> <img
src="/images/body/Pokemon-Cartridges-Authenticate/Figure4.webp"
alt="Figure4" /> <br><br></p></li>
<li><p>正版卡带芯片背面左上方有田字（火叶相较宝石偏下一些）.
假卡芯片背面很多圆点. 这个方法可以判别卡带芯片是否为正版. <img
src="/images/body/Pokemon-Cartridges-Authenticate/Figure5.webp"
alt="Figure5" /> <br><br></p></li>
<li><p>芯片下方有行白字（Nintendo那行）.
有的假卡会没有，版本批次不同后面的数字不一样，但是每个版本一般固定只有两种.
假卡印刷歪一点. 理论上，看背面就好了（大黄原话）. <img
src="/images/body/Pokemon-Cartridges-Authenticate/Figure6.webp"
alt="Figure6" /> <br><br></p></li>
<li><p>与第四世代的联动. 据说现在假卡已经能做到了，而且新出的gba烧录卡也能做到，所以这个方法失效.
不过不能联动的肯定不是正卡.</p></li>
</ul>
<p><br><br></p>
<h2
id="nds系列第一类珍珠-钻石-白金">NDS系列第一类（珍珠 钻石 白金）</h2>
<p>这一类卡带偏灰色，较难辨别.</p>
<ul>
<li>首先是正面贴纸的颜色、字体、粗细等等，参照对比图. <img
src="/images/body/Pokemon-Cartridges-Authenticate/Figure7.webp"
alt="Figure7" /></li>
</ul>
<p>上真下假. <br><br></p>
<ul>
<li>背面三行字的字体、粗细，其中第二行是反光材质的，有的角度拍不太清楚可以要求拍反光.</li>
<li>如果金手指（卡带背面下方金属部分）上方绿色部分的字不正便是假卡.
但不同角度照片也可能把正卡拍的比较歪，而且有的假卡做的已经很正了.
此外金手指上的字一般差不太多，不会像这个离谱到有Nintendo字样. <img
src="/images/body/Pokemon-Cartridges-Authenticate/Figure8.webp"
alt="Figure8" /></li>
</ul>
<p>第二点与第三点的图. <br><br></p>
<ul>
<li>与第五世代的联动.
这个同GBA系列第四点，有的假卡已经能做到了，所以失效. <br><br></li>
</ul>
<h2
id="nds系列第二类心金-魂银-黑-白-黑2-白2">NDS系列第二类（心金 魂银 黑 白 黑2 白2）</h2>
<p>这一类卡带呈深黑色，与灰色还是有区别的.</p>
<ul>
<li>正版卡带在强光下卡带透红. 这个基本已经可以区别正卡假卡了. <img
src="/images/body/Pokemon-Cartridges-Authenticate/Figure9.webp"
alt="Figure9" /></li>
</ul>
<p>都是正卡. <br><br></p>
<ul>
<li><p>正面贴纸的颜色、字体、粗细等等，同第一类. <br><br></p></li>
<li><p>背面字体、粗细，同第一类. <br><br></p></li>
<li><p>金手指的字正不正、对不对，同第一类. <br><br></p></li>
<li><p>心魂的与第五代联动，同第一类. <br><br></p></li>
<li><p>与宝可梦银行（Mover）（黑白与黑白2）或AR搜寻器的联动（黑白2）可以用于区分，暂时假卡好像还不能联动.
<br><br></p></li>
</ul>
<blockquote>
<p>大概的就是这些，比较难区分的就是NDS系列第一类（dppt）了.
需要多看看，积累经验才能准确辨别.</p>
</blockquote>
<h1 id="卡盒">卡盒</h1>
<h2 id="gba系列">GBA系列</h2>
<p>这个比较好认，色调啥的完全不对，一般一眼就能看出来.
假盒花里胡哨闪的过分. <br><br></p>
<h2 id="nds系列">NDS系列</h2>
<ul>
<li>全新的NDS美版卡带的塑封是没有中间一条Nintendo的，只有欧版全新才带那个塑封.
<img data-src="/images/body/Pokemon-Cartridges-Authenticate/Figure10.webp"
alt="Figure10" /></li>
</ul>
<p>假. <br><br></p>
<ul>
<li>美版看左下角 <strong>E</strong> 字及其附近的粗细与字体. <img
src="/images/body/Pokemon-Cartridges-Authenticate/Figure11.webp"
alt="Figure11" /></li>
</ul>
<p>上假下真 上面的E和下面的E在框框里的位置不太一样，粗细也不同.
<br><br></p>
<ul>
<li>蓝色 wifi 标上 Nintendo 的字体（假卡不全是第二种）. <img
src="/images/body/Pokemon-Cartridges-Authenticate/Figure12.webp"
alt="Figure12" /></li>
</ul>
<p>上正下假 <br><br></p>
<ul>
<li>美版是黑灰色的盒子，欧版是白透色的盒子.
白透色的盒子上有个美版分级E很明显是假盒. <img
src="/images/body/Pokemon-Cartridges-Authenticate/Figure13.webp"
alt="Figure13" /></li>
</ul>
<p>假 <br><br></p>
<ul>
<li>避免买只有三张说明书的（一张游戏说明书两张白色的纸片），很有可能是假盒
+ 假说明书.</li>
</ul>
<p>一般来说假卡配假盒，假卡壳配假芯片的多.
但现在还有不少奸商真盒塞假卡或是真卡配假盒，所以还是要擦亮眼睛.</p>
<p><br><br></p>
<hr />
<p><br><br></p>
<h1 id="美版的分类">美版的分类</h1>
<p>纯美版（北美版）、加美版、亚太美版见图 <img
src="/images/body/Pokemon-Cartridges-Authenticate/Figure14.webp"
alt="Figure14" /></p>
<p>依次为纯美、加美、亚太美.
说明书上纯美加美没啥区别（具体的不太清楚，应该一样的），亚太美只有几张薄薄的小白纸.</p>
<p><br><br></p>
<hr />
<p><br><br></p>
<h1 id="大黄的叮嘱">大黄的叮嘱：</h1>
<figure>
<img data-src="/images/body/Pokemon-Cartridges-Authenticate/BigYellow.webp"
alt="BigYellow" />
<figcaption aria-hidden="true">BigYellow</figcaption>
</figure>
]]></content>
      <categories>
        <category>Pokemon</category>
      </categories>
      <tags>
        <tag>Collection</tag>
        <tag>Pokemon</tag>
      </tags>
  </entry>
  <entry>
    <title>VS. Recorder</title>
    <url>/Pokemon/VS-Recorder/</url>
    <content><![CDATA[<p>此 Blog 用于记录一些宝可梦对战比赛，终有一日成为宝可梦大师！
平时比赛可能不是很勤，尽量8.</p>
<p>封面 [ID:79621961].</p>
<span id="more"></span>
<h1 id="年10月苏州月赛战报-冠军">2020年10月苏州月赛战报-冠军</h1>
<figure>
<img data-src="/images/body/VS-Recorder/SPL-2020-10-05.png"
alt="SPL-2020-10-05" />
<figcaption aria-hidden="true">SPL-2020-10-05</figcaption>
</figure>
<h2 id="date-2020-10-05">Date: 2020-10-05</h2>
<h2 id="rule-不限标-允许携带最多一个幻兽">Rule: 不限标
允许携带最多一个幻兽</h2>
<h2 id="record">Record:</h2>
<ul>
<li>第一轮瑞士轮 轮空</li>
<li>第二轮瑞士轮 vs red X 首发谜拟Q+霜奶仙 对面首发野菊+妙蛙
赌对面点谜拟Q开空间所以霜奶仙换后排魔女 谜拟Q影袭队友触发弱测
结果对面打霜奶仙位 开空间 跪了</li>
<li>第三轮瑞士轮 vs bd O bd开卡包开到高罕太激动了
嘎啦没点防壁被装饰jjh谜拟Q秒了
然后就被谜拟Q杀穿了（感觉点了防壁也赢不了？）</li>
</ul>
<p>2-1勉强进半决赛</p>
<ul>
<li>半决赛 vs red O 同样的首发 直接装饰jjh谜拟Q开干
霜奶仙退场后梦幻变身谜拟Q 两只谜拟Q杀穿了</li>
<li>决赛 vs 乌笔澄 bo3规则 OO
<ul>
<li>第一轮首发谜拟Q+风妖精 对面咆哮虎+智挥猩 谜拟Q剑舞
风妖精被击掌触发按钮白给换上霜奶仙 再次霜奶仙配合jjh谜拟Q贯穿</li>
<li>第二轮对面首发垃圾之翼+毒电开顺风 还是被谜拟Q+霜奶仙秒了毒电
最后残局对面健康西施 我方残血霜奶仙+风妖精 霜奶仙给风妖精装饰后被打死
风妖精掉包换来了西施的背心 然后月爆对攻西施结束 拿下冠军</li>
</ul></li>
</ul>
<h2 id="sentiment">Sentiment</h2>
<p>没想到大部分钢属性幻兽的情况下这队表现能这么好！点名表扬谜拟Q
霜奶仙和风妖精. 真爱队胜利还是很开心的，以后再接再厉. ## Team:
有些配置记不清了，大概如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Mimikyu @ Babiri Berry  </span><br><span class="line">Ability: Disguise  </span><br><span class="line">Level: 50  </span><br><span class="line">EVs: 252 HP / 160 Atk / 94 Def / 4 SpD  </span><br><span class="line">Adamant Nature  </span><br><span class="line">- Play Rough  </span><br><span class="line">- Shadow Sneak  </span><br><span class="line">- Swords Dance  </span><br><span class="line">- Shadow Claw  </span><br><span class="line"></span><br><span class="line">Alcremie @ Safety Goggles  </span><br><span class="line">Ability: Aroma Veil  </span><br><span class="line">Level: 50  </span><br><span class="line">EVs: 252 HP / 74 Def / 4 SpA / 180 Spe  </span><br><span class="line">Timid Nature  </span><br><span class="line">- Decorate  </span><br><span class="line">- Dazzling Gleam  </span><br><span class="line">- Protect  </span><br><span class="line">- Helping Hand  </span><br><span class="line"></span><br><span class="line">Whimsicott @ Focus Sash  </span><br><span class="line">Ability: Prankster  </span><br><span class="line">Level: 50  </span><br><span class="line">EVs: 252 HP / 6 SpD / 252 Spe  </span><br><span class="line">Timid Nature  </span><br><span class="line">IVs: 0 Atk  </span><br><span class="line">- Tailwind  </span><br><span class="line">- Endeavor  </span><br><span class="line">- Memento  </span><br><span class="line">- Helping Hand  </span><br><span class="line"></span><br><span class="line">Rotom-Heat @ Wiki Berry  </span><br><span class="line">Ability: Levitate  </span><br><span class="line">Level: 50  </span><br><span class="line">EVs: 252 HP / 66 Def / 116 SpA / 76 Spe  </span><br><span class="line">Modest Nature  </span><br><span class="line">IVs: 0 Atk  </span><br><span class="line">- Thunderbolt  </span><br><span class="line">- Nasty Plot  </span><br><span class="line">- Protect  </span><br><span class="line">- Overheat  </span><br><span class="line"></span><br><span class="line">Hatterene-Gmax (F) @ Weakness Policy  </span><br><span class="line">Ability: Magic Bounce  </span><br><span class="line">Level: 50  </span><br><span class="line">EVs: 252 HP / 4 Def / 252 SpA  </span><br><span class="line">Quiet Nature  </span><br><span class="line">IVs: 0 Atk  </span><br><span class="line">- Psychic  </span><br><span class="line">- Dazzling Gleam  </span><br><span class="line">- Calm Mind  </span><br><span class="line">- Trick Room  </span><br><span class="line"></span><br><span class="line">Mew @ Aguav Berry  </span><br><span class="line">Ability: Synchronize  </span><br><span class="line">Level: 50  </span><br><span class="line">EVs: 252 HP / 252 Spe  </span><br><span class="line">Jolly Nature  </span><br><span class="line">IVs: 30 Atk  </span><br><span class="line">- Tailwind  </span><br><span class="line">- Transform  </span><br><span class="line">- Fake Out  </span><br><span class="line">- Helping Hand  </span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p><br></p>
<hr />
<p><br></p>
]]></content>
      <tags>
        <tag>Life</tag>
        <tag>Pokemon</tag>
      </tags>
  </entry>
  <entry>
    <title>快乐的喷喷生活</title>
    <url>/Game/Share-Splatoon2-Happiness/</url>
    <content><![CDATA[<p>[\]:Share-Splatoon2-Happiness</p>
<p>以此Blog记录我爱的 <em>Splatoon</em> 和朋友们.</p>
<p>封面 [ID:82331425].</p>
<span id="more"></span>
<h1 id="thanks-to">Thanks TO</h1>
<h2 id="先感谢专业摄影师-口一宝">先感谢专业摄影师
<em>口一宝</em>——————</h2>
<figure>
<img data-src="/images/body/Share-Splatoon2-Happiness/Photographer.png"
alt="Photographer" />
<figcaption aria-hidden="true">Photographer</figcaption>
</figure>
<h2 id="感谢和我一起玩的朋友们">感谢和我一起玩的朋友们</h2>
<ul>
<li>天才口一狗勾</li>
<li>蜜柑xbb</li>
<li>童泡泡</li>
<li>梨梨猫猫</li>
<li>浴缸狂魔钢蛋</li>
<li>还有海产群的以及和我一起快乐喷喷的各位!</li>
</ul>
<h1 id="gallery">Gallery</h1>
<p><img data-src="/images/body/Share-Splatoon2-Happiness/S(1).png" /> <img
src="/images/body/Share-Splatoon2-Happiness/S(2).png" /> <img
src="/images/body/Share-Splatoon2-Happiness/S(3).png" /> <img
src="/images/body/Share-Splatoon2-Happiness/S(4).png" /> <img
src="/images/body/Share-Splatoon2-Happiness/S(5).png" /> <img
src="/images/body/Share-Splatoon2-Happiness/S(6).png" /> <img
src="/images/body/Share-Splatoon2-Happiness/S(7).png" /> <img
src="/images/body/Share-Splatoon2-Happiness/S(8).png" /> <img
src="/images/body/Share-Splatoon2-Happiness/S(9).png" /></p>
]]></content>
      <categories>
        <category>Game</category>
      </categories>
      <tags>
        <tag>Life</tag>
        <tag>Splatoon</tag>
      </tags>
  </entry>
  <entry>
    <title>亲爱的宝可梦♡</title>
    <url>/Pokemon/See-My-Loving-Pokemons/</url>
    <content><![CDATA[<p>以此博客纪念我爱的宝可梦们~~ 封面 [ID:79498766].</p>
<span id="more"></span>
<h1 id="写在这里">写在这里：</h1>
<p>希望大家都能喜爱并珍惜与自己相遇的那些宝可梦！
享受宝可梦带来的快乐！</p>
<p><br><br></p>
<hr />
<hr />
<h1 id="チュチュ">チュチュ</h1>
<figure>
<img data-src="/images/body/See-My-Loving-Pokemons/kyukyu.png"
alt="チュチュ" />
<figcaption aria-hidden="true">チュチュ</figcaption>
</figure>
<h2 id="about">About</h2>
<p><img data-src="/images/body/See-My-Loving-Pokemons/kyukyu-Summary.png"
alt="Summary" /> - 种类：#778 <a
href="https://wiki.52poke.com/wiki/%E8%B0%9C%E6%8B%9F%EF%BC%B1">谜拟Q</a>
- 相遇时间：2021-01-03 - 相遇地点：阿罗拉地区乌拉乌拉岛超值超市旧址<img
src="/images/body/See-My-Loving-Pokemons/Thrifty-Megamart.png"
alt="Thrifty-Megamart" /> - 相遇版本：ポケットモンスター サン</p>
<p><img data-src="/images/body/See-My-Loving-Pokemons/kyukyu-Encounter1.png"
alt="Encounter1" /> <img
src="/images/body/See-My-Loving-Pokemons/kyukyu-Encounter2.png"
alt="Encounter2" /></p>
<p><br><br></p>
<hr />
<p><br><br></p>
<h1 id="volta">Volta</h1>
<figure>
<img data-src="/images/body/See-My-Loving-Pokemons/Volta.png" alt="Volta" />
<figcaption aria-hidden="true">Volta</figcaption>
</figure>
<h2 id="about-1">About</h2>
<p><img data-src="/images/body/See-My-Loving-Pokemons/Volta-Summary.png"
alt="Summary" /> - 种类：#478 <a
href="https://wiki.52poke.com/wiki/%E9%9B%AA%E5%A6%96%E5%A5%B3">雪妖女</a>
- 相遇时间：2021-04-19 - 相遇地点：丰缘地区浅滩洞穴冰之房间<img
src="/images/body/See-My-Loving-Pokemons/Hoenn_Shoal_Cave_Map.png"
alt="Thrifty-Megamart" /> - 相遇版本：Pokemon Ruby</p>
<figure>
<img data-src="/images/body/See-My-Loving-Pokemons/Volta-Encounter1.png"
alt="Encounter1" />
<figcaption aria-hidden="true">Encounter1</figcaption>
</figure>
<h2 id="plans">Plans</h2>
<ul>
<li>集齐3代奖章后传去4代进化.</li>
</ul>
<p><br><br></p>
<hr />
<p><br><br></p>
<h1 id="ivy">Ivy</h1>
<figure>
<img data-src="/images/body/See-My-Loving-Pokemons/Ivy.png" alt="Ivy" />
<figcaption aria-hidden="true">Ivy</figcaption>
</figure>
<h2 id="about-2">About</h2>
<p><img data-src="/images/body/See-My-Loving-Pokemons/Ivy-Summary.png"
alt="Summary" /> - 种类：#282 <a
href="https://wiki.52poke.com/wiki/%E6%B2%99%E5%A5%88%E6%9C%B5">沙奈朵</a>
- 相遇时间：2021-01-22 - 相遇地点：丰缘地区102号道路<img
src="/images/body/See-My-Loving-Pokemons/Route102.webp"
alt="Thrifty-Megamart" /> - 相遇版本：Pokemon Ruby</p>
<p><img data-src="/images/body/See-My-Loving-Pokemons/Ivy-Encounter1.png"
alt="Encounter1" /> ## Evolution <img
src="/images/body/See-My-Loving-Pokemons/Ivy-Evolution1.png"
alt="Evolution1" /> ## Plans - 集齐3代奖章.</p>
<p><br><br></p>
<hr />
<p><br><br></p>
<h1 id="jirachi">Jirachi</h1>
<figure>
<img data-src="/images/body/See-My-Loving-Pokemons/Jirachi.png"
alt="Jirachi" />
<figcaption aria-hidden="true">Jirachi</figcaption>
</figure>
<h2 id="about-3">About</h2>
<p><img data-src="/images/body/See-My-Loving-Pokemons/Jirachi-Summary.png"
alt="Summary" /> - 种类：#385 <a
href="https://wiki.52poke.com/wiki/%E5%9F%BA%E6%8B%89%E7%A5%88">基拉祈</a>
- 相遇时间：2021-02-18 - 相遇地点：<a
href="https://wiki.52poke.com/wiki/%E5%91%BD%E4%B8%AD%E6%B3%A8%E5%AE%9A%E8%88%AC%E7%9A%84%E7%9B%B8%E9%81%87">Fateful
Encounter</a>. - 相遇版本：Pokemon Ruby</p>
<figure>
<img data-src="/images/body/See-My-Loving-Pokemons/Jirachi-Encounter1.png"
alt="Encounter1" />
<figcaption aria-hidden="true">Encounter1</figcaption>
</figure>
<p><br><br></p>
<hr />
<p><br><br></p>
<h1 id="charizard">Charizard</h1>
<figure>
<img data-src="/images/body/See-My-Loving-Pokemons/Charizard.png"
alt="Charizard" />
<figcaption aria-hidden="true">Charizard</figcaption>
</figure>
<h2 id="about-4">About</h2>
<ul>
<li>种类：#006 <a
href="https://wiki.52poke.com/wiki/%E5%96%B7%E7%81%AB%E9%BE%99">喷火龙</a></li>
<li>相遇时间：2021-07-26</li>
<li>相遇地点：关都地区真新镇<img
src="/images/body/See-My-Loving-Pokemons/Pallet-Town.webp"
alt="Pallet Town" /></li>
<li>相遇版本：Pokemon Leaf Green</li>
</ul>
<p><img
src="/images/body/See-My-Loving-Pokemons/Charizard-Encounter1.png"
alt="Encounter1" /> ## Evolution <img
src="/images/body/See-My-Loving-Pokemons/Charizard-Evolution1.png"
alt="Evolution1" /> <img
src="/images/body/See-My-Loving-Pokemons/Charizard-Evolution2.png"
alt="Evolution2" /> ## Plans - 集齐3代奖章.</p>
<p><br><br></p>
<blockquote>
<p>Not The End. :D</p>
</blockquote>
<p><br><br></p>
<hr />
<p><br><br></p>
<h1 id="ditto">DITTO</h1>
<figure>
<img data-src="/images/body/See-My-Loving-Pokemons/DITTO.jpg" alt="DITTO" />
<figcaption aria-hidden="true">DITTO</figcaption>
</figure>
<h2 id="about-5">About</h2>
<p><img data-src="/images/body/See-My-Loving-Pokemons/DITTO-Summary.jpg"
alt="Summary" /> - 种类：#132 <a
href="https://wiki.52poke.com/wiki/%E7%99%BE%E5%8F%98%E6%80%AA">百变怪</a>
- 相遇时间：2022-05-07 - 相遇地点：关都地区红莲镇宝可梦屋<img
src="/images/body/See-My-Loving-Pokemons/Pokémon_Mansion.webp"
alt="Pokémon_Mansion" /> - 相遇版本：Pokemon Leaf Green</p>
<figure>
<img data-src="/images/body/See-My-Loving-Pokemons/DITTO-Encounter1.png"
alt="Encounter1" />
<figcaption aria-hidden="true">Encounter1</figcaption>
</figure>
<h2 id="plans-1">Plans</h2>
<ul>
<li>集齐全奖章.</li>
</ul>
<p><br><br></p>
<hr />
<hr />
<p><br><br></p>
<h1 id="more">More</h1>
<h2 id="第三世代">第三世代</h2>
<p><img data-src="/images/body/See-My-Loving-Pokemons/More/G3/G3(1).png" />
<img data-src="/images/body/See-My-Loving-Pokemons/More/G3/G3(2).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(3).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(4).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(5).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(6).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(7).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(8).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(9).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(10).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(11).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(12).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(13).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(14).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(15).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(16).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(17).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(18).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(19).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G3/G3(20).png" /></p>
<p><br><br></p>
<hr />
<p><br><br></p>
<h2 id="第四世代">第四世代</h2>
<p><img data-src="/images/body/See-My-Loving-Pokemons/More/G4/G4(1).png" />
<img data-src="/images/body/See-My-Loving-Pokemons/More/G4/G4(2).png" /></p>
<p><br><br></p>
<hr />
<p><br><br></p>
<h2 id="第五世代">第五世代</h2>
<p><img data-src="/images/body/See-My-Loving-Pokemons/More/G5/G5(1).png" />
<img data-src="/images/body/See-My-Loving-Pokemons/More/G5/G5(2).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G5/G5(3).png" /></p>
<p><br><br></p>
<hr />
<p><br><br></p>
<h2 id="第六世代">第六世代</h2>
<p><img data-src="/images/body/See-My-Loving-Pokemons/More/G6/G6(1).png" />
<img data-src="/images/body/See-My-Loving-Pokemons/More/G6/G6(2).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G6/G6(3).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G6/G6(4).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G6/G6(5).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G6/G6(6).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G6/G6(7).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G6/G6(8).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G6/G6(9).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G6/G6(10).png" /> <img
src="/images/body/See-My-Loving-Pokemons/More/G6/G6(11).png" /></p>
<p><br><br></p>
<hr />
<p><br><br></p>
<h2 id="第七世代">第七世代</h2>
<p>No Hurry.</p>
<p><br><br></p>
<hr />
<p><br><br></p>
<h2 id="第八世代">第八世代</h2>
<p>No Hurry.</p>
]]></content>
      <tags>
        <tag>Life</tag>
        <tag>Pokemon</tag>
      </tags>
  </entry>
  <entry>
    <title>如何备份你的存档</title>
    <url>/Pokemon/Strategies/In-Game/How-To-Back-Up-Your-Savefiles/</url>
    <content><![CDATA[<p>这篇文章是宝可梦正版正作卡带从 <em>Gen1</em> 到 <em>Gen7</em>
的存档提取与导入教程.
不局限于宝可梦正作，其他卡带也可以通过同样的方法提取.
如果你对备份存档感到介意，请根据自身情况取舍.</p>
<p>封面 [ID:86927624].</p>
<span id="more"></span>
<h1 id="写在前面">写在前面</h1>
<p>已经有人在贴吧写了详细的傻瓜教程，比我写的详细很多：<a
href="https://tieba.baidu.com/p/6349601583?share=9105&amp;fr=sharewise&amp;see_lz=0&amp;share_from=post&amp;sfc=copy&amp;client_type=2&amp;client_version=12.15.1.0&amp;st=1640142523&amp;unique=9EBFF40D479B24A05CA7FA461487C5A9&amp;qq-pf-to=pcqq.group&amp;red_tag=0588212229">【教程】全版本正版游戏卡带存档导出导入教程</a>
这篇注重于收录常规方法而非详细教程（都有写的那么详细的了）.</p>
<p>除了下面提到的方法，更多方法请参考<a
href="https://projectpokemon.org/home/forums/topic/15107-nds-how-to-backuprestore-your-retail-cartridge-save-file-for-ds-games/">NDS:
How to Backup/Restore your retail cartridge save file for DS
games</a>.</p>
<h1 id="gb-与-gbc-卡带"><em>GB</em> 与 <em>GBC</em> 卡带</h1>
<p>包含的宝可梦卡带有：</p>
<ul>
<li>宝可梦 红 / 绿 / 蓝 / 黄</li>
<li>宝可梦 金 / 银 / 水晶</li>
</ul>
<p>这类应该只能通过特殊设备提取与导入，如 <em>Flash Boy</em> 、 <em>GB
Operator</em> 等.</p>
<h2 id="flash-boy"><em>Flash Boy</em></h2>
<p><img data-src="/images/body/How-To-Back-Up-Your-Savefiles/Flash-Boy1.png"
alt="Flash Boy" /> <img
src="/images/body/How-To-Back-Up-Your-Savefiles/Flash-Boy2.png"
alt="Flash Boy" /> 在各电商应该都有购买方式.</p>
<h2 id="gb-operator"><em>GB Operator</em></h2>
<p><a
href="https://www.epilogue.co/product/gb-operator">官网地址</a></p>
<figure>
<img data-src="/images/body/How-To-Back-Up-Your-Savefiles/GB-Operator.gif"
alt="GB Operator" />
<figcaption aria-hidden="true">GB Operator</figcaption>
</figure>
<blockquote>
<p>注意，这类卡带的存档依赖电池，如果电池没电了会导致存档丢失.</p>
</blockquote>
<h1 id="gba-卡带"><em>GBA</em> 卡带</h1>
<p>包含的宝可梦卡带有：</p>
<ul>
<li>宝可梦 红宝石 / 蓝宝石 / 绿宝石</li>
<li>宝可梦 火红 / 叶绿</li>
</ul>
<p>这类存档提取与导入可以通过：</p>
<ol type="1">
<li>使用特殊设备提取，如上述 <em>Flash Boy</em> 、 <em>GB
Operator</em>.</li>
<li>使用 <em>初版 NDS</em> 或 <em>NDS lite</em> 配合 NDS
烧录卡与存档提取软件 <strong><em>GBA Backup Tool</em></strong>.</li>
</ol>
<ul>
<li><a
href="https://www.gamebrew.org/wiki/GBA_Backup_Tool">使用方法</a></li>
<li><span class="exturl" data-url="aHR0cHM6Ly90aWViYS5iYWlkdS5jb20vcC80MTkxNDAwNzQ1">使用方法 -
中文<i class="fa fa-external-link-alt"></i></span></li>
<li><a href="/download/GBA-Backup-Tool.nds">下载</a></li>
<li><a href="/Game/DSTWO/">DSTWO相关资源整理</a></li>
</ul>
<figure>
<img
src="/images/body/How-To-Back-Up-Your-Savefiles/GBA-Backup-Tool.png"
alt="GBA Backup Tool" />
<figcaption aria-hidden="true">GBA Backup Tool</figcaption>
</figure>
<h1 id="nds-与-3ds-卡带-以及-3ds-vc-系列"><em>NDS</em> 与 <em>3DS</em>
卡带 以及 <em>3DS</em> <strong>VC</strong> 系列</h1>
<p>包含的宝可梦卡带有：</p>
<ul>
<li>宝可梦 珍珠 / 钻石 / 白金</li>
<li>宝可梦 心金 / 魂银</li>
<li>宝可梦 黑 / 白</li>
<li>宝可梦 黑2 / 白2</li>
<li>宝可梦 X / Y</li>
<li>宝可梦 欧米伽红宝石／阿尔法蓝宝石</li>
<li>宝可梦 日 / 月</li>
<li>宝可梦 究极之日 / 究极之月</li>
<li>宝可梦 VC 系列</li>
</ul>
<p>这类存档提取与导入需要使用破解 <em>3DS</em> ，想要破解 <em>3DS</em>
请参见：<span class="exturl" data-url="aHR0cHM6Ly9zdHJheS1zb3VsLmNvbS8=">一只火狐的杂物间<i class="fa fa-external-link-alt"></i></span>.
请具备一定的破解 3DS 软件安装能力.</p>
<ul>
<li>使用 <em>3DS</em> 存档提取软件 <strong><em>CheckPoint</em></strong>
（推荐）或者 <strong><em>TWLSaveTool</em></strong> .
<ul>
<li><a
href="https://projectpokemon.org/home/tutorials/save-editing/managing-3ds-saves/using-checkpoint-r25/">CheckPoint使用方法</a></li>
<li><a
href="https://projectpokemon.org/home/tutorials/save-editing/managing-nds-saves/using-twl-save-tool-r59/">TWLSaveTool使用方法</a></li>
<li><a
href="https://github.com/FlagBrew/Checkpoint/releases">CheckPoint下载</a></li>
<li><a
href="https://github.com/TuxSH/TWLSaveTool/releases">TWLSaveTool下载</a></li>
</ul></li>
</ul>
<p>Checkpoint界面： <img
src="/images/body/How-To-Back-Up-Your-Savefiles/CheckPoint.png"
alt="CheckPoint" /> TWLSaveTool界面： <img
src="/images/body/How-To-Back-Up-Your-Savefiles/TWLSaveTool.png"
alt="TWLSaveTool" /></p>
<h1 id="已失效的与未经测试的-3ds-卡带存档提取外设">已失效的与未经测试的
<em>3DS</em> 卡带存档提取外设</h1>
<h2 id="cyber-save-editor"><strong>Cyber Save Editor</strong></h2>
<p><img
src="/images/body/How-To-Back-Up-Your-Savefiles/Cyber-Save-Editor01.png"
alt="Cyber Save Editor" /> &gt; 网站已经停止服务了，应该仅支持日版.</p>
<figure>
<img
src="/images/body/How-To-Back-Up-Your-Savefiles/Cyber-Save-Editor02.jpg"
alt="Cyber Save Editor" />
<figcaption aria-hidden="true">Cyber Save Editor</figcaption>
</figure>
<h2 id="cyber-save-editor-2"><strong>Cyber Save Editor 2</strong></h2>
<p>普通版 <img
src="/images/body/How-To-Back-Up-Your-Savefiles/Cyber-Save-Editor03.png"
alt="Cyber Save Editor 2" /> <img
src="/images/body/How-To-Back-Up-Your-Savefiles/Cyber-Save-Editor04.png"
alt="Cyber Save Editor 2" /> <br></p>
<p>典藏版 <img
src="/images/body/How-To-Back-Up-Your-Savefiles/Cyber-Save-Editor05.webp"
alt="Cyber Save Editor 2" /> &gt;
<strong>仅支持日版</strong>，是否停止服务未知，如果你知道，请<a
href="/about/">与我联系</a>. - <a
href="https://www.tldevtech.com/best-3ds-save-editor-cyber-save-editor/">Cyber
Save Editor 2使用方法</a></p>
<h1 id="写在最后">写在最后</h1>
<p>不建议滥用存档导入导出，还请保持对游戏、对宝可梦的热爱进行使用！
如果你知道更多的方法，还请<a href="/about/">不吝赐教</a>！</p>
]]></content>
      <categories>
        <category>Pokemon</category>
      </categories>
      <tags>
        <tag>Pokemon</tag>
      </tags>
  </entry>
  <entry>
    <title>宝可梦绿宝石及没有电的红蓝宝石实机乱数（不包含 ID 或 Egg）</title>
    <url>/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part1/</url>
    <content><![CDATA[<p>这是宝可梦绿宝石及没电红蓝宝石的实机乱数教程. 不包含 ID 与 Egg
的乱数教程. 如有纰漏，请<a href="/about/">与我联系</a>，万分感谢！</p>
<p>封面 [ID:57789285]. <span id="more"></span></p>
<p><strong>注意，本教程仅支持：</strong></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Support</th>
<th style="text-align: center;">红蓝宝石</th>
<th style="text-align: center;">绿宝石</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">电池有电</td>
<td style="text-align: center;">✘</td>
<td style="text-align: center;">✔</td>
</tr>
<tr class="even">
<td style="text-align: center;">电池没电</td>
<td style="text-align: center;">✔</td>
<td style="text-align: center;">✔</td>
</tr>
</tbody>
</table>
<p>如果你在找有电的红蓝宝石实机乱数教程，请点击<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part2/">这里</a>.</p>
<p>如果你在找火红叶绿的实机乱数，请点击<a
href="/Pokemon/Strategies/In-Game/RNG/Pokemon-RNG-Abuse-Gen3-Part3/">这里</a>.</p>
<blockquote>
<p>实机很难实现，难度很高.</p>
</blockquote>
<h1 id="准备工作">准备工作</h1>
<p>如果你想要乱数闪光宝可梦，你需要知道你的<a
href="https://wiki.52poke.com/wiki/ID_No.#.E9.87.8CID_No.">SID</a>.</p>
<blockquote>
<p>如果你想要乱数的是已经创建好的存档，这可能会需要你导出存档并使用
<em>PKHex</em>
等软件查看你的存档（不涉及修改与导入），请根据自身接受程度使用.</p>
</blockquote>
<blockquote>
<p>由于我没有怎么研究过乱数ID，所以如果你想要乱数ID，请参考：<a
href="https://www.smogon.com/ingame/rng/rs_nonbredrng#idsid">Smogon ID
乱数教程</a>.<br> 之后如果自己研究了一遍就会上传Blog.</p>
</blockquote>
<blockquote>
<p>不会导出存档？看看这篇博客：<a
href="/Pokemon/Strategies/In-Game/How-To-Back-Up-Your-Savefiles/">如何备份你的存档</a>.</p>
</blockquote>
<h2 id="硬件准备">硬件准备</h2>
<ul>
<li>能够游玩第三世代宝可梦卡带的机器（<em>GBA</em>系列、初代<em>NDS</em>
或 <em>NDS lite</em>，不推荐使用 <em>NGC</em>）.</li>
<li>电脑.</li>
<li>（若使用初代<em>NDS</em> 或 <em>NDS
lite</em>可选）<em>NDS</em>烧录卡与读卡器.</li>
</ul>
<blockquote>
<p>使用
<em>NDS</em>烧录卡提取存档进行查看可以大幅节省部分步骤的时间，强烈推荐.请根据自身接受程度使用.<br>
如果不准备使用烧录卡，请准备足够的神奇糖果.</p>
</blockquote>
<h2 id="下载乱数所需工具">下载乱数所需工具：</h2>
<ul>
<li>计时器<a href="/download/CCTimer.rar">CCTimer</a>
因为没有找到该软件的发布页，所以上传至仓库可直接点击下载，如果你知道它的发布页，请与我联系.</li>
<li>乱数工具<a
href="https://www.dropbox.com/sh/68qqg26op3uaymc/AAC8QFFKYxAqQjG80abgcHZ1a?dl=0">3genSearch</a>
国内需要科学上网，因原作者禁止二次发布所以这里不提供直接下载，可以通过各搜索引擎找到别人的分享.</li>
<li>乱数工具<a
href="https://github.com/Admiral-Fish/RNGReporter/releases">RNGReporter</a>
如果因为国内 GitHub 下载速度原因不好下载，可以点击<a
href="/download/RNGReporter.zip">这里</a>进行下载.</li>
</ul>
<blockquote>
<p>两个乱数工具选择任意一个都可以，本教程使用的是 <em>3genSearch</em>.
RNGReporter的使用与之类似，还请读者自行探索.</p>
</blockquote>
<h2 id="了解乱数机制">了解乱数机制</h2>
<p>我会尽量讲的简洁易懂一些，了解乱数机制可以为你理解每一步所做的原因，同时掌握各种乱数方法也会更迅速牢固.</p>
<h3 id="随机数">随机数</h3>
<blockquote>
<p>真正意义上的随机数（或者随机事件）在某次产生过程中是按照实验过程中表现的分布概率随机产生的，其结果是不可预测的，是不可见的。而计算机中的随机函数是按照一定算法模拟产生的，其结果是确定的，是可见的。我们可以这样认为这个可预见的结果其出现的概率是100%。所以用计算机随机函数所产生的“随机数”并不随机，是伪随机数。</p>
</blockquote>
<h3 id="游戏机制与乱数目标">游戏机制与乱数目标</h3>
<p>由于宝可梦绿宝石与没有电的红蓝宝石（以下简称
<strong><em>E</em></strong> 与 <strong><em>RS</em></strong>
）的初始seed相同（<strong><em>E</em></strong> :
<code>0x 0</code>，<strong><em>RS</em></strong> :
<code>0x 5A0</code>），而当进入游戏后，会以每秒约60帧的速度过帧（根据运行机器不同会有极小差别）.当游戏判断需要生成一只宝可梦的时候便会使用当前帧的数据来生成，我称之为
<em>生成帧</em> . <em>3genSearch</em> 与 <em>RNGReporter</em>
都可以用来获取一个seed下产生的帧的信息.
我们的目标就是在某一seed下准确击中想要的帧数，即控制
<em>生成帧</em>.</p>
<h2 id="确定乱数目标">确定乱数目标</h2>
<p><strong><em>如果选择了野外相遇的宝可梦，请在队伍中准备一只习得了<a
href="https://wiki.52poke.com/wiki/%E7%94%9C%E7%94%9C%E9%A6%99%E6%B0%94%EF%BC%88%E6%8B%9B%E5%BC%8F%EF%BC%89#.E5.8F.AF.E4.BB.A5.E5.AD.A6.E4.BC.9A.E8.AF.A5.E6.8B.9B.E5.BC.8F.E7.9A.84.E5.AE.9D.E5.8F.AF.E6.A2.A6">甜甜香气</a>的宝可梦.</em></strong>
确定乱数目标后，选择相应的 <em>Method</em>. 如果是乱数蛋，请参阅<a
href="https://www.smogon.com/ingame/rng/emerald_rng_part4">这里</a>.</p>
<h3 id="method-1"><em>Method 1</em></h3>
<ul>
<li>御三家（<strong><em>RS</em></strong>、<strong><em>E</em></strong>
一周目与 <strong><em>E</em></strong> 二周目）</li>
<li>定点宝可梦</li>
<li>釜炎镇 NPC 赠送的小果然的蛋</li>
<li><strong><em>RS</em></strong> 通过甜甜香气遭遇的宝可梦</li>
<li><strong><em>RS</em></strong> 通过钓鱼遭遇的宝可梦（除丑丑鱼）</li>
<li><strong><em>RS</em></strong> 通过碎岩遭遇的宝可梦</li>
</ul>
<h3 id="method-2"><em>Method 2</em></h3>
<ul>
<li>草丛/海草/深沙/洞穴/水上/可以遇到宝可梦的建筑中通过移动/转向
遭遇的宝可梦（除了游走宝可梦）</li>
<li><strong><em>E</em></strong> 通过甜甜香气遭遇的宝可梦</li>
<li><strong><em>E</em></strong> 钓鱼钓上来的宝可梦</li>
<li><strong><em>E</em></strong> 通过碎岩遇到的宝可梦</li>
</ul>
<h3 id="method-4"><em>Method 4</em></h3>
<ul>
<li>钓鱼钓上来的丑丑鱼</li>
</ul>
如果是 <em>Method
1</em>中的前三类，点击下面的谜拟Q来查看保存游戏的位置与生成帧的所在时机（
<strong><em>E</em></strong> 与 <strong><em>RS</em></strong>
有些会有区别）：
<details>
<summary>
<img no-lazy data-src="/images/mimikyu.png" alt="Method 2 请点击丘丘" align=left>
</summary>
<br> -- 御三家：在博士的包前保存，在问你“Do you choose this
POKéMON?”时等待生成帧 <br> -- 飘浮泡泡：在反派干部前保存，在研究员说“It
might be an odd way of thanking you, but take this POKéMON.”时等待生成帧
<br> --
游走水都：击败冠军后在出自己的房间门前存档，在让你选择红蓝时等待生成帧
<br> -- 复活化石：在研究员前保存，在他说“The fossil was an ancient
POKéMON. [LILEEP/ANORITH], it was!”时等待生成帧 <br> -- 小果然的蛋：在
NPC 前存档，在她说“Good! I hope you'll walk plenty with this here
EGG!”时等待生成帧 <br> -- 变隐龙：在隐形的变隐龙前存档，在提示“The
startled POKéMON attacked!”时等待生成帧 <br> --
大吾的铁哑铃：在精灵球前存档，在选择是否拿走时等待生成帧 <br> --
胡说树：在其面前存档，在提示“The weird tree attacked!”时等待生成帧 <br>
--
盖欧卡与固拉多：在距离剧情触发前一步存档，在进入战斗前最后一段时等待生成帧
<br> -- 凤王：Save on the first space of the peak of the cliff. Last
input is pressing up on the directional pad to place yourself on the
second space of the cliff. <br> -- 梦幻：Save in the area it appears in.
Last input is a press of the A button to "tag" it. <br> --
其他：在宝可梦/触发物前保存，在进入战斗前最后一段时等待生成帧 <br> <br>
凤王和梦幻的不知道怎么表达比较好，看英文感受一下.
</details>
<p><br><br></p>
<p>如果是 <em>Method 2</em> 或 <em>Method 1</em>
的后三类，在进入战斗前最后一次点击作为生成帧. &gt;
实际生成帧可能会更往后，如甜甜香气，但这段时间是固定的，可以通过多次尝试来更新.</p>
<h1 id="开始乱数">开始乱数</h1>
<h2 id="搜索目标宝可梦">搜索目标宝可梦</h2>
<p>打开乱数工具，选择/填入图中红框中内容： <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part1/Figure1.png"
alt="Figure1" /></p>
<ol type="1">
<li>根据乱数目标选择<em>固定</em>或<em>野生</em>.</li>
<li>如果选择了<em>野生</em>，可以修改绿框中的地点、版本信息.</li>
<li>输入初期 seed，<strong><em>E</em></strong> 为
0，<strong><em>RS</em></strong> 为 5A0.</li>
<li>F为搜索帧数的范围，建议800~100000，因为 seed
固定了所以可能很靠后才有你想要的帧.（1秒约60帧，请自行推测是否有耐心）（请根据实际情况调整，如甜甜香气动画较长，所以起始帧会高一些）.</li>
<li><em>Method</em> 选择之前确定的 <em>Method</em>.</li>
<li>检索区域根据自己的需要填写，若勾选
<strong><em>只显示异色</em></strong> ，需要在勾选框上方填入表里ID.</li>
<li>点击黑框<em>计算</em>，得到结果.</li>
</ol>
<blockquote>
<p>没有想要的宝可梦怎么办？<br>
不建议帧数再加了，10w帧约27.8分钟了，可以试着降低一下要求.<br></p>
</blockquote>
<blockquote>
<p>闪帧太靠后了怎么办？<br> 换个存档叭. 太非了这个档.</p>
</blockquote>
<p>在结果中选择一个满意的结果作为目标帧，将其
<strong><em>F</em></strong>
栏（即为你的<em>目标帧</em>）填入蓝框中（蓝框后面的内容不需要管）.</p>
<h2 id="校准误差">校准误差</h2>
<p><strong><em>如果你的目标宝可梦不是野外宝可梦（如定点宝可梦）且准备使用烧录卡协助乱数，那么要在步骤1结束后，使用GBA_Backup软件将存档提取出来</em></strong>
&gt; GBA_Backup软件可在<a
href="/How-To-Back-Up-Your-Savefiles/">这里</a>找到.</p>
<ol type="1">
<li><p>在游戏中你应该存档的位置存档（如果你准备在洞穴或是能出现宝可梦的建筑中使用甜甜香气，请往深处走一些距离，否则甜甜香气可能会失效），存档完成后关机.</p></li>
<li><p>打开计时器 <em>CCTimer</em>，选择
<em>Setting</em>，点击红框内容，根据游戏平台选择对应选项. <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part1/Figure2.png"
alt="Figure2" /></p></li>
<li><p>回到 <em>Timer</em>，在蓝框内填入你刚刚的 <em>目标帧</em> 并点击
<strong><em>Add</em></strong> . <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part1/Figure3.png"
alt="Figure3" /></p></li>
<li><p>点击 <strong><em>Start</em></strong>
按钮的同时开始游戏(gba系列和设置过的nds是直接开机，未设置过的nds系列是在主页面点击GBA游戏图标).</p></li>
<li><p>在游戏中快速到达目标帧的确定位置（如：在选择宝可梦使用甜甜香气的界面）.</p></li>
<li><p>在 <em>CCTimer</em> 上的倒计时归零的瞬间按下机器的
<strong><em>A</em></strong> 键，然后等待进入战斗界面.</p></li>
<li><p>捕捉这只宝可梦.</p></li>
<li><ul>
<li>如果你不准备使用烧录卡：将宝可梦的性格、等级、能力值等输入个体值计算软件得到其个体，如果无法得到唯一的个体，使用足够多的神奇糖果后重试.
这之后，关闭游戏.
<strong><em>如果你的目标宝可梦不是野外宝可梦（如定点宝可梦），记住不要保存</em></strong></li>
<li>如果你准备使用烧录卡：保存并关闭游戏，使用GBA_Backup软件提取出存档，使用读卡器连接到电脑后使用
<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2t3c2NoL1BLSGVYL3JlbGVhc2Vz">PKHex<i class="fa fa-external-link-alt"></i></span>
软件打开存档，查看刚捕捉的宝可梦的数据.</li>
</ul></li>
<li><p>回到乱数工具，在黄框中填入刚捕捉到的宝可梦数据（如果不是闪光记得不要勾选
<strong><em>只显示异色</em></strong> ），点击 <em>计算</em>.
记下橙色框中的数字（如有多个，选择离<em>目标帧</em>最近的）. <img
src="/images/body/Pokemon-RNG-Abuse-Gen3-Part1/Figure4.png"
alt="Figure4" /></p></li>
<li><p>回到
<em>CCTimer</em>，计算<em>目标帧</em>减去刚刚橙色框中的数字的值，点击
<strong><em>Clear</em></strong> 按钮清除后输入该值并点击
<strong><em>Add</em></strong> .</p>
<blockquote>
<p>例如 CCTimer 中的值（目标帧）是2156，击中帧是2177，2156 - 2177 =
-21（橙色框中数字为 21），那么将 CCTimer 中的值更新为 2156 - 21 =
2135.</p>
</blockquote></li>
</ol>
<p>误差校准完成.</p>
<blockquote>
<p>注意，如果你更换了目标，即宝可梦获得方式改变（如Method不同 或
由游戏厅切换为固拉多），请重新进行误差校准！</p>
</blockquote>
<h2 id="乱数">乱数</h2>
<p><strong><em>如果你的目标宝可梦不是野外宝可梦（如定点宝可梦）且使用烧录卡协助乱数，那么先使用GBA_Backup软件将备份存档导入</em></strong>
和校准误差的4、5、6步一致： 1. 点击 <strong><em>Start</em></strong>
按钮的同时开始游戏. 2. 在游戏中快速到达目标帧的确定位置. 3. 在
<em>CCTimer</em> 上的倒计时归零的瞬间按下机器的
<strong><em>A</em></strong> 键，然后等待进入战斗界面. 4.
如果得到的不是<em>目标帧</em>，可以选择再次进行误差校准或者再多尝试几次.</p>
<blockquote>
<p>因为手工操作多少会有些误差，建议多尝试几次，若十几二十次失败再考虑重新校准误差.</p>
</blockquote>
<ol start="5" type="1">
<li>乱数成功，得到目标！</li>
</ol>
<h1 id="reference">Reference</h1>
<ul>
<li><a
href="https://taiyaki3gen.hatenablog.com/entry/2020/05/30/162400">3genSearch
作者博客</a></li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cuc21vZ29uLmNvbS9pbmdhbWUvcm5nLw==">Smogon RNG
教程<i class="fa fa-external-link-alt"></i></span></li>
<li><a
href="https://www.bilibili.com/video/BV14Z4y1M7rM?share_source=copy_web">呆呆兽都能学会的【三代定点宝可梦乱数教程】
-- 百分之零点六 哔哩哔哩</a></li>
</ul>
<h1 id="appreciation">Appreciation</h1>
<ul>
<li>感谢<strong>Rai</strong>为我纠正了一些错误.</li>
</ul>
]]></content>
      <categories>
        <category>Pokemon</category>
      </categories>
      <tags>
        <tag>Pokemon</tag>
        <tag>Pokemon-RNG-Abuse</tag>
        <tag>Pokemon-Gen3</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Hexo与GitHub制作私人博客</title>
    <url>/Learning/Blog/Build-Your-Own-Blog-Like-This-One/</url>
    <content><![CDATA[<p>想要搭建自己的博客？跟着这篇文章做下去，谜拟Q都能搭出私人博客！</p>
<p>以此文章记录丘丘Blog的制作过程.</p>
<p>封面 [ID:91018415]. <span id="more"></span></p>
<h1 id="前言">前言</h1>
<p><strong>注意，这篇仅针对Windows用户，如果你的系统是Mac或者Linux，请参考<a
href="https://hexo.io/zh-cn/docs/">官方文档</a>.</strong></p>
<p>说实话我做Blog就是为了记录分享，最重要的是很有意思，捣鼓捣鼓出来很有成就感.
不过我觉得这篇知乎专栏写的很不错，有兴趣的可以看看.</p>
<p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xOTc0Mzg2MQ==">为什么你要写博客？ -
陈素封的文章 - 知乎<i class="fa fa-external-link-alt"></i></span></p>
<p>接下来我将记录一下这个博客的搭建与完善过程.</p>
<p>谜拟Q都能看懂的博客搭建教程 开工！</p>
<h1 id="搭建">搭建</h1>
<p>这部分主要实现博客的从无到有，是做成自己独一无二博客的基础.</p>
<h2 id="github">GitHub</h2>
<h3 id="注册-github-账号">注册 GitHub 账号</h3>
<p>这个很简单，<a
href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F&amp;source=header-home">点击这里</a>来创建
GitHub 账号.</p>
<h3
id="在个人主界面里选择创建一个新的-repository">在个人主界面里选择创建一个新的
<em>Repository</em></h3>
<p><em>Repository name</em> 处填写 <code>username.github.io</code>. 其中
<em>username</em> 是你的 GitHub 用户名. <strong>请勾选 <em>Add a README
file</em> 选项.</strong> <img
src="/images/body/Build-Your-Own-Blog-Like-This-One/Figure1.png"
alt="Figure1" /> &gt; 图中因为我已经创建过了，所以会报错.</p>
<p>创建后默认自动启用 HTTPS，博客地址为：https://username.github.io.
其中 <em>username</em> 是你的 GitHub 账号名.
（不过可能进去没啥东西）</p>
<h2 id="环境搭建">环境搭建</h2>
<p>Hexo 基于 Node.js，搭建过程中还需要使用 <code>npm</code>（Node.js
已带） 和 <code>git</code>，因此先搭建本地操作环境，安装 Node.js 和
Git.</p>
<blockquote>
<p>这里我全部按默认配置完成安装</p>
</blockquote>
<h3 id="安装-node.js">安装 Node.js</h3>
<p>访问 <span class="exturl" data-url="aHR0cHM6Ly9ub2RlanMub3JnL2VuLw==">Node.js
官方网站<i class="fa fa-external-link-alt"></i></span>下载并安装Node.js . 这里我选择的是LTS版本（16.13.1），当前
<span class="exturl" data-url="dHRwczovL2hleG8uaW8vemgtY24vZG9jcy8=">Hexo 官方文档<i class="fa fa-external-link-alt"></i></span>建议 Node.js
版本高于12.0.0，可随时确认.</p>
<blockquote>
<p>此外，使用 Node.js 官方安装程序时，请确保勾选 <em>Add to PATH</em>
选项（默认已勾选）</p>
<p>安装完成后，组合键<kbd>Win</kbd>+<kbd>R</kbd> 输入 <code>cmd</code>
并打开，依次输入
<code>node -v</code>、<code>npm -v</code>并回车，如下图出现程序版本号即安装成功.</p>
</blockquote>
<figure>
<img data-src="/images/body/Build-Your-Own-Blog-Like-This-One/Figure2.png"
alt="Figure2" />
<figcaption aria-hidden="true">Figure2</figcaption>
</figure>
<h3 id="安装-git">安装 Git</h3>
<p>访问 <span class="exturl" data-url="aHR0cHM6Ly9naXQtc2NtLmNvbS9kb3dubG9hZC93aW4=">Git
官方下载地址<i class="fa fa-external-link-alt"></i></span>下载并安装 Git.</p>
<blockquote>
<p>安装完成后，组合键 <kbd>Win</kbd>+<kbd>R</kbd> 输入 <code>cmd</code>
并打开，输入
<code>git --version</code>、并回车，如下图出现程序版本号即安装成功.</p>
</blockquote>
<figure>
<img data-src="/images/body/Build-Your-Own-Blog-Like-This-One/Figure3.png"
alt="Figure3" />
<figcaption aria-hidden="true">Figure3</figcaption>
</figure>
<h2 id="连接-github">连接 GitHub</h2>
<p>打开 <em>Git Bash</em> ，输入以下代码设置用户名和邮箱： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --global user.name &quot;GitHub 用户名&quot;</span><br><span class="line">git config --global user.email &quot;GitHub 邮箱&quot;</span><br></pre></td></tr></table></figure>
&gt; 用自己的 GitHub 用户名与邮箱替代代码中的相应部分.</p>
<h3 id="创建-ssh-密钥">创建 SSH 密钥</h3>
<p>继续输入代码<code>ssh-keygen -t rsa -C "GitHub 邮箱"</code>
然后一路回车.</p>
<h3 id="添加密匙">添加密匙</h3>
<p>进入 &lt;C:\.ssh&gt;
目录（可能需要勾选显示“隐藏的项目”，如果没有，请查看输出信息中的默认生成位置），用记事本打开公钥
<em>id_rsa.pub</em> 文件并复制里面的内容.</p>
<p>登陆 GitHub ，进入个人 <em>Settings</em> 页面，选择左边栏的 <em>SSH
and GPG keys</em> ，点击 <em>New SSH key</em>.</p>
<p>Title 随便填写一个名字，将 <em>id_rsa.pub</em> 内容复制粘贴到 Key
中，点击 <em>Add SSH key</em> 完成添加. <img
src="/images/body/Build-Your-Own-Blog-Like-This-One/Figure4.png"
alt="Figure4" /></p>
<h3 id="验证连接">验证连接</h3>
<p>打开 <em>Git Bash</em>，输入 <code>ssh -T git@github.com</code> 出现
<strong><em>“Are you sure……”</em></strong> 字样时，输入 <em>yes</em>
并回车确认.</p>
<p>显示 <strong><em>“Hi xxx! You've successfully……”</em></strong>
即连接成功.</p>
<h2 id="安装-hexo">安装 Hexo</h2>
<p>在喜欢的位置创建一个空文件夹，打开 <em>Git Bash</em> 利用
<code>cd</code> 命令移动至此文件夹.</p>
<blockquote>
<p>之后若无特殊说明则将此文件夹称为根目录</p>
</blockquote>
<p>输入 <code>npm install -g hexo-cli</code> 回车进行安装.</p>
<p>安装完成后输入以下代码： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo init   #初始化 hexo</span><br><span class="line">hexo g  # 生成页面</span><br><span class="line">hexo s  # 启用预览，默认端口4000</span><br></pre></td></tr></table></figure> 访问<a
href="http://localhost:4000" class="uri">http://localhost:4000</a>，出现
Hexo 默认页面，则本地博客安装成功.</p>
<blockquote>
<p>使用组合键 <kbd>Ctrl</kbd>+<kbd>C</kbd> 来关闭本地预览服务.</p>
<p>若组合键 <kbd>Ctrl</kbd>+<kbd>C</kbd> 没有效果，可打开 <em>cmd</em>
运行 <code>taskkill /f /t /im node.exe</code> 来关闭服务.</p>
<p>如果出现页面加载不出来，可能是端口被占用了. 组合键
<kbd>Ctrl</kbd>+<kbd>C</kbd> 关闭服务器，运行
<code>hexo server -p 5000</code> 更改端口号为5000后重试.</p>
</blockquote>
<p>Hexo 博客文件夹目录结构如下：(图源水印) <img
src="/images/body/Build-Your-Own-Blog-Like-This-One/Figure5.jpg"
alt="Figure5" /></p>
<h2 id="部署-hexo-到-github-pages">部署 Hexo 到 GitHub Pages</h2>
<p>在 <em>Git Bash</em> 中运行
<code>npm install hexo-deployer-git --save</code>.</p>
<p>打开根目录，找到文件 *_config.yml* 并打开，修改文件末尾的 Deployment
部分为： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: git@github.com:用户名/用户名.github.io.git</span><br><span class="line">  branch: main</span><br></pre></td></tr></table></figure> &gt; 用自己的 GitHub 用户名替换代码相应部分</p>
<p>接着，在 <em>Git Bash</em> 中运行 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo d  # 部署博客</span><br></pre></td></tr></table></figure></p>
<p>这时访问自己的 GitHub 域名 <span class="exturl" data-url="aHR0cHM6Ly91c2VybmFtZS5naXRodWIuaW8=">https://username.github.io<i class="fa fa-external-link-alt"></i></span> 就可以看到 Hexo 网站了.</p>
<p><br><br><br>到这里私人博客的搭建就差不多了，接下来便是去安装 hexo
的<span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL3RoZW1lcy8=">主题<i class="fa fa-external-link-alt"></i></span>与<a
href="https://hexo.io/plugins/">插件</a>了.</p>
<h1 id="完善">完善</h1>
<p>这部分将你的博客个性化，来创造自己独一无二的博客吧！</p>
<h2 id="选择并安装主题">选择并安装主题</h2>
<p>在 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL3RoZW1lcy8=">Themes | Hexo<i class="fa fa-external-link-alt"></i></span>
选择一个喜欢的主题，按照官方文档进行安装即可. 这里我选择的是 <a
href="https://zhwangart.com/2018/11/30/Ocean/">Ocean 主题</a>.</p>
<p>因为官方文档的步骤都十分详细，因此这里不展开细说.
一般主题所需的插件也会在官方文档中提供安装与使用方法.</p>
<h2 id="完成">完成</h2>
<p>跟着官方文档做下去，再按照自己的需求更改，个性化的博客便做好了.
可以参考这篇文章<a
href="/Learning/Blog/Blog-Personalization/">博客个性化笔记----基于Ocean</a>.</p>
<h1 id="reference">Reference</h1>
<p><a
href="https://www.zhihu.com/question/20962496/answer/677815713">如何在
GitHub 上写博客？ - 少数派的回答 - 知乎</a></p>
<p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82MDU3ODQ2NA==">使用 Hexo+GitHub
搭建个人免费博客教程（小白向） - crystal的文章 - 知乎<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL3poLWNuL2RvY3Mv">Hexo 官方中文文档<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly96aHdhbmdhcnQuY29tLzIwMTgvMTEvMzAvT2NlYW4v">Ocean
官方文档<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>Blog</tag>
        <tag>Practical-Tips</tag>
        <tag>GitHub</tag>
        <tag>Hexo</tag>
        <tag>Ocean</tag>
      </tags>
  </entry>
  <entry>
    <title>解决访问GithHub速度慢的问题</title>
    <url>/Learning/Solutions/Accessing-GitHub-Slowly-Solution/</url>
    <content><![CDATA[<p>今天早上上 GitHub 又没上上去，去网上找了一下原因是 GitHub 的 CDN
域名遭到了 DNS 污染，导致无法连接使用 GitHub
的加速分发服务器，才使得国内访问速度很慢.</p>
<p>可以通过修改本地 <code>hosts</code> 文件来绕过 DNS 解析来加速.</p>
<p>封面 [ID:46018784].</p>
<span id="more"></span>
<h1 id="solution">Solution</h1>
<ul>
<li><p>首先打开<a
href="http://tool.chinaz.com/dns/">站长工具</a></p></li>
<li><p>填入 &lt;Github.com&gt; <img
src="/images/body/Accessing-GitHub-Slowly-Solution/Figure1.png"
title="在 请输入域名 栏填写" alt="Figure1" /></p></li>
<li><p>将检测列表里的 TTL 值最小的 IP 记为 <em>a.b.c.d</em>.</p></li>
<li><p>使用记事本打开 <code>hosts</code> 文件，位于 &lt;C:&gt;.</p></li>
<li><p>将以下内容加在 <code>host</code> 文件末尾： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a.b.c.d www.github.com</span><br><span class="line">a.b.c.d github.global.ssl.fastly.net</span><br><span class="line">a.b.c.d nodeload.github.com</span><br></pre></td></tr></table></figure> &gt;
其中 <em>a.b.c.d</em> 是上述步骤中记录的 IP 地址. &gt;
如果没有修改权限可以将 <code>host</code>
文件移出该文件夹，修改完成后再移回去. &gt; 系统会确认你授权管理员权限.
<img data-src="/images/body/Accessing-GitHub-Slowly-Solution/Figure2.png"
title="系统向确认你授权管理员权限" alt="Figure2" /></p></li>
<li><p><em>cmd</em> 输入命令 <code>ipconfig /flushdns</code>
刷新DNS缓存.</p></li>
<li><p>Done！试试访问GitHub吧！</p></li>
</ul>
<h1 id="reference">Reference</h1>
<p><a
href="https://blog.csdn.net/CS13477062349/article/details/88020283?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.no_search_link&amp;spm=1001.2101.3001.4242.1">完美解决打开github速度慢的问题</a></p>
]]></content>
      <categories>
        <category>Learning</category>
      </categories>
      <tags>
        <tag>Practical-Tips</tag>
        <tag>GitHub</tag>
        <tag>Solutions</tag>
      </tags>
  </entry>
</search>
